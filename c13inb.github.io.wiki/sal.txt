Amira es un software para visualización científica. Permite cargar archivos de volumen, superficies, tractos, etc. Además se puede programar scripts con el lenguaje tcl.


El laboratorio C13 tiene una licencia flotante de un solo usuario que comparte con el laboratorio del Dr. Rojas Piloni. Utilizamos un calendario de google para reservar el uso de la licencia, ya que solo un usuario puede usar el software en todo momento. El usuario puede cambiar, pero no puede haber dos usuarios al mismo tiempo usando el software.

**Solicita a Luis Concha acceso al calendario de Amira si quieres usar el software.**

# Configurar Amira
Necesitamos abrir una terminal y correr:
```
cp -r /home/inb/LATP2/.config/FEI ~/.config/
cp /home/inb/LATP2/.flexlmrc ~/
```

Y ahora sí podemos utilizar el software con el siguiente comando:
```
/home/inb/lconcha/fmrilab_software/Amira/5.6.0/bin/start
```
# Anaconda

[Anaconda](https://www.anaconda.com/) es un manejador de paquetes y ambientes de Python de código abierto.
Anaconda se encarga de instalar, correr y actualizar paquetes de Python y sus depependencias, así como también para crear ambientes de python de manera muy sencilla.

En esta entrada de la wiki encontrarás algunos comandos básicos para su uso e informacion sobre como configurar Anaconda para que funcione adecuademente en tu cuenta del cluster. Si quieres aprender mas sobre su uso avanzado te recomendamos la [wiki oficial de Anaconda](https://docs.conda.io/projects/conda/en/latest/index.html).



>  :warning: Si ya tenias una instalación local previa de Anaconda y planeas crear nuevos ambientes es necesario realizar una configuracion inicial para no saturar los discos del cluster. Mas de esto en esta wiki.


## Instalando anaconda (miniconda) en el cluster

>  :warning: Lo más relevante de esta sección es asegurarse de que que conda se instale fuera de tu carpeta home. Instalar conda dentro de home inflinge las normativas del cluster con respecto al uso de espacio de discos duros.

La instalación de Anaconda trae por default mucha paquetería científica de python y esto puede generar mucha redundancia y uso de datos en los discos duros del cluster. Por ello recomendamos instalar [miniconda](https://docs.conda.io/en/latest/miniconda.html), que es una versión mínima de Anaconda que sólo trae python. Las librerias que vayan a requerir las pueden ir agregando en los diferentes ambientes que vayan creando.

Para comenzar pueden descargar la versión más reciente de miniconda de este [link](https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh). Si requieren una versión distinta pueden revisar las diferenes opciones en la [documentación oficial](https://docs.conda.io/en/latest/miniconda.html).

Después en una terminal (suponiendo están en la misma carpeta donde guardaron el archivo) ejecutamos el scrip que descargamos:
```
bash Miniconda3-latest-Linux-x86_64.sh
```

Primero nos va a solicitar leer y aceptar los términos de condiciones de licencia los cuales podemos leer detenidamente dando `enter` luego `q` y finalmente escribiendo `yes`.

>  :warning: El siguiente paso es super importante!

Ahora nos va a solicitar en que ubicación instalará Miniconda. Por default será dentro de tu carpeta home lo cual no es permitido en el cluster (Más información de por que en este link). Es vital que cambien el path de instalación a algun folder dentro de su usuario en misc, como ejemplo

```
/misc/computadora/usuario/miniconda
```

donde hay que cambiar `computadora` y `usuario` por su computadora preferente en misc y su usuario.

Después de esto está bien darle a los defaults de la instalación para una instalación general.



## Ambientes de Anaconda
Un ambiente de Anaconda es un directorio que contiene una instalacion aislada de Python y paquetes puestos por el usuario. De esta forma puedes tener varios ambientes con diferentes versiones de python y/o paquetes de tal forma que no haya interferencia o conflicto entre ellos.

Una de las cosas mas utiles de Anaconda es que puedas crear tus propios ambientes de Python y puedas instalar los paquetes que requieras. Con anaconda puedes hacer todo esto sin necesidad de los permisos de superusuario que normalmente impide la instalacion de software en el cluster.


Tu ambiente *(base)* de Anaconda será un python vanilla. Si hay paquetes que necesitas que quisieras tener, ha llegado la hora de que crees tus propios ambientes y les instales lo que requieras.


### Configuracion para crear ambiente fuera de la carpeta de instalacion
Por default Anaconda crea los ambientes en el mismo lugar donde instalaste Anaconda en el paso de instalación. Si instalaste correctamente anaconda en algun lugar de /misc puedes brincarte estas instrucciones. Este paso es opcional si requieres a tus ambientes en otro lugr fuera de la ruta de instalación.

Para cambiar esto necesitamos hacer una configuracion sencilla en tu cuenta. Primero es necesario crees un nuevo folder donde quieras almacenar tus ambientes. La reglas del cluster indican que sea un folder de la carpeta /misc y de preferencia dentro de una carpeta con titulo nobackup. 

En una terminal nueva (que empiece en tu home) escribimos:
```
gedit .condarc
```
la cual abrira gedit con un nuevo archiuvo .condrac vacio. Continuacion pegaremos las siguientes lineas (cambiando "/misc/ruta/a/tu/folder/de/ambientes"  a la ruta del folder que acabas de crear) y le daremos Save
```
envs_dirs:
 - /misc/ruta/a/tu/folder/de/ambientes

env_prompt: ({name})
```
Con esto tendremos Anaconda listo para crear ambientes nuevos.

Nota: Sí algún día borras anaconda no olvides eliminar estos ambientes de dicho lugar.

### Crear/eliminar ambientes nuevos
Para crear un ambiente nuevo de Anaconda escribimos en la terminal:
```
conda create -n myenv python
```
Sustituyendo "myenv" por el nombre que le queremos dar al ambiente. Este comando ba a crear un ambiente con python 3. Podemos especificar la version de python a instalar, como por ejemplo:
```
conda create -n myenvPython2 python=2.7
```
Crearia un nuevo ambiente *myenvPython2* con Python 2.7 instalado.


Para eliminar un ambiente ejecutamos
```
conda remove --name myenv --all
```
sustituyendo *myenv* con el nombre del ambiente a eliminar.

### Navegando tus ambientes
Por default tu miniconda siempre arracna en el ambiente *(base)*

Para ver tus ambientes disponibles los puedes enlistar en la terminal con:
```
conda env list
```
Para una instalación nueva de anaconda sólo tendrá enlistado el ambiente *(base)*, mientras vayas agregando ambientes apareceran aquí.

Para activar un ambiente diferente al *(base)* requieres ejecutar en terminal el comnado:
```
conda activate nombre_del_ambiente_a_activar
```
donde cambias "nombre_del_ambiente_a_activar" por el ambiente a activar.

Puedes moverte con el comando activate entre tus ambientes.


## Manejo de paquetes

Para ver que paquetes de python están en tu ambiente activo basta con escribir
```
conda list
```
Para instalar paquetes nuevos en el ambiente actual lo mas recomendado es hacerlo mediante los paquetes propios comandos de anaconda, loc cuales se van a encargar de instalar todas las dependecias requeridas por este paquete. Esto lo podemos hacer con el comando:
```
conda install paquete
```
Cambiendo *paquete*, por el que vas a instalar.

Si por alguna razón el paquete que vas a instalar no se encuentra en el respositorio default de Anaconda (y por lo tanto falló el comando anterior), te recomendamos intentar buscarlo en el canal repositorio alternativo de *conda-forge*:
```
conda install paquete -c conda-forge
```

El canal *conda-forge* es un repositorio alternativo mantenido por la comunidad pythonera donde vas a encontrar la mayoría de paquetes que requieras. Si de plano tampoco se encuentra en *conda-forge*, aún puedes instalarlo usando el clásico pip:
```
pip install paquete_raro
```
Sin embargo no es recomendado pues anaconda no siempre podrá manejar adecuademente las dependencias de dicho paquete. Usalo sólo en caso de que tu paquete no se encuentre en *conda-forge*.


# BIDS


[BIDS](https://bids.neuroimaging.io/) es un estándar de almacenamiento de datos, que mediante una jerarquía de carpetas y nomenclatura específica de archivos, permite la utilización transparente (y supuestamente sencilla) de complicados [*pipelines*](http://bids-apps.neuroimaging.io/) de procesamiento de imágenes reunidos en *contenedores* tipo [Docker](https://www.docker.com/) y/o [Singularity](http://singularity.lbl.gov/) que facilitan la reproducibilidad de los resultados. Puede usarse para analizar fMRI, DWI, e imágenes anatómicas.


No es la intención de esta página el repetir lo que ya está dicho de cómo se organizan los datos en BIDS, pues para ésto hay tutorales. [Aquí están los tutoriales oficiales](https://github.com/bids-standard/bids-starter-kit/wiki/Tutorials), pero una búsqueda en Google revelará muchos más.

Una vez que organices tus datos, revisa que hayas hecho un buen trabajo, validando tu fólder bids mediante el [bids validator](http://bids-standard.github.io/bids-validator/).


Listo para correr un contenedor? Tenemos instalado [Singularity](http://singularity.lbl.gov/) en el cluster del laboratorio! De igual forma, está instalado en el LAVIS!

Como ejemplo, veamos cómo correr [fmriprep](https://fmriprep.readthedocs.io/en/stable/).  [Sigue esta liga para un corto tutorial.](./fmriprep)

***

## PPMI
Para notas sobre cómo bajar datos de [PPMI](https://www.ppmi-info.org/) y convertirlos a BIDS, visita [aquí](./ppmi_bids).


***

## Convertir tus imágenes pre-clínicas en formato BIDS

Para mayor control y estandarización en la organización de tus imágenes, se recomienda el uso de BIDS. Y también tiene la ventaja de que es muchísimo mas rápido convertir todas tus imágenes que están en el Bruker en formato nifti. 

En este tutorial te digo como hacer la conversion utilizando las herramientas de `BIDS converter` ya englobadas en un script que hará todo el proceso de conversion por ti. Sin embargo hay solo un preparativo previo: tienes que pasar a un directorio todos las carpetas del bruker que desees convertir. 

Accede a la ruta del bruker:
```
ls /misc/bruker7/data02/user/...
```

Una vez que identificas las imágenes de tu experimento, las moveremos a tu directorio de trabajo (`/misc/../..`):

`cp -r /misc/bruker7/data02/user/mi_usuario/mis_imagenes* /mi/directorio/de/trabajo/`
> Usa las rutas de acuerdo a tu usuario y el directorio donde almacenas tu información.

Ahora si usaremos el script de abajo que ya engloba las dos funciones de bruker para realizar la conversion `bids_helper` que generará el archivo `.csv` de la descripción de tu dataset y `bids_convert` que hará toda la conversión. 

Abre `micro` o `nano` en la terminal y haz _copy & paste_ lo siguiente:

```bash

#!/bin/bash


module load brkraw/0.3.11


raw_dir=$1

mkdir ${raw_dir}/BIDS
bids_dir=${raw_dir}/BIDS
csv_filename=dataset_description

brkraw bids_helper $raw_dir ${raw_dir}/${csv_filename} -j 


brkraw bids_convert $raw_dir ${raw_dir}/${csv_filename}.csv -o $bids_dir

```

Ahora cierra el editor, nombra el script como bruker2bids.sh y luego escribe en la terminal: `chmod a+x bruker2bids.sh`

Listo, ahora usaremos el código de la siguiente manera:

```
bruker2bids /la/ruta/de/mis/imagenes/crudas/
```

> Modifica la ruta del directorio por la ruta donde tienes guardadas las imágenes crudas que pasaste del bruker.

La organización quedará de la siguiente manera:

```bash

raw_dir
   \- bruker_raw_folder                               
   \- bruker_raw_folder
   \- bruker_raw_folder
   .
   .
   .
   .
   \- dataset_description.csv
   \- dataset_description.json
   \- BIDS
       \- README
       \- dataset_description.json
       \- participants.json
       \- participants.csv
       \- sub-001
            \-anat
                \- nii.gz
            \-dwi
                \- .bval
                \- .bvec
                \- nii.gz
            \-fmap
                \- nii.gz
            \-func
                \- nii.gz

       \- sub-002
            .
            .
            .

```
Bash es un intérprete de comandos que viene por defecto en los sistemas **Linux y Mac**.  Este programa interpreta órdenes que el sistema operativo llevará a cabo. Permite un control de las tareas comunes del sistema y es de gran utilidad para la automatización de tareas.  Sin embargo, dado que el **shell bash** requiere el manejo fluido comandos, la curva de aprendizaje suele ser lenta.


Con la intención de facilitar su uso, aquí encontrarás una lista de comandos más comunes que te ayudarán con tu trabajo diario con bash. Si quieres aprender más, te recomiendo el capítulo [The Unix Workbench](https://seankross.com/the-unix-workbench/command-line-basics.html) donde viene a gran detalle e incluye ejercicios de práctica. 


## bash - Comandos Básicos ##

En la sección [Comandos Básicos](./Bash:-Comandos-Básicos) se encuntran una serie de comandos frequentemente utilizados en bash que permiten la interacción con el sistema.

El 95% de todos los comandos, trucos y piruetas que **se recomienda que todo integrante del laboratorio sepa** están agradablemente compilados en un TUTORIAL de la gente que hace el fsl, el cual puede consultarse [aquí](https://open.win.ox.ac.uk/pages/fslcourse/lectures/scripting/all.htm). **NOTA**: En ese tutorial utilizan el lenguaje de shell llamado ''sh'', que está localizado en ''/bin/sh'', mientras que en el laboratorio habitualmente utilizamos ''bash'', que está en ''/bin/bash''. Los dos lenguajes hacen prácticamente lo mismo y tienen una sintaxis casi idéntica, con ligeras diferencias que pueden consultarse [aquí](https://superuser.com/questions/125728/what-is-the-difference-between-bash-and-sh.). Y por acá hay otro excelente tutorial: https://command-line-tutorial.readthedocs.io/


## bash - Avanzado ##
Una vez aprendidos los comandos básicos puede consultar la sección de bash [avanzado](./Bash:-Avanzado), la cual contiene comandos que te  permitirán realizar muchas más acciones en la terminal.
## Operaciones ariméticas con variables de coma flotante ##

awk "BEGIN {print $ul_mean+(2*$ul_st); exit}"

uthr=$(awk "BEGIN {print $ul_mean+(2*$ul_st); exit}")


awk '{ $1 = $2 + $3 / $4; print }' inventory-shipped

The arithmetic operators in awk are:

x + y
    Addition. 

x - y
    Subtraction. 

- x
    Negation. 

+ x
    Unary plus. No real effect on the expression. 

x * y
    Multiplication. 

x / y
    Division. Since all numbers in awk are double-precision floating point, the result is not rounded to an integer: 3 / 4 has the value 0.75. 

x % y
    Remainder. The quotient is rounded toward zero to an integer, multiplied by y and this result is subtracted from x. This operation is sometimes known as "trunc-mod." The following relation always holds:

    b * int(a / b) + (a % b) == a

    One possibly undesirable effect of this definition of remainder is that x % y is negative if x is negative. Thus,

    -17 % 8 = -1

    In other awk implementations, the signedness of the remainder may be machine dependent. 

x ^ y

x ** y
    
Exponentiation: x raised to the y power. 2 ^ 3 has the value 8. The character sequence `**' is equivalent to `^'. (The POSIX standard only specifies the use of `^' for exponentiation.) ## Selección de elementos, filas y columnas ##
Supongamos que hay un archivo con la siguiente información dentro de un archivo de valores separados por comas llamado **datos.csv**. 

Al utilizar el valor **$0** se imprimen todos los valores contenidos en el archivo.

``` bash
 $ awk -F "\"*,\"*" '{print $0}' datos.csv

type,ID,WM.cm3,WM.%,GM.cm3,GM.%
no_incl,job932,381.3076,34.6114,537.8429,48.8202
no_incl,job933,599.6653,35.8897,798.9063,47.8141
no_incl,job945,523.3554,42.194,610.4963,49.2194
no_incl,job957,483.2968,35.1759,646.6898,47.0682
```
Si quisieras imprimir la 3ra columna completa se escribe de la siguiente manera, donde el $3 equivale a la tercera columna, $2 a la segunda, $1 a la primera, etc.:

```bash 
$ awk -F "\"*,\"*" '{print $3}' datos.csv

WM.cm3
381.3076
599.6653
523.3554
483.2968
```

Con NR==# se puede escoger una fila en particular, en este caso escogemos la 3er fila:

``` bash
$ awk -F "\"*,\"*" 'NR==3' datos.csv

no_incl,job933,599.6653,35.8897,798.9063,47.8141
```

Y utilizando una combinación de ambos se puede seleccionar un elemento en particular, aquí escogimos el elemento de  la 4a fila y 6a columna:
``` bash
$ awk 'NR==4 {print $6}' tmp.csv

49.2194
```

Finalmente se pueden seleccionar multiples elementos de una fila o columnas. A continuación escogimos en el primer ejemplo la fila 3, columnas 2, 3 y 4.
Y en el segundo ejemplo se escogieron de la fila 2 a la 4, columnas 2, 3 y 4.

Ejemplo 1

```bash
$ awk -F "\"*,\"*" 'NR==3 {print $2,$3,$4}' datos.csv

job933 599.6653 35.8897
```
Ejemplo 2
``` bash
$ awk -F "\"*,\"*" 'NR==2,NR==4 {print $2,$3,$4}' datos.csv

job932 381.3076 34.6114
job933 599.6653 35.8897
job945 523.3554 42.194
```
### Nota ###
Si tu archivo no es .csv y es .txt o es una variable dentro de un scrip no es necesario incluir la opción **-F "\"*,\"*"**, que solo se utiliza para indicar que los valores estan separados por comas. Entonces se escribiría:

```bash
awk 'NR==3 {print $2,$3,$4}' datos.txt
```
 o

```bash
awk 'NR==3 {print $2,$3,$4}' $datos
```
## AWK ##
AWK es un lenguaje de programación diseñado para procesar datos basados en texto, ya sean ficheros o flujos de datos.

## Estructura de awk ##
**awk** bla bla bla bla bla pendiente

blablablabla blablablabla


``` bash
 awk bla bla bla BEGIN END print
```
## Declarar variables de BASH dentro de awk ##
awk -v d=INICIO '{print d " " $0}'

## Redireccionar valores generados por awk ##
Declarar las variables de BASH A awk


**awk** bla bla bla bla bla pendiente

``` bash
Td=`fslstats_rois $t2m $labels $Tal_DER "-M -S -P 50 -m -s -V"`
  Tdmean=$(awk '{print $1}' <<< "$Td")
```
## Agregar variables al PRINCIPIO o al FINALde una fila ##
Al **final**
``` bash
awk -v d=$dir '{print d " " $0}' tmp_struct0.txt > tmp.txt 
```
Al **principio**
```
bash awk -v d=$dir '{print d $0 " "}' tmp_struct0.txt > tmp.txt
```
## Selección de elementos, filas y columnas ##
[awk select](./Bash:-AWK-Selec) permite seleccionar elemento de un archivo con varias columnas y filas (.csv .txt etc) **awk** . Y puede ser una fila, una columna o varias, o un solo elemento.

## Operaciones ariméticas con variables de coma flotante  ##
Bash no puede realizar operaciones aritméticas con números con decimales, sin embargo, awk, si logra multiplicar, dividir, sumar y restar estos valores. Para esto revisar la entrada [awk arimet](./Bash:-AWK-Arimet).
## [Permisos](./Bash:-Permisos) ##
Los permisos de archivos determinan los usuarios que pueden interactuar con éstos. Quién puede modificar, borrar o mover los mismos.

## [Comprimir](./Bash:-Comprimir) ##
Este comando te sirve para disminuir el tamaño de los archivos que se manejan en el clúster se puede utilizar el formato __TAR__ comprimido por __gzip__.

## [Variables](./Bash:-Variables) ##
El manejo de variables es fundamental para la programación y bash scripting no es la excepción. Aquí te explico más.

## [Bucles/Loops](./Bash:-Loops) ##
Los comandos `for`, `while` y otros te permiten repetir una misma tarea tantas veces lo requieras y son altamente efectivas para automatizar procesos. En esta entrada hay ejemplos.

## [Funciones](./Bash:-Funciones) ##

## [Comando `sed`](./Bash:-sed) ##

## [Comando `grep`](./Bash:-grep) ##
El comando `grep` es una herramienta muy poderosas para búsqueda y otros procesos en linux.

## [AWK Programming Language](./Bash:-AWK) ##  
El lenguaje `awk` permite procesar datos de texto y numeros con decimales (de punto flotante). Aquí encontraras ejemplos prácticos para el procesamiento de imágenes con bash.

## [Gestión de procesos](./Bash:-Gestión-de-procesos) ##
Conocer los comandos de gestión de procesos y del sistema es importante para el buen uso del cluster.

## [ssh - Security Shell](./SSh) ##
El protocolo **ssh** permite realizar acceso remoto con una interacción a nivel de consola o mediante interfaces gráficas. 
# Lista de comandos:

## man = manual
La gran mayoria de los comandos vienen con un manual de uso, para acceder a estos hay que utilizar `man` y despues escribir el nombre del comando que quieres aprender a usar:

```
man echo

NAME
       echo - display a line of text

SYNOPSIS
       echo [SHORT-OPTION]... [STRING]...
       echo LONG-OPTION

DESCRIPTION
       Echo the STRING(s) to standard output.

       -n     do not output the trailing newline

       -e     enable interpretation of backslash escapes

       -E     disable interpretation of backslash escapes (default)

       --help display this help and exit

       --version
              output version information and exit     
.
.
.
.
```

## echo
Imprime una frase o lo que sea que se escriba en la terminal:

```
echo Hello world!

## Hello world!
```

## pwd = print working directory
Si necesitas saber en que directorio estas tranajando, este comando lo que hace es que imprime tu actual directorio 
```
pwd

## /home/inb/paulinav
```

## cd = change directory
Este comando funciona para cambiar directorio. Cuando inicias sesión en tu computadora, lo más probable es que tu directorio sea el home y muy probable es que tengas que cambiar al directorio donde se encuentran tus datos. 

Mi directorio actual es:
```
pwd
## /home/inb/paulinav
```
Cambio de directorio a donde esten mis datos:
```
cd /misc/nyquist/paulinav/datos

pwd

## /misc/nyquist/paulinav/datos
```

Para regresar directorios:
```
cd ..

## /misc/nyquist/paulinav

cd ../..

## /misc/nyquist

cd ../../../

## /misc
```

## ls = list
Este comando va a enlistar los archivos que existen en tu actual directiorio. Supongamos que estamos en el home:

```
ls

## Desktop
## Documents
## Downloads
## Music
## Videos
```
Pero tambien puedes utilizar `ls` para enlistar los archivos que existen en una ruta específica

```
ls /misc/nyquist/paulinav/miniconda

## bin
## compiler_compat
## condabin
## envs
....ect
```

## mkdir = make directory
Ahora podemos crear uno o multiples nuevos directorios/carpetas con este comando:

```
mkdir Mi_carpeta
```
o multiples:
```
mkdir carpeta1 carpeta2 carpeta3
```

## cp = copy
Con este comando podemos hacer una copia de los archivos que queramos de un directorio a otro, por ejemplo:
```
cp /misc/nyquist/paulinav/archivo.txt /misc/rhesus/paulinav/datos
```

## mv = move
este comando tiene dos funciones: mover el archivo de un lugar a otro o/y renombrar dicho archivo.
Para mover mi archivo de un directorio a otro:
```
mv archivo.txt ~/Documentos
```
Para cambiarle el nombre:
```
mv archivo.txt nuevo_archivo.txt
``` 
## rm = remove
Poderoso y peligroso. El comando `rm` es para eliminar archivos de forma **definitiva** ya que NO hay vuelta atrás una vez que lo ejecutas, así que aguas! Para usarlo solo necesitas darle el path del archivo:
```
rm archivo.txt
```
o 
```
rm /misc/nyquist/paulinav/archivo.txt
```

## cat = concatenate 
Este comando es muy útil y tiene varias funciones, entre las más relevantes es leer/imprimir, crear y unir archivos .txt, .sh y más. 

Para leer el contenido de un archivo .txt:
```
cat archivo.txt
```
Para concatenar dos archivos:
```
cat archivo1.txt archivo2.txt > nuevo_archivo.txt
```
Para crear un nuevo archivo:
```
cat > archivo.txt
```

## head
Este comando imprime/lee las primeras líneas de un archivo y es muy util cuando estas explorando el contenido de ciertos archivos sin tener que ver todo el contenido usando `cat`.
```
head abecedario.txt

## A
## B
## C
## D

```
## tail
Mientras que `tail` lee las últimas lineas de un archivo:
```
tail abecedario.txt

## W
## X
## Y
## Z
```

## tree
este comando despliega a los directorios con su estructura e información. Da una representación visual de las carpetas y sus archivos de manera muy eficaz. Ya que por ejemplo, `ls` si bien es efectivo, solo enlista los archivos de un solo path, mientras que `tree` despliega todos los directorios y sub directorios dentro del path.
```
tree /home/paulinav

# /home/paulinav
# ├── Documents
# │   ├── file1.txt
# │   └── file2.txt
# ├── Downloads
# │   └── program1
# └── Pictures
#     └── image1.jpg
```

## * = wildcard
Uno de mis favoritos es el super asterisco `*`, que es una manera altamente efectiva de filtrar, buscar y seleccionar archivos en un directorio. Aquí vamos a poner unos ejemplos.
Suponiendo que tenemos una serie de archivos en nuestro directorio:
```
ls

## img.png
## img_hm.png
## img_rat.png
## img_b.png
## script_rat.sh
## script_hm.sh
## script_img.sh
## list_px.txt
## list_task.txt
## list_class.txt
```
Puedo seleccionar solamente todos aquellos con terminación `.sh`:
```
ls *.sh

## script_rat.sh
## script_hm.sh
## script_img.sh
```
O filtrar aquellos archivos que son relacionados a roedores:
```
ls *rat*

## img_rat.png
## script_rat.sh
```
O seleccionar todos los archivos que empiecen con list:
```
ls list*

## list_px.txt
## list_task.txt
## list_class.txt
```

## & = ampersand
Este es un indicativo al final de un comando que permite que se ejecute en el background mientras te permite seguir trabajando o escribiendo en la terminal. Un ejemplo donde es increiblemente útil es al abrir imágenes, por ejemplo:
```
display imagen.png &
```












*[DICOM]: Digital Imaging and Communication in Medicine
## Comprimir

Comprimir los archivos [__DICOM__](http://es.wikipedia.org/wiki/DICOM), reduce dramaticamente el uso de espacio de disco, por lo que es una practica recomendable. Además depende de una instrucción sencilla.  

Para comprimir un directorio se usa:

    tar cvzf archivo.tar.gz /archivo/*

Para extraer el contenido se utiliza:

    tar xvzf archivo.tar.gz

Para listar el contenido sin extraer:

    tar tvzf archivo.tar.gz

f
: indica el nombre del archivo

z
: indica que va comprimir con gzip el archivo

j
: cuando se usa, indica el uzo de bzip que tiene una tasa mayor de compresión pero tarda mas y consume mas recursos

v
: permite ver los avisos del proceso 

c
: indica que se creara una archivo comprimido

x
: indica que se descomprime el archivo 

t
: genera un listado de los archivos que lo forman
## top
Muestra los procesos que se están ejecutando y permite matarlos.

## htop

**htop** es una versión más avanzada de **top**, la cual permite observar los procesos activos.

El comando `htop` inicia esta interfaz en la cual nos desplazamos con las flechas arriba y abajo. El comando tiene más opciones de control. Sin embargo nos pueden interesar dos: F6 permite seleccionar el orden en el que se presentan los procesos, y F9 terminar los procesos.

Son de especial interes el arreglo por __USER__, __CPU%__ y __MEM%__.

## Matar procesos ##

Bash tiene diversas formas para terminar comandos y procesos en ejecución, revise la entrada para [terminar un proceso](./Bash:-kill).

##ps

Muestra la lista de procesos del usuario.

Este comando es útil en varias cuestiones, por ejemplo, nos puede mostrar los procesos en nuestro sistema, el estado del mismo, los datos sobre el tamaño de algún proceso, los usuarios a los que pertenecen algunos procesos, el tiempo del CPU, el tiempo del reloj y muchos más.

Parámetros:

     -a Muestra todos los procesos con un control, este comando no sólo muestra datos del usario actual.
     -r Muestra sólo los procesos que están en ejecución
     -x Muestra procesos, de los cuáles la terminal no tiene control.
     -u Muestra los procesos del propio usuario (owner process)
     -l Muestra los datos en formato de una lista larga
     -w Muestra procesos de la línea de comandos.

##free -h

Muestra el estado de la memoria del CPU actual.

## df

Muestra el espacio libre de los discos/dispositivos. Legible a humanos (-h)

      df -h

## ping

Indica si hay respuesta por parte del servidor

      ping mansfield
## ¿Cómo matar un proceso?

En ocasiones ocurre que por alguna razón, los procesos en los que trabajamos,
necesitan ser terminados:

- Porque ocupan muchos recursos,
- Porque se quedaron trabados,
- Porque sus procesos _"padre"_ murieron pero ellos no
- O porque no permiten la ejecución de otros programas.

En cualquiera de los casos es importante saber cómo matar los procesos.

### ps y kill

La opción clásica para matar un proceso es usando dos comandos en la terminal.

    ps -a

Permite ver una lista de los procesos en ejecución que nos pertenecen.

    ps -A

Nos muestra una lista completa de todos los procesos activos.  En ambos casos
se puede usar grep para buscar en la lista un programa en particular.

    ps -A | grep programa

Cuando lo utilizamos, nos muestra una salida como esta:

    PID TTY          TIME CMD
    1841 pts/9    00:00:00 dbus-launch
    3622 tty2     00:00:00 bash
    5411 pts/7    00:00:00 ps

Dónde lo importante es el número __PID__, pues este número es el que
utilizaremos en el comando _kill_.

    kill 5411

Si se necesita que el proceso acabe inmediatamente, se puede usar una
prioridad __9__ que lo vuelve obligatorio.

    kill -9 5411


### htop

Htop es una manera muy cómoda para terminar un proceso. Basta seleccionar el proceso y presionar __F9__, esta acción 
contiene varias opciones, sin embargo, es suficiente con la opción por default. Al presionar enter el proceso termina.

En cuaquier caso para salir de una selección se presiona __ESC__. Y para salir del programa se usa la tecla __q__.

[[images/htop.gif]]

### Interfaz gráfica

Si se quiere hacer gráficamente, se abre la aplicación __system monitor__ o
desde la consola `gnome-system-monitor` ahí en la pestaña de procesos se ubica
el programa y al presionar el segundo botón sobre el proceso aparece la opción
__kill process__. Un ejemplo:  

[[images/killgrafico.gif]]  

## Matar todo lo que puede morir (de tu sesión)

En un caso extremo dónde se haya trabado todo y no veas nada incluída la interfaz gráfica, primero se debe de ingresar al **TTY** (terminales físicas sin entorno gráfico) por medio de las teclas **Crtl+Alt+F1-F6**, son seis las que se pueden seleccionar, de F1 a F6.

Una vez ahí se debe dar login con tu **usuario** y **contraseña**.

Entonces se escribe:

    kill -9 -1

Parecerá que se reinicia la sesión gráfica y tendrás que entrar de nuevo. Asegúrate de entrar nuevanebte al TTY y cerrar la sesión.
## Iteración de comandos con `for` ##

**for** es un comando poderoso que permite repetir un comando en varios archivos. La traducción de for sería:

**Definiendo** <mi_variable> **como** <mis_archivos>; **se debe de** <usar_comando> <mi_variable>; terminado

**for** var **in** *.*; **do** <comando> $var; done

<mi_variable> puede ser cualquier letra que se quiera asignar


En el siguiente ejemplo se imprimira en la pantalla todos los archivos dentro de una carpeta escribiendo antes la palabra "hola"
``` bash
for i in $( ls ); do echo hola: $i; done
```
  *  **i**: es mi variable que defino y comprende a todos los archivos que se mencionan en `$(ls )`    
  * **echo hola:** es el comando que quiero repetir.


``` bash
hola archivo1.txt
hola archivo1.txt
hola archivo2.txt
hola archivo3.txt
hola archivo4.txt
```

Otro ejemplo de un uso de **for** es el siguiente para subir al cluster la  realización de una mascara binaria con *bet*  en todos los archivos **nii.gz** que comienzan con **t1_** y tienen 4 caracteres más.

``` bash
for x in $(ls t1_????.nii.gz); do fsl_sub -N $x bet $x $x -m -n -B -f 0.35; done
```
## Leer lineas de un archivo de texto con `while read` ##
Si tengo un archivo de texto (txt) y quiero realizar una acción con cada linea puedo usar:
``` bash
while read linea; do
echo $linea; 
done < miTexto.txt
```
lo anterior imprimira el contenido de cada linea: 

```bash
3 GCC Genu of corpus callosum
4 BCC Body of corpus callosum
5 SCC Splenium of corpus callosum
```
## Crear condicionales con `break` y `continue` ##
Si bien el `for` nos hace la vida más fácil al ejecutar una gran cantidad de tareas, puede tambien quedarse atorado en un loop "infinito", es asi que `break` resulta bastante útil. Aquí es una sintaxis de vainilla:

```bash
nombres=("Maria" "Luisa" "Carla" "Mariana" "Flor")

for n in "${nombres[@]}"; do
   echo "Nombre: $n"

  if [ "$n" == "Mariana" ]; then
      echo "Encontré a Mariana. Para aquí"
      break

  fi

done

## output
Nombre: Maria
Nombre: Luisa
Nombre: Carla
Nombre: Mariana
Encontré a Mariana. Para aquí
```
Donde el script hará la iteraciones necesarias hasta llegar al nombre de Mariana (en este caso) y ahí es donde terminará el loop. 


Ahora, si cambiamos el `break` por el `continue`, hará que las iteraciones sigan corriendo aunque haya encontrado la variable:
```bash
nombres=("Maria" "Luisa" "Carla" "Mariana" "Flor")

for n in "${nombres[@]}"; do
    echo "Nombre: $n"

    if [ "$n" == "Mariana" ]; then
        echo "Ignora que encontramos a Mariana"
        continue
    fi
done

## output
Nombre: Maria
Nombre: Luisa
Nombre: Carla
Nombre: Mariana
Ignora que encontramos a Mariana
Nombre: Flor
```
Vuelve a hacer la iteración, pero aun que haya encontrado a "Mariana", va a continuar el loop hasta que acabe todas las iteraciones. 






## Ajuste de permisos para trabajos en el clúster

Es muy importante entender el tema de los permisos ya que al estar trabajando en el clúster, si no tienes los permisos necesarios, esto puede limitar mucho tu trabajo. 

### ¿Como saber que permisos tengo? 

Al utilizar `ls -l` nosotros podemos ver los detalles de cada directorio y archivo, incluyendo los permisos:

![image](https://github.com/c13inb/c13inb.github.io/assets/129544525/fdc38680-2baf-4acb-adcd-35ddafe2f937)

En el recuadro rojo vemos los permisos donde:

`a`: archive, osea que es un archivo nada más.

`d`: directory, es un directorio.
 
`r`: read permissions, quiere decir que tienes tu como usuario permisos de lectura en el archivo/directorio.

`w`: write permissions, esto significa que como usuario puedes escribir, modificar o incluso elimiar el archivo/directorio.

`x`: execute permissions, esto aplica para poder ejecutar scripts principalmente (más abajo explico como).


Pero vemos que hay una separación con  `-` entre permisos, esto se refiere quien y quienes son los que tienen permisos aquí, es decir: 

![image](https://github.com/c13inb/c13inb.github.io/assets/129544525/0375fb49-773c-4e68-8044-dbdbdd7a102e)

* Rectangulo amarillo son tus permisos como usuario (paulinav) 
* Rectangulo azul son los permisos del grupo (fmriuser)
* Rojo son los permisos a "otros", osea todos aquellos que no sean tu como usuario o los que pertenecen al grupo fmriuser. 

Entonces, en otras palabras: si tu como usuario tienes `rwx` quiere decir que tienes todos los permisos en dichos archivos/directorio.

Ahora, en la siguiente imágen, el rectangulo amarillo te dice el nombre del usuario (paulinav) y el grupo al que perteneces (fmriuser)

![image](https://github.com/c13inb/c13inb.github.io/assets/129544525/66fc01c1-6cfe-42c1-b77a-c2852a361918)

## Modificar permisos con `chmod`
Ahora que ya sabemos como leer los permisos, podemos utilizar el comando `chmod` que es el que nos ayudara a modificar/específicar los permisos a quienes nosotros queramos. 

La sintaxis de `chmod` se basa en el "quién", "qué" y "cúal" dar los permisos:

* Quién

`u`: osea el dueño del archivo

`g`: permisos a todos los miembros del grupo

`o`: permisos al resto (otros)

`a`: permisos a todos los de arriba

* Qué

`-`: remueve los permisos

`+`: concede el permiso

* Cúal

`r`; permiso de lectura

`w`: permiso de escritura

`x`: permiso de ejecución

Por ejemplo, si yo creo un nuevo script, no lo voy a poder ejecturar inmediatamente, necesitaré cambiar los permisos de tal manera que pueda ser ejecutado:
```
chmod a+x mi_script.sh
```
Donde estoy especificando que `mi_script.sh` pueda ser ejecutado (`x`) por cualquiera (`a`)

---

También puedes asignar el grupo ya sea fmriuser o bioinfo a una carpeta, subcarpetas y los archivos que contenga, se puede usar el comando:
``` 
chown -R usuario:grupo carpeta/
```
Y para permitir escritura y lectura al grupo usas:
```
chmod -R g+rwx carpeta/
```
Sin embargo, puede ocurrir que no se pueda cambiar el grupo si no somos los dueños de la carpeta en cuestión. Si es necesario ajustar el grupo y por alguna razón no funciona el comando, el administrador del equipo en cuestión puede realizar el cambio.



   


En el contexto de la programación, una variable funciona como un "contenedor" que almacena un valor que puede ir cambiando a lo largo del tiempo durante la ejecución de un programa. Cuando se declara una variable, este se reserva en un espacio en la memoria donde almacena su valor, normalmente tu como usuario decides que nombre le das a tu variable, el cual tiene que ser un nombre unico de preferencia, para que puedas hacer referencia a ella en el código. 
Las variables tienen la ventaja de que pueden contener cualquier tipo de informacion, ya sea numérica, texto, directorios, etc.

### Asignación de variables 

En este primer ejemplo la variable contiene la frase Hola mundo, la cual puedes imprimirla en la terminal usando `echo`. Donde el signo `=` lo utilizo para **asignar** mi variable y el signo de `$` para mandarlo a llamar. 

```bash
> mi_variable = "Hola mundo"

> echo $mi_variable 

> Hola mundo
```

Hagamos otros ejemplos:

```bash
> export PATH=/misc/nyquist/paulinav

> echo $PATH

> /misc/nyquist/paulinav
```

```bash
> edad = 30

if [ $edad -ge 18 ]
 then
    categoria="Adulto"
else
    categoria="Menor"
fi

> categoria=Adulto
```

```bash
> input=/misc/nyquist/usuario/mis_imagenes
> output=/misc/carr2/usuario/analisis

for f in ${input}
   do
      cp -r $f ${output}

done

```

Existen mil maneras mas de utilizar las variables. Al final del día, las variables te facilitaran muchisimo el manejo de la terminal, y tambien brindarán estabilidad en tus scripts. 



El comando `sed` (**s**tream **ed**itor) es una herramienta muy poderosa y elegante para la manipulación de texto. El comando te permite realizar operaciones de búsqueda, sustitución y manipulación de texto ya sea en archivos o basicamente de cualquier argumento de salida de otros comandos. Veamos un poco más.

### Sintaxis basica

```bash
sed [OPCIONES] [SCRIPT] [ARCHIVO]
```
Hagamos un ejemplo:

```bash
> echo 
"Pepe Pecas pica papas con un pico, 
con un pico pica papas Pepe Pecas. 
Si Pepe Pecas pica papas con un pico, 
¿donde esta el pico con que Pepe Pecas pica papas?" 
>> Pepe_Pecas.txt
```
De este texto voy a reemplazar todas las palabras "papas" por "manzana":

```bash
sed 's/papas/manzana/g' Pepe_Pecas.txt
```
```bash
> cat Pepe_Pecas.txt

"Pepe Pecas pica manzana con un pico, 
con un pico pica manzana Pepe Pecas. 
Si Pepe Pecas pica manzana con un pico, 
¿donde esta el pico con que Pepe Pecas pica manzana?"
```
Tambien podemos contar cuantas veces se menciona a Pepe en el texto:
```bash
> sed 's/Pepe/Pepe\n/g' Pepe_Pecas.txt | grep -c "Pepe"
> 4
```

O porque no agregar una linea al final del texto:
```bash
> sed '$a\Definitivamente Pepe perdio el Pico' Pepe_Pecas.txt

> cat Pepe_Pecas.txt

"Pepe Pecas pica papas con un pico, 
con un pico pica papas Pepe Pecas. 
Si Pepe Pecas pica papas con un pico, 
¿donde esta el pico con que Pepe Pecas pica papas?
Definitivamente Pepe perdio el Pico"
```



[Aquí](https://www.digitalocean.com/community/tutorials/the-basics-of-using-the-sed-stream-editor-to-manipulate-text-in-linux) te dejo un manual para más trucos con `sed`

## Grupo __bioinfo__ ##

### Datos
Los usuarios de este grupo pueden iniciar sesión al igual que los del grupo
fmriuser. Sin embargo con el afán de facilitar la labor de respaldo de los
diferentes grupos, es recomendable usar una carpeta por usuario en la carpeta
local de datos en específico, las que se encuentran en los equipos de bioinformática.

    /datos/equipo_bioinfo/usuario

Actualmente se cuenta con los equipos Opti790 y mendel.

### Permisos

A su vez es importante que el grupo y los [permisos](https://github.com/rcruces/C-13_wiki_demo/wiki/Permisos) de grupo se asignen tanto a carpetas como a archivos, ya que si los permisos no están debidamente asignados, esto puede derivar en un fallo en el procesamiento de la tarea por parte del clúster.

### Programas

Los programas se encuentran alojados en la carpeta:

    /datos/mendel/bioinfo/

Esto para permitir el acceso de todos los equipos del clúster a los programas.
Además algunas de las variables necesarias se asignan en un perfil que se
carga al inicio de sesión de cada usuario del grupo.

Los programas instalados son:

    Bowtie
    Bowtie2
    Tophat
    Cufflinks
    Bedtools
    HTseq
    Samtools
    Blat

Aún faltan por instalar y configurar:

    cummeRbund

### PATH y Variables

Para `bowtie2` se generó la variable BT2_HOME que señala a `/datos/mendel/bioinfo/bowtie2/`. Además las direcciones para las diferentes aplicaciones se encuentran en el path de los usuarios del grupo __bioinfo__. Por lo que en teoría cualquier aplicación de los paquetes se ejecutaría automáticamente para todos los usuarios.# Generar Mapas de B1 en Bruker


Paravision 7 incluye una secuencia para generar mapas de B1 basado en el método DREAM [(Nehrke y Börnet, 2012)](https://onlinelibrary.wiley.com/doi/10.1002/mrm.24158).

![](images/2025-02-25-09-35-41.png)

Según el manual de Paravision 7, es posible sacar directamente los mapas, que están representados en unidades de Hz/W. 

![Manual Paravision 7](images/B1map_PV7manual.png)

Sin embargo, en ocasiones uno puede preferir el mapa de ángulos de desviación en grados. 

En el foro de discusión de preclinical imaging de Bruker, dan una solución sencilla [(link, se requiere registrarse gratis)](https://pci-community.com/t/b1-mapping/900/11):

![code](images/B1map_pciforum.png)

Muy bien, muy bien, pero puede haber una solución más sencilla y transparente. Es decir, quiero ver las imágenes que adquiere la secuencia de B1Map de Bruker, de las cuales se deriva el ángulo de desviación real. 

# Generar Mapas de B1 con QUIT

[QUIT](https://quit.readthedocs.io/en/latest/) es un programa que incluye diversas rutinas para imagen cuantitativa. Es bastante útil para relaxometría, transferencia de magnetización, etc. Afortunadamente, incluye una rutina para calcular el mapa de B1 a partir de las imágenes crudas del método DREAM.

Para poder tener las imágenes crudas del DREAM, debemos reconstruirlas de manera normal (el default es B1Map). Las buscamos en el Explorer de PV7, y damos clic derecho en ellas.

![](images/2025-02-25-09-36-37.png)

![](images/2025-02-25-09-36-45.png)

Seleccionamos Data Reconstruction

![](images/2025-02-25-09-36-58.png)

Y solicitamos una reconstrucción convencional.

![](images/2025-02-25-09-37-10.png)

Eso genera una nueva serie de imágenes, en 4 dimensiones, siendo el primer volumen la imagen STE, y el segundo el eco de gradiente (FID):

![](images/2025-02-25-09-38-37.png)

Ahora, convertimos esas imágenes usando `brkraw`. Las encontraremos como `Magnitude Image`, y veremos que tiene dos volúmenes.

![](images/2025-02-25-09-40-09.png)


`brkraw` no lo convierte a 4D, sino que hace dos imágenes independientes. Para facilitarme la vida, voy a hacer unos links simbólicos para identificar quién es STE y quién es FID:

```bash
ln -s 250224_mt_r2g1c_s2_3_4_3_b1map-_e4_-01.nii.gz STE.nii.gz
ln -s 250224_mt_r2g1c_s2_3_4_3_b1map-_e4_-02.nii.gz fid.nii.gz
```

Ahora concatenamos estos dos volúmenes en un archivo 4D que llamaré `dream_file.nii.gz`:

```bash
mrcat -axis 3 fid.nii.gz ste.nii.gz dream_file.nii.gz
```

Usar `QUIT` para hacer B1map es muy sencillo:

![](images/2025-02-25-09-45-52.png)

El ángulo nominal que nos pide lo podemos sacar con `brkraw` (si vemos la figura de arriba, notaremos que el _flip angle_ es 15).

Entonces, el comando queda:

```bash
qi dream dream_file.nii.gz --out=prefixdream --order=f -a 15
```

Esto es rapidísimo, y el resultado son dos archivos:

![](images/2025-02-25-09-49-48.png)# CUDA en Don Clusterio

CUDA es un sistema de procesamiento masivamente paralelo desarrollado por NVIDIA que se lleva a cabo en la tarjeta gráfica (GPU). Hace muchos procesos brutalmente más rápidos. No todo puede ser programado en CUDA, pero ciertas cosas lo aprovechan muchísimo, sobre todo las cosas de machine learning, y el programa eddy de fsl.

En Ubuntu 22.04 el default es instalar la versión 11 de CUDA, pero a fsl le gusta la versión 9.1. Para configurar la versión 9.1 usamos el siguiente comando:

```bash=
source /home/inb/lconcha/fmrilab_software/tools/inb_config_cuda9.sh
```

En realidad, lo único que hace ese script es revisar si CUDA 9.1 está instalado, y si sí, agregarlo al `LD_LIBRARY_PATH`.

Tienes duda si ya quedó? Usa el siguiente comando:

```bash=
inb_test_eddy_cuda.sh
```

:warning: No todas las PCs tienen GPU Nvidia, por lo que no todas las máquinas corren CUDA. Si vas a estar haciendo cosas en GPU, primero fíjate si puedes usarlo. 


:information_source: Update 25 de agosto 2022:
Existe una cola en SGE llamada `nvidia.q` que está configurada para ser usada a través de `fsl_sub` de fsl 6.0.2 o 6.0.5. Para mandar muchos jobs con programas que aprovechan CUDA, se puede usar:

    fsl_sub -q nvidia.q mi_script_que_usa_cuda.sh
**Lo que sigue aplica únicamente a las computadoras del laboratorio C13 y las de la Dra. García-Gomar (ENES-J).** Los usuarios de otros laboratorios son responsables de sus propios respaldos. Platiquen con su jefe/jefa sobre opciones.


# Respaldos del laboratorio C13 y ENES-J
Los respaldos de las **carpetas dentro de `/misc`** se realizan periodicamente, preferentemente en horarios que no coincidan con el uso del clúster.

:warning:  En el respaldo se exceptúan los datos  que se encuentran en la carpeta `tmp`, los archivos en la carpeta `Virtual Box` y los archivos contenidos en carpeta con nombre `nobackup`, `TMP*`, `tmp*`, `pruebas*`, `PRUEBAS*`, `Pruebas*` o `temporal*`. Tampoco se respalda `Dropbox`.

# Revisa tus respaldos!
Es importante que periódicamente revises que tus respaldos sí se estén haciendo. Localiza algún archivo que hayas generado la semana pasada, por ejemplo, y búscalo en los respaldos.

# Dónde están los respaldos
Para ver los respaldos, debes hacer `ssh` a la computadora `tesla` con tu nombre de usuario (no sabes ssh? pícale [aquí](./SSh). Una vez en `tesla`, encontrarás los respaldos de `/misc` en la carpeta `/bak.misc`. Dentro de ella, verás diferentes versiones temporales de los respaldos (los últimos 3 días, uno para la semana pasada, y uno para cada uno de los dos meses anteriores). Mira un ejemplo:

![image](https://github.com/user-attachments/assets/470d1e73-f53a-40cc-8895-949e1ba6c592)

:information_source: Los datos de cada PC se guardan en una carpeta que tiene su nombre. Por ejemplo, `/misc/mansfield` está en las carpetas `/bak.misc/mansfield-*`. Por lo tanto, no esperes encontrar (por ejemplo) datos que estaban en `/misc/carr` dentro de `/bak.misc/lauterbur-*`. Mira un ejemplo:

![image](https://github.com/user-attachments/assets/0ee93893-d1ea-4a76-b4af-3425680ae023)


:warning: La primera vez que navegas por las carpetas de `/bak.misc` habrá un rezago (se tarda), porque el sistema debe armar el árbol de directorios. Espera alrededor de un minuto antes de espantarte de que no funciona. Las siguientes llamadas a `ls` serán más ágiles.

:question: Qué pasa si no veo los respaldos? Lo más seguro es que el sistema está "desmontado". Esto sucederá después de apagones del cluster. No te desesperes. Avísale a Luis. Si estás segura/o que tu disco no se está respaldando, avísale a Luis, que seguramente olvidó agregarlo a la lista de discos a respaldar.

:hourglass_flowing_sand: Todo lo relacionado a los respaldos es lento, debes ser paciente. Recuerda que estamos respaldando cerca de 100 TB que deben comprimirse y de-duplicarse para caber en nuestros sistemas Synology. Esto se hace gracias al maravilloso [`borg`](https://www.borgbackup.org/), que de verdad que sí es maravilloso, pero no rápido.

# Datos antiguos

Para los datos que fueron procesados con mucha aterioridad y no estén actualmente en uso, es recomendable que se compriman y le avises a Luis para poder ser removidos de los discos que están activos en el clúster. Luis tiene discos viejos con datos de ex-alumnos. Si los necesitas, avísale.

# Agilizando tu experiencia de usuario en Don Clusterio.

Si siempre usas la misma PC para trabajar gráficamente en Don Clusterio, este tutorial es para tí. Prepárate para acelerar todo tu entorno gráfico, y notarás que tu sesión en google-chrome o firefox vuelan, y que navegas más rápido las carpetas en el navegador de archivos. Es en serio, la experiencia es noche y día.

:zap:  Este tutorial no afecta ni beneficia las sesiones remotas, y solamente agiliza tu experiencia en la computadora donde siempre te sientas. Si eres nómada en el laboratorio, entonces deja ésto pasar.

## Descripción del problema
Cada usuario en linux tiene una carpeta `$HOME`, donde se guardan archivos de configuración, historial, etc. En el caso de sesiones gráficas, ahí también se graban tu cache e historial de navegadores de internet, navegadores de archivos, archivos temporales de libreoffice, etc. Debido a que en Don Clusterio tu `$HOME` está físicamente albergado en el servidor, todo el tráfico de google chrome, firefox, y demás, tiene que cruzar a través de la red desde tu computadora hacia el servidor. Esto sucede cientos de veces por segundo, por lo que la experiencia del usuario se va degradando.

Afortunadamente, es posible mover tus carpetas de cache a un disco local y así evitar tanto tráfico de red. Aunque hace mucho esto lo hacíamos con links simbólicos, es posible hacerlo de manera muy formal siguiendo las especificaciones del X Desktop Group (XDG). Si te sientes geek o quieres aprender, checa [este link](https://specifications.freedesktop.org/basedir-spec/latest/index.html). Si hoy no te sientes particularmente geek, baste decir que solo vamos a mover el cache y el config hacia un disco local. El resto de configuraciones se quedan en tu `$HOME` para que todo siga funcionando como siempre.

## Instrucciones

### Revisando disco

Antes de empezar, tenemos que asegurarnos que tenemos un disco duro local hacia dónde copiar nuestros archivos de cache y configuración. Casi todas las PCs de Don Clusterio tienen un disco montado en `/misc/NOMBRE_DE_LA_PC`. Si no lo tiene, este tutorial no te servirá, y pídele a la persona responsable de tu laboratorio que te compre un disco duro. 

:eye:  Como ejemplo, vamos a usar el usuario `nickcave`, que quiere cambiar su cache/config a la computadora `larmor`.

Revisamos si hay disco duro usando `df -hl` y vemos qué hay montado en `/misc`. En este ejemplo, vemos que sí existe `/misc/larmor`.

![image](https://github.com/user-attachments/assets/6317523a-9ad2-41fa-8543-f018657a553d)

Entonces, creamos un fólder en ese disco. Recuerda que si escribes en algún lugar en `/misc`, debes hacerlo dentro de una carpeta con tu nombre de usuario. [Checa acá si ya se te olvidó](https://github.com/c13inb/c13inb.github.io/wiki/Cl%C3%BAster:-Folder-almacenamiento-(misc)). **Asegúrate que existan al menos 20 GB libres en ese disco.**

Entonces, el usuario `nickcave` hace una carpeta llamada `/misc/larmor/nickcave/` (si ya existe, pues no la crea).

## Copiando cache y config

Usa el script `inb_config_XDG.sh`. Se le debe dar un argumento, que es la carpeta donde vamos a copiar nuestro cache/config. Para hacer la vida fácil, **nombra la carpeta como `XDG`**. En nuestro ejemplo:

![image](https://github.com/user-attachments/assets/b229f53e-97eb-46c9-b1ff-4b89bac27ca6)

:eye: Fíjate cómo el usuario `nickcave` está trabajando en `larmor`, misma máquina donde está el disco `/misc/larmor`. No andes haciendo ésto desde otra máquina o se va a tardar mucho porque estarás enviando todo a través de la red innecesariamente.

El script `inb_config_XDG.sh` copiará tus archivos y preparará dos archivos nuevos: `~/.profile` y `~/.pam_environment`. Cuánto se tarde en copiar dependerá de cuánto tienes en tu cache de firefox y google-chrome, por lo que se recomienda borrar tu caché previo a este paso (revisa cómo hacerlo en [chrome](https://support.google.com/accounts/answer/32050?hl=es-419&co=GENIE.Platform%3DDesktop) y [firefox](https://support.mozilla.org/es/kb/limpia-la-cache-y-elimina-los-archivos-temporales-)). Verás muchos archivos siendo copiados pasar por la terminal, pero al final verás:

![image](https://github.com/user-attachments/assets/6deb8a49-9aad-4be0-b7a6-759fcb996d90)

Y como siempre obedecemos las instrucciones, cerramos la sesión completamente (logout). Al volver a entrar (suponiendo que estás en la máquina que estamos agilizando), toooodo será mucho más rápido. **Disfruta tu nueva experiencia de usuario**.

## Consideraciones importantes
Para que el archivo `~/.profile` corra, **no deben existir `~/.bash_login` ni `~/.bash_profile`**. Si los tienes y les habías puesto cosas de configuración, pasa su contenido a `~/.bashrc` y reinicia tu sesión.


## Y qué onda con la terminal.
Nada, no pasa nada. Todo sigue como si no hubiéramos cambiado la configuración. Pero en `~/.profile` se quedaron unas líneas que revisan que todo esté bien, que serán útiles en caso de algún desperfecto. El aviso será como este:
![image](https://github.com/user-attachments/assets/8aad24a2-062c-494d-9773-50862aea4411)

Como puedes ver, con todo y aviso de errores, la terminal se puede usar. Es solo el login gráfico el que se verá afectado (ver Troubleshooting).

## Troubleshooting
El problema principal que puede tener todo ésto es que la PC donde está el disco que alberga tu carpeta `XDG` esté fuera de línea. Por ejemplo, que esté apagada o desconectada de la red. Esto hará que si haces login gráfico en otra PC, tu sesión te dará un error relacionado a XDG y te invitará a corregirlo lo más pronto posible. No panic. Puedes cerrar ese aviso, y usar tu sesión. Eso sí, estará lentita y no estará actualizado tu historial de navegación de internet, etc. Así que si esto sucede, avisa qué máquina está caída y le daremos su revisada.

## Revirtiendo los efectos
No puede ser más fácil: borra el archivo `~/.pam_environment` y reinicia tu sesión. Si quieres que se respete tu historial de navegación en internet, sincroniza las carpetas que tenías en tu `XDG` con los equivalentes dentro de tu `$HOME`. Si ya te animaste a hacer esto, es que sabes lo que estás haciendo, solo recordar que el default de esas carpetas están definidas en  [este link](https://specifications.freedesktop.org/basedir-spec/latest/index.html).






El término clúster (del inglés cluster, "grupo" o "racimo") se aplica a los conjuntos o conglomerados de computadoras construidos mediante la utilización de hardwares comunes y que se comportan como si fuesen una única computadora.

**El clúster de cómputo del INB se llama `Don Clusterio`.**


# Cambio de contraseña (password):
Cada usuario puede cambiar su contraseña, y es recomendable hacerlo con cierta periodicidad. Utiliza una contraseña fuerte, que use letras mayúsculas y minúsculas, números y caracteres especiales. 

Para cambiar tu contraseña, usa el comando `yppasswd`.

:information_source: Hay un periodo de aproximadamente 5 min para que tu nueva contraseña se propague a todas las computadoras del cluster.

## Organización de datos en el clúster

La más importante a conocer acerca de como guardar tus datos usando tu usuario en el clúster:
+ Folder del usuario [/home](./Clúster:-Folder-usuario-(home))
+ Folder de almacenamiento [/misc](./Clúster:-Folder-almacenamiento-(misc))
+ Folder temporal [/tmp](./Clúster:-Folder-temporal-(tmp))

## Respaldo de datos

En la entrada [Respaldo de datos](./Clúster:-Respaldo-de-datos) podemos encontrar en qué consiste el respaldo de datos que se realizan al clúster, dónde se guardan y cómo nombrar a mis datos para que se respalden.

## Comandos básicos del clúster

En la entrada  [Gestión de procesos](./Bash:-Gestión-de-procesos) encontramos los principales comandos para monitorear los trabajos, eliminar trabajos con error y para revisar la carga del clúster.

## Módulos

Los módulos es una forma de cargar los softwares a tu sesión de manera fácil y sin conflictos entre versiones. Checa a detalle como activarlos en la entrada de [Módulos](https://github.com/c13inb/c13inb.github.io/wiki/Modules).


## Uso del clúster

En la entrada [Uso del clúster](./Clúster:-Uso-del-clúster) podemos encontrar ejemplos para hacer ejecuciones en el clúster.

## Errores del clúster

Aquí se encuentran los principales [Errores del clúster](./Clúster:-Errores-del-clúster) cuando los jobs no corren.


![](https://github.com/c13inb/c13inb.github.io/blob/master/images/donClusterio_01.png)

Este es Don Clusterio. Es nuestro amigo. Es el gurú del cluster hippie del INB. Un cluster sin sysadmin, basado en el respeto y cariño entre sus integrantes. Un lugar donde todos ayudan para que las PCs estén prendidas, donde los usuarios se dan consejos entre todas y todos. Un lugar donde nadie escribe datos en su HOME. Donde son cuidadosos con sus respaldos, y donde nadie se agandalla all.q. Un hermoso lugar donde el conocimiento se vierte sobre la wiki. Vemos aquí a Don Clusterio sonriendo mientras revisa los logs de acceso remoto, satisfecho por no ver sesiones de x2go colgadas desde hace más de tres días. Larga vida a Don Clusterio.
# El software de Don Clusterio.

Lista de software instalado en Don Clusterio orientado a neuroimagen, ciencia y utilidades en Linux. 
* El manejador de jobs de Don Clusterio es gracias a SGE ([Some Grid Engine](https://github.com/daimh/sge)).
* Algunos de estos paquetes se instalaron con [`deb-get`](https://github.com/wimpysworld/deb-get). ¡Es la onda!.

## Academy/office software
| Package Name   | Description   |
| :------------- | :------------ |
| [`Mrtrix`](https://www.mrtrix.org/) | <i>Tools to perform diffusion MRI analyses</i> |
| [`mrview`](https://mrtrix.readthedocs.io/en/latest/reference/commands/mrview.html) | <i>Mrtrix MRI viewer.</i> |
| [`fsl`](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki) | <i>Library of analysis tools for FMRI, MRI and DTI. </i> |
| [`fsleyes`](https://open.win.ox.ac.uk/pages/fsl/fsleyes/fsleyes/userdoc/) | <i>FSL MRI viewer.</i> |
| [`freesurfer`](https://surfer.nmr.mgh.harvard.edu/) | <i>Neuroimaging toolkit for processing, analyzing, and visualizing human brain MRI</i> |
| [`Afni`](https://afni.nimh.nih.gov/) | <i> Analysis and display of multiple MRI modalities (FMRI, MRI and DTI). </i> |
| [`MRIcroGL`](https://www.nitrc.org/projects/mricrogl) | <i>MRI viewer.</i> |
| [`DSI studio`](https://dsi-studio.labsolver.org/) | <i>Tractography software tool</i> |
|  | |
| [`Matlab`](https://www.mathworks.com/products/matlab.html) | <i>Programming language that expresses matrix and array mathematics directly.</i> |
| [`rstudio`](https://www.rstudio.com/) | <i>Professional software for data science teams.</i> |
| [`VScode`](https://code.visualstudio.com/) | <i>Code editing. Redefined.</i> |
| [`Singularity`](https://docs.sylabs.io/guides/3.5/user-guide/introduction.html) | <i>Container platform</i> |
| [`gitkraken`](https://www.gitkraken.com/) | <i>Intuitive Git GUI & powerful Git CLI.</i> |
|  | |
| [`Onlyoffice`](https://www.onlyoffice.com/en/desktop.aspx) | <i>Free desktop office suite for document editing and collaboration.</i> |
| [`Sejda`](https://www.sejda.com/) | <i>Easy, pleasant and productive PDF editor.</i> |
| [`parcellite`](http://parcellite.sourceforge.net/) | <i>Clipboard manager.</i> |
| [`zotero`](https://www.zotero.org/) | <i>A free, easy-to-use tool to help you collect, organize, cite, and share research.</i> |
| [`inkscape`](https://inkscape.org/) | <i>Draw and create vector graphics.</i> |
|  | |
| [`rocketchat`](https://rocket.chat/) | <i>Official Desktop Client for Rocket.Chat.</i> |
| [`zoom`](https://zoom.us/) | <i>Video Conferencing, Cloud Phone, Webinars, Chat, Virtual Events.</i> |

Nota: El python default en el cluster es python3 que trae matplotlib y numpy instalados. Si requieres tus propios ambientes te recomendamos revisar [Anaconda](./Anaconda).




## GUI software
| Package Name   | Description   |
| :------------- | :------------ |
| [`Brave`](https://brave.com/) | <i>Browse privately. Search privately. And ditch Big Tech.</i> |
| [`Google chrome`](https://www.google.com/chrome/) | <i>Fast, Secure Browser from Google.</i> |
|  | |
| [`bitwarden`](https://bitwarden.com/) | <i>Open Source Password Manager.</i> |
| [`keepassxc`](https://keepassxc.org/) | <i>Cross-Platform Password Manager.</i> |
|  | |
| [`shutter`](https://shutter-project.org/) | <i>Screenshot program.</i> |
| [`x2go`](https://wiki.x2go.org/doku.php) | <i>Access a graphical desktop via web.</i> |
| [`vlc`](https://www.videolan.org/vlc/) | <i>Plays most multimedia files</i> |



## CLI softare
| Package Name   | Description   |
| :------------- | :------------ |
| [`xterm`](https://invisible-island.net/xterm/) | <i>Old school terminal emulator.</i> |
| [`tilix`](https://gnunn1.github.io/tilix-web/) | <i>Terminal emulator with tabs.</i> |
| [`terminator`](https://gnome-terminator.org/) | <i>Terminal emulator with tabs and broadcast.</i> |
| [`Byoubu`](https://www.byobu.org/) | <i>Window manager and terminal multiplexer.</i> |
|  | |
| [`bat`](https://github.com/sharkdp/bat) | <i>A 'cat' clone with wings.</i> |
| [`duf`](https://github.com/muesli/duf) | <i>Disk Usage/Free Utility - a better 'df' alternative.</i> |
| [`fd`](https://github.com/sharkdp/fd) | <i>A simple, fast and user-friendly alternative to 'find'.</i> |
| [`lsd`](https://github.com/Peltoche/lsd) | <i>The next gen 'ls' command.</i> |
|  | |
| [`micro`](https://micro-editor.github.io/) | <i>A modern and intuitive terminal-based text editor.</i> |
| [`vim`](https://www.vim.org/) | <i>Highly configurable text editor.</i> |
|  | |
| [`rclone`](https://rclone.org/) | <i>Syncs your files to cloud storage.</i> |
| [`ssh`](https://www.openssh.com/) | <i>Connectivity tool for remote login.</i> |
| [`wget`](https://www.gnu.org/software/wget/?) | <i>Package for retrieving files using HTTP, HTTPS, FTP and FTPS.</i> |
|  | |
| [`htop`](https://htop.dev/) | <i> Interactive process viewer.</i> |
| [`nvtop`](https://github.com/Syllo/nvtop) | <i>A (h)top like task monitor for AMD and NVIDIA GPUs.</i> |
|  | |
| [`pandoc`](https://pandoc.org/) | <i>A universal document converter.</i> |
| [`imagemagick`](https://imagemagick.org/index.php) | <i>Create, edit, compose, or convert digital images.</i> |
|  | |
| [`git`](https://git-scm.com/) | <i>Distributed version control system.</i> |
| [`tree`](https://github.com/Old-Man-Programmer/tree) | <i>Utility to display a tree view of directories.</i> |
| [`parallel`](https://www.gnu.org/software/parallel/) | <i>Tool for executing jobs in parallel.</i> |

## Pendientes de instalar
| Package Name   | Description   |
| :------------- | :------------ |
| [`ants`](http://stnava.github.io/ANTs/) | <i>Advanced Normalization Tools</i> |
| [`itk-snap`](http://www.itksnap.org/pmwiki/pmwiki.php) | <i>Software application used to segment structures in 3D medical images.</i> |
| [`Fiji`](https://fiji.sc/) | <i>ImajeJ with many useful plugins</i> |



En esta página se describen los errores clásicos del cluster.

## Cómo saber que hubo un error
Supongamos que acabamos de mandar un job, ya sea con `fsl_sub` o a través de alguna interface gráfica, como por ejemplo Feat. La pregunta es: está corriendo mi job? La respuesta es fácil de encontrar:

  qstat

Nos regresa algo como lo siguiente:

```{bash}
job-ID  prior   name       user         state submit/start at     queue                          slots ja-task-ID
-----------------------------------------------------------------------------------------------------------------
   4008 0.29506 feat5_stop federica     Eqw   08/18/2014 14:22:16                                    1        
   3308 0.00000 feat3_film federica     hqw   08/14/2014 12:17:19
   3973 0.00000 feat5_stop federica       r   08/18/2014 14:16:12                                    1        
```

Revisemos lo que significa: `job-ID` es el *ticket* que tiene nuestro trabajo en la cola. `prior` es la prioridad del trabajo, que la asigna el propio sistema del cluster. `name` es el nombre del trabajo (recuerda que con `fsl_sub -N <nombre>` puedes asignarlo. En caso de interfaces gráficas como Feat, el mismo programa se encarga de darle nombre. `user` es el dueño del job, y al final tenemos `submit/start at`, que nos dice cuando mandamos el job y cuándo empezó a ejecutar. Ahora, el más importante es `state`. En este ejemplo tenemos tres diferentes estados:

  * `Eqw`. Significa que hubo un error. Este job no va a ejecutarse hasta que se solucione el problema que causó el error.
  * `hqw`.  Este job tiene un //hold//, es decir, que no va a correr sino hasta que un job, probablemente un pre-requisito para este job, termine. Por ejemplo, los post-stats de Feat no pueden correr si no ha corrido stats. Este no es un error.
  * `r`. Este job está corriendo.

Para saber qué pasó con un job en estado `Eqw`, podemos ejecutar:

  qstat -j <job-id>

Por ejemplo, el job-id 4008 está en estado de error. Ejecutar `qstat -j 4008` regresa mucho texto, pero lo más importante está al final:

```{bash}
script_file:                /home/inb/lconcha/fmrilab_software/fsl_5.0.6/bin/feat
jid_predecessor_list (req):  4007
error reason    1:          08/18/2014 14:30:39 [1035:32278]: error: can't chdir to /datos/tournoux/federica/detanner/gaze/sujet
scheduling info:            queue instance "all.q@hahn.inb.unam.mx" dropped because it is disabled
                            queue instance "all.q@neurona.inb.unam.mx" dropped because it is disabled
                            queue instance "high.q@hahn.inb.unam.mx" dropped because it is disabled
                            queue instance "high.q@neurona.inb.unam.mx" dropped because it is disabled
                            queue instance "low.q@hahn.inb.unam.mx" dropped because it is disabled
                            queue instance "low.q@neurona.inb.unam.mx" dropped because it is disabled
                            Job is in error state

```

Aquí lo crucial es `error reason 1`, y `can chdir to /datos/tournoux…`. Esto significa que la carpeta donde tiene que escribir el script (en este caso feat), no está accesible. En efecto, este es el error más común, y hay dos razones para ésto.

La primer razón es causada por el usuario, al tratar de escribir en una carpeta no existente o en la que no tiene permisos de escritura. Esto sucede, por ejemplo, si el usuario `usuarioA`, en una terminal, está colocado en la carpeta `/home/inb/__usuarioX__`, en la cual, por defecto, no tiene permisos de escritura, y ahí ejecuta algún `fsl_sub`. Los logs que genera `fsl_sub` no podrán ser escritos en la carpeta actual. La solución es cambiar de carpeta.
`
La segunda razón es culpa del sistema de archivos NFS, que es el que permite que las computadoras compartan sus discos duros en la red de nuestro cluster.


Para diagnosticar este problema, ejecutamos el siguiente escript:

  inb_cluster_NFS_status_simple.sh


Un output de este escript es como:

```{bash}
--> arwen 	.. W ................. W ... W ..........OK
--> austin 	.. W ............... W ... W ... W .......OK
--> bloch 	.. W ............... W ... W ... W .......OK
--> cannabis 	... W ............... W ... W ..........OK
--> carr 	... W .............. W ... W ... W .......OK
--> charcot 	... W ................ W ... W ..........OK
--> claustrum 	... W ................ W ... W ..........OK
--> copula2 	... W .............. W ... W ... W .......OK
--> copula 	... W ............. W ... W ... W .......OK
--> ernst 	... W .............. W ... W ... W .......OK
--> evarts 	... W ................ W ... W ..........OK
--> fourier 	... W .............. W ... W ..........OK
--> giora 	... W .............. W ... W ... W .......OK
--> hahn 	... W .............. W ... W ... W .......OK
--> jasper 	... W ................ W ... W ..........OK
--> mansfield 	... W ............... W .. W ... W .......OK
--> mountcastle 	... W ................. W .. W ..........OK
--> penfield 	... W ................. W .. W ..........OK
--> purcell 	... W ............... W ... W .. W .......OK
--> rabi 	... W ................. W ... W .........OK
--> rhesus 	... W ............... W ... W .. W .......OK
--> sherrington 	... W ............... W ... W ... W .....OK
--> tanner 	... W ............... W ... W ... W .....OK
--> torrey 	... W ................ W ... W ... W .......OK
--> tournoux 	... W ................. W ... W ........OK

  Note: [W] means a whitelisted or disabled mount point (not an error).

    Whitelisted node(s)/mount(s): lauterbur sesamo drobo bruker pruebas

  whitelist file is /home/inb/lconcha/fmrilab_software/tools/inb_cluster_whiteList.txt


```

Vemos cómo el script pasa por todas las computadoras y revisa que cada uno de los sistemas de archivos estén bien montados en /datos. Si todo está bien, la computadora marca `OK`. Todo lo demás indica errores. En este caso, `lauterbur` no tiene montados los `homes`, así que ningún script va a correr en lauterbur. En otros casos este script nos dirá que algún directorio `/misc` está mal montado.  Vemos también que `Rhesus` no está prendida. Afortunadamente, el cluster deshabilita a las computadoras caídas para que no les lleguen jobs, así que esto no debe ser un problema mayor. Si aparece `W` en vez de `.` significa que ese nodo está deshabilitado a propósito por alguna razón, y por lo tanto se puso en la _lista blanca_ (whitelist), y el no encontrarlo no es un error.

En caso de que este script marque errores, *el usuario no puede corregir el problema* así que se recomienda comunicarse con el administrador del sistema (Luis, o Leopoldo, por ahora).
En principio en la carpeta __/misc__ , que se encuentra en la raíz de todos los equipos, se encuentran carpetas con los nombres de los equipos y por lo tanto con acceso a cada uno de ellos.

Por ejemplo, la carpeta __/misc/tanner__ se encuentra físicamente en el equipo __tanner__, pero se encuentra disponible desde cualquier equipo que forme parte del clúster.

Dentro de estas carpetas se encuentran directorios que pertenecen a los usuarios designados a usar ese espacio del equipo.

Es muy importante que los usuarios graben sus datos a procesar y sus resultados en alguna carpeta dentro de __/misc__ utilizando la siguiente nomenclatura:

       /misc/__host__/__usuario__

dónde __host__ es el nombre de la máquina que físicamente tiene el disco duro. Se recomienda que sea la que normalmente se usa físicamente. Ejemplos son: tournoux, fourier, tanner, etc. Nombrando la carpeta __usuario__ facilitamos la tarea de saber cuántos datos tiene cada persona en el cluster.

> Por favor, solo se puede utilizar la carpeta `/misc` en el equipo que se te ha asignado. Si por alguna razón el disco esta lleno. Es posible usar temporalmente otro equipo, mientras que se reporta el problema al administrador del sistema.



## Crear una carpeta

Una vez que cuenten con Usuario/Contraseña podrán crear sólo una carpeta en el equipo asignado si cuentan con los permisos necesarios, el procedimiento es el siguiente:

       mkdir /misc/nombre_del_equipo/tu_usuario

### Carpeta nobackup

Si existen archivos muy grandes que no requieran de respaldo, es recomedable crear una carpeta dentro de su carpeta /misc con el nombre *nobackup*. Esta carpeta podrá ser vista por el resto del folder pero no se realizará backup de ella, facilitando la carga de trabajo del clúster en general.

## Disponibilidad de datos en el clúster

Ya que el trabajo en el clúster requiere que los datos se encuentre accesibles para cualquier equipo que pueda llevar a cabo la tarea en cuestión. Los datos deben ser colocados en carpetas que se monten en todos los equipos.  

Para saber cuánto espacio libre hay en  los discos, basta con abrir una terminal y escribir:

```
df -h
```

Un ememplo de output:

```
Filesystem      Size  Used Avail Use% Mounted on
udev             12G     0   12G   0% /dev
tmpfs           2.4G  2.2M  2.4G   1% /run
/dev/sda2        46G   39G  4.7G  90% /
tmpfs            12G   92M   12G   1% /dev/shm
tmpfs           5.0M  4.0K  5.0M   1% /run/lock
tmpfs            12G     0   12G   0% /sys/fs/cgroup
/dev/loop0       18M   18M     0 100% /snap/chromium-ffmpeg/9
/dev/loop2       15M   15M     0 100% /snap/gnome-logs/43
/dev/sda1        48M  6.1M   42M  13% /boot/efi
/dev/sda3        71G   54M   68G   1% /tmp
/dev/sdb2       1.8T  1.4T  351G  80% /datos/disco2
/dev/sdc5       3.6T  2.5T 1013G  71% /misc/mansfield
tmpfs           2.4G   16K  2.4G   1% /run/user/121
tmpfs           2.4G  236K  2.4G   1% /run/user/1000
/dev/sdd1       917G  777G   95G  90% /media/lconcha/CONCHA_WD
/dev/sdh1        30G   17G   12G  58% /media/lconcha/myswap
```
Vemos que en `/misc/mansfield` Me quedan 1016G (GB).
Si quieres hacer pruebas que no requieran del clúster, puedes hacer carpetas dentro de  `/tmp`, que vive físicamente en la computadora que estás usando. Ojo: Esta carpeta *no se exporta* al clúster, por lo que no podrás hacer uso de ningún comando de cluster con datos aquí, y si lo haces, vas a tener uno de tus jobs con status de [errores del cluster](./Cluster:-Errores-del-cluster)...

La otra opción es usar la carpetas que no se respaldan en el cluster, que son visibles por todo el cluster pero no se les hacen [respaldo](./Cluster:-Respaldo-de-datos). Simple: nombra a tu carpeta `temporal`, `tmp`, o `nobackup` adentro de `misc`, por ejemplo `/misc/mansfield/lconcha/nobackup/mispruebas`.

Por favor, borra tus archivos una vez que hayas terminado de hacer tus pruebas.
## ¿Qué es el Home?

El home es un espacio que pertenece a cada usuario, es el lugar dónde nos encontramos al iniciar sesión. Suele tener permisos de __escritura/lectura__ exclusivos para el usuario al que pertenece. También aquí suelen residir los archivos de configuración exclusivos para el usuario.

## ¿Dónde está?

En la estructura de los sistemas **Unix** suelen encontrarse en la dirección

     /home/usuario

Pero en el clúster del laboratorio, la ruta correcta es:

    /home/inb/usuario

Donde usuario es sustituido por el usuario en curso. Se puede acceder mediante:

#### Ruta absoluta

     cd /home/inb/usuario

#### Ruta con "wildcard" (comodín)

    cd ~/

#### También nos podemos trasladar usando el comando cd sin argumentos

    cd

O sea, los tres formatos del comando **cd** tienen la misma función.

En el caso de los equipos que forma parte del clúster, el directorio home se encuentra físicamente en el servidor central.




## Y ¿qué debo escribir?

Es importate señalar, que debido a la configuración de [respaldo](./Cluster:-Respaldo-de-datos) y [almacenamiento](./Cluster:-Folder-almacenamiento-(misc)) del clúster, es recomendable que en la carpeta home no se coloquen archivos de gran tamaño, dando preferencía a archivos como scripts, archivos de configuración, documentos. En el caso de requrir guardar archivos que se consideren grandes y que no se deseen respaldar se puede recurrir al uso de la carpeta [temporal](./Cluster:-Folder-temporal-(tmp)) o una carpeta con el título nobackup (revisar [almacenamiento](./Cluster:-Folder-almacenamiento-(misc))).

## Qué otras cosas hay en `$HOME`?
En esa carpeta suelen vivir todos los archivos de configuración y cache del usuario. Ojo, que ésto puede llegar a crecer mucho, sobre todo por el cache de google-chrome. Se recomienda vaciar el cache del navegador cada par de meses para evitar tener demasiados archivos.

### Moviendo las configuraciones y cache de `$HOME`
Dado que `$HOME` está en una carpeta que físicamente reside en el servidor, cada vez que se consulta un archivo de configuración, la información debe viajar a través de la red local. Aunque la mayoría de las veces esto es muy rápido, algunos usuarios han decidido cambiar el lugar donde residen físicamente tales archivos de configuración, para que estén en una carpeta de un disco duro local en la PC que habitualmente utilizan. **Los usuarios que siempre se conectan remotamente, entonces, no tienen ningún beneficio de lo que se explica a continuación.**

En distribuciones modernas de linux (como ubuntu), la carpeta de configuración se define dentro de las variables de entorno que comienzan con `$XDG_`. Si te gustaría saber más al respecto, lee las especificaciones [aquí](https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html). 

Usa el script `inb_config_XDG.sh` para mover tus carpetas de configuración a un disco duro local. 

:information_source: [CHECA AQUÍ UN TUTORIAL](./Cluster:XDG) :smile: 


```
Uso: inb_config_XDG.sh </misc/DISCO/USUARIO/newXDG>

Donde newXDG representa una carpeta en un lugar de /misc donde tienes permisos de escritura.
Se recomienda que la carpeta se llame XDG, por ejemplo /misc/mansfield/lconcha/XDG
```

:warning: El inconveniente de mover tus configuraciones y cache, es que si no está disponible la PC donde está el disco duro que contiene tus carpetas XDG, tus sesiones remotas tendrán problemas. Claro, esto también sucede si tu XDG está en el servidor, pero si el servidor se cae, estamos frente a un problema mayor que afecta a todos los usuarios, no solo a tí, y muy seguramente será atendido a la brevedad. Por lo tanto, valora conveniencia/velocidad/robustez antes de correr el script mencionado arriba. Buena suerte!



Las carpetas HOME de todos los usuarios se respaldan automáticamente todas las noches. Estos respaldos **no incluyen carpetas ocultas** (e.j. `.cache`).

LOS RESPALDOS DE DATOS SON RESPONSABILIDAD DE LOS USUARIOS, NO DE DON CLUSTERIO.

Los usuarios del laboratorio C13 y las de la Dra. García-Gomar (ENES-J) tienen un sistema especial de respaldos, documentado [aquí](./Cluster-Respaldo-C13_ENES). **Los usuarios de otros laboratorios son responsables de sus propios respaldos**. Platiquen con su jefe/jefa sobre opciones.
Como usuarios del clúster es necesario considerar varios factores para una
buena ejecución de los trabajos que enviamos. La localización de los [datos en
el clúster](https://github.com/rcruces/C-13_wiki_demo/wiki/Datos-Cluster) los [permisos](https://www.computernetworkingnotes.com/rhce-study-guide/linux-file-permission-explained-in-easy-language.html) y el estado de las
colas de ejecución del clúster.

## La manera más fácil de enviar un trabajo al cluster
Aunque la manera formal es utilizar [qsub](http://gridscheduler.sourceforge.net/htmlman/htmlman1/qsub.html), normalmente queremos que el comando que acabamos de escribir en la terminal se ejecute en el cluster, no en esta máquina. Para estos fines, nuestro amigo es `fsl_sub`. Para usarlo, simplemente lo anteponemos a cualquier comando a ejecutar, con todo y los argumentos propios del comando a ejecutar. De manera general:

```
fsl_sub <comando> [argumentos]
```


De esta forma, si queremos ejecutar el comando `ls` en el cluster, simplemente escribimos `fsl_sub ls`, y si quisieramos argumetos, pondríamos, por ejemplo, `fsl_sub ls -lart`.

`fsl_sub` tiene varias opciones que controlan en qué sistema de colas va a correr nuestro trabajo, la prioridad del mismo, e incluso nos permite utilizar un archivo lleno de jobs para mandar como un _arreglo_ al cluster. Quizás la opción más util es la de nombrar a nuestro job, que por defecto simplemente será bautizado con un aburrido número. Si hemos enviado a procesar los datos de 50 sujetos al cluster, por ejemplo, nos gustaría saber qué sujetos siguen en ejecución. Para ésto, usamos:


```
fsl_sub -N <nombreDelJob>
```


por ejemplo: `fsl_sub -N suj331 recon-all -all -subjid 331`.
El identificador `suj331` aparecerá en la lista de jobs cuando usemos
`qstat`. Ojo, pues los nombres de jobs no pueden iniciar con un número.

Un ejemplo veloz para mandar a procesar a 5 sujetos en freesurfer:

```
for suj in 301 302 303 304 305; do fsl_sub -N s${suj} recon-all -all -subjid $suj;done
```


en este ejemplo, cada job tiene la forma `recon-all -all -subjid $suj`,
donde `$suj` toma el valor de 301 a 305. Estudia la sintaxis de `fsl_sub`
y trata de entender cómo se le hizo.



## Por qué `fsl_sub`?

`fsl_sub` hace mucho más fácil enviar jobs al cluster. Simplemente se le antepone el comando a cualquier otro comando que hubiera corrido localmente. Si las carpetas input y output son visibles a través del cluster, el usuario no tiene nada más que hacer.

`fsl_sub` es parte de las herramientas de _fsl_. Es un _wrapper_ para el comando `qsub`, que es el que verdaderamente manda los jobs al cluster. Para más información del uso de `fsl_sub` consulta [aquí](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/SGE%20submission%20FAQ).

Si quieres aprender a utilizar `qsub` de verdad, consulta [acá](http://bioinformatics.mdc-berlin.de/intro2UnixandSGE/sun_grid_engine_for_beginners/how_to_submit_a_job_using_qsub.html). Ahí encontrarás el verdadero poder de `qsub`. Pero como dijo tío Ben: "Con gran poder viene gran responsabilidad".



## Controlando _multi-threaded jobs_

:warning: Algunos comandos se paralelizan _dentro_ de un CPU, usando una tecnología llamada multi-threading. Esto es **encima de la paralelización del cluster**. Los usuarios deben ser cuidadosos de al enviar jobs paralelizados al cluster. 

:information_source: Podemos usar `fsl_sub -s smp,$nthreads miscript.sh`, donde -s significa _ambiente paralelo_, y sus opciones son `smp` que así está bautizado el ambiente configurado en Don Clusterio, y `4` que es un ejemplo de cuantos threads quiere uno usar. El número de threads es distinto en cada PC, pero la gran mayoría tiene 7; solo las más nuevas como nyquist o geminis tienen 15 **Ejemplo:** `fsl_sub -s smp,7 tckgen -nthreads 7 -algorithm iFOD2 -seed_image mask.mif csd.mif tractos.tck`. Nótese como `-s smp,7` y `-nthreads 7` coinciden. Así, la PC a la que le caiga usará 7 de sus 7 slots en este job en particular, y no le puede caer otro job similar de manera simultánea. En una PC con 15 slots, le pueden caer dos de estos jobs sin problemas, y no se pone lenta.


## Una vez que enviaste tu job...

Para conocer el estado de las colas de ejecución se pueden usar los siguientes
comandos:

```
qstat -f
```
Permite ver los trabajos en una lista de hosts con los slot's en uso   
locales/clúster/disponibles.

```
qstat -u '*'
```
Permite ver todos los trabajos de todos los usuarios en ejecución


```
qstat
```
Sólo muestra los trabajos del usuario que lo ejecuta


```
qdel #
```
Permite borrar trabajos de la cola de ejecución, en este caso `#` se sustituye
por el número del trabajo que se quiere eliminar



```
qdel -u usuario
```
Borra todos los trabajos del usuario.




## Si los trabajos no corren
Por favor revisa la [página donde se explican los posibles errores](?id=errorescluster)


## Cómo no usar el clúster

Por defecto, algunas herramientas como `Feat` o `probtrack` utilizan el cluster. A veces no lo quieres usar.

Para correr trabajos de fsl en la máquina de manera local sin entrar al clúster
se puede usar los comandos:

```
unset FSLPARALLEL
unset SGE_ROOT
```
A partir de que se escribe esto en la terminal, el uso de programas se hará de forma local sin mandarlos al clúster. Sin embargo el equipo seguira formando parte del clúster. Cuando abras una nueva terminal se quitará este efecto mágico, y regresarás al *default de sí usar el cluster*.

## Matlab en paralelo con SGE

No es posible paralelizar funciones de matlab al estilo [matlab pool](https://la.mathworks.com/help/parallel-computing/parpool.html). Sin embargo, sí es posible paralelizar trabajos de matlab encapsulándolos en bash y mandándolos al cluster mediante SGE. [Sigue estas instrucciones para aprender cómo](matlabInSGE).
# Análisis De Correlación Basado En Semilla (Seed-Based Correlation Analysis)

En este tutorial aprenderás dos formas de hacer un seed-based correlation analysis (SCA) ya sea usando AFNI y FSL,o bien usando R. Como bien sabes el SCA es uno de los métodos más sencillos  de estimar la Conectividad funcional en el cual primero se extrae la serie temporal promedio de una región de interés y luego  se computa un mapa de correlación (pearson) de esa serie de tiempo con la del resto de los voxeles de la imagen funcional. 
***
**Para seguir este tutorial puedes usar los siguientes archivos:**

- **[NIFTI  4D preprocesado](https://drive.google.com/file/d/14Mx4MbFO2GjrMWvq4-CHX3HHbiN_A3jh/view?usp=sharing)** (pronto existirá una sección sobre preprocesamiento de datos de  resting state)
![](https://github.com/alffajardo/mri_data/blob/master/tutorials/sca/func.gif)

- **[ NIFTI ROI binario](/home/alfonso/Desktop/pcc_mask.nii.gz)** (Consula como hacer un ROI binario [aquí](https://www.youtube.com/watch?v=fIu4tUjRfUE&t=145s))

  ![](https://github.com/alffajardo/mri_data/blob/master/tutorials/sca/pcc_mask.png)

**Nota importante:** Aunque quizás parezca obvio, no está de más decir que tu NIFTI 4D y tu ROI deben tener las mismas dimensiones x y z y estar en el mismo espacio. En este caso ambas imágenes ya se encuentran en el espacio del atlas MNI152.

## OPCIÓN 1: USANDO FSL Y AFNI  DESDE LA TERMINAL

  para mayores facilidades puedes descargar el script **[rmap_afni.sh](https://github.com/alffajardo/mri_data/blob/master/tutorials/sca/rmap_afni.sh)**. Una vez que le hayas dado permisos de ejecución al archivo simplemente necesitas correrlo de la siguiente manera:

  ```
rmap_afni.sh <archivo NIFTI preprocesado> < ROI binario> <nombre del output>
  ```
  
  ejemplo: 

  ```
./rmap_afni.sh sub-001_bandassed_denoised_warp_FWHM4.nii.gz pcc_mask.nii.gz sub-001_pcc
  ```

  **A continuación explicaremos en detalle que es lo que hace este script:**
  
  1.  Extraer la serie de tiempo promedio de tu funcional usando el ROI:
  
  ```fslmeants -i sub-001_bandassed_denoised_warp_FWHM4.nii.gz -m pcc_mask.nii.gz -o pcc.ts```
  
Si realizaste bien este paso, al intrducir en la terminal el comando `head pcc.ts`  deberías ver lo siguiente:

   ```
-3.744489014 
    1.972393204 
    10.74178089 
    14.54784234 
    8.430280266
   -5.448772119 
   -19.30749452 
   -25.47799781 
   -21.67057823 
   -11.75656644
``` 
    

2. Obtener el mapa de correlación con AFNI
  
```3dTcorr1D -prefix sub-001_pcc_corrmap.nii.gz sub-001_bandassed_denoised_warp_FWHM4.nii.gz pcc.ts```

Puedes visualizar el mapa de correlación con el visor de tu preferencia. para visualizarlo con fsleyes escribe:

```fsleyes -std sub-001_pcc_corrmap.nii.gz -dr 0.3 0.8   -cm red-yellow```

**Si hiciste todo bien deberías ver algo como en la siguiente imagen:**

![](https://github.com/alffajardo/mri_data/blob/master/tutorials/sca/sub-001_pcc_corrmap.png)

#### Como podrás observar hemos obtenido un patrón muy conocido en la literatura. ¡¡Así es!! ¡¡Se trata de la ***Default Mode Network***!! 

# Seed-Based Correlation Analysis

En este tutorial aprenderás dos formas de hacer un seed-based correlation analysis (SCA) ya sea a usando AFNI y FSL  o usando R. Como bien sabes el SCA es uno de los métodos más sencillos  de estimar la Conectividad funcional en el cual primero se extrae la serie temporal promedio de una región de interés y luego  se computa un mapa de correlación (pearson) de esa serie de tiempo con la del resto de los voxeles de la imagen funcional. 

**Para seguir este tutorial puedes usar los siguientes archivos:**

- ###### [NIFTI  4D preprocesado](https://drive.google.com/file/d/14Mx4MbFO2GjrMWvq4-CHX3HHbiN_A3jh/view?usp=sharing) (pronto existirá una sección sobre preprocesamiento de datos de  resting state)

  ![](https://github.com/alffajardo/mri_data/blob/master/tutorials/sca/func.gif)

- **[ NIFTI ROI binario](https://github.com/alffajardo/mri_data/blob/master/tutorials/sca/pcc_mask.nii.gz)** (Consulta como hacer un ROI binario [aquí](https://www.youtube.com/watch?v=p70utwa-NkU&t=51s))

  ![](https://github.com/alffajardo/mri_data/blob/master/tutorials/sca/pcc_mask.png)

  

 **Nota importante:** Aunque quizás parezca obvio, no está de más decir que tu NIFTI 4D y tu ROI deben tener las mismas dimensiones x y z y estar en el mismo espacio. En este caso ambas imágenes ya se encuentran en el espacio del atlas MNI152

  
  
## OPCIÓN 1: USANDO FSL Y AFNI  DESDE LA TERMINAL

  para mayores facilidades puedes descargar el script **[rmap_afni.sh](https://github.com/alffajardo/mri_data/blob/master/tutorials/sca/rmap_afni.sh)**. Una vez que le hayas dado permisos de ejecución al archivo simplemente necesitas correrlo de la siguiente manera:

```rmap_afni.sh <archivo NIFTI preprocesado> < ROI binario> <nombre del output> ```
  
  ejemplo: 

  ```./rmap_afni.sh sub-001_bandassed_denoised_warp_FWHM4.nii.gz pcc_mask.nii.gz sub-001_pcc_corrmap```

  **A continuación explicaremos en detalle que es lo que hace este script:**
  
  **1.  Extraer la serie de tiempo promedio de tu funcional usando el ROI:**
  
```fslmeants -i sub-001_bandassed_denoised_warp_FWHM4.nii.gz -m pcc_mask.nii.gz -o pcc.ts```

Si realizaste bien este paso, al intrducir en la terminal el comando `head pcc.ts`  deberías ver lo siguiente:
  
 ``` 
  -3.744489014 
    1.972393204 
    10.74178089 
    14.54784234 
    8.430280266
   -5.448772119 
   -19.30749452 
   -25.47799781 
   -21.67057823 
   -11.75656644
```
**2. Obtener el mapa de correlación con AFNI**

```3dTcorr1D -prefix sub-001_pcc_corrmap.nii.gz sub-001_bandassed_denoised_warp_FWHM4.nii.gz pcc.ts```

Puedes visualizar el mapa de correlación con el visor de tu preferencia. para visualizarlo con fsleyes escribe:

```fsleyes -std sub-001_pcc_corrmap.nii.gz -dr 0.3 0.8   -cm red-yellow```


**Si hiciste todo bien deberías ver algo como en la siguiente imagen:**

![](https://github.com/alffajardo/mri_data/blob/master/tutorials/sca/sub-001_pcc_corrmap.png)

### Como podrás observar hemos obtenido un patrón muy conocido en la literatura. ¡¡Así es!! ¡¡Se trata de la ***Default Mode Network***!! 

***
## OPCIÓN 2: USANDO R

antes de correr el script  asegúrate de tener instalados los paquetes en R:
- oro.nifti
- neurobase
- RNifti

Si no los tienes instalados  simplemente abre una consola de R y escribe:

`install.packages(c("oro.nifti","neurobase","RNifti"))`

Para mayores facilidades puedes descargar el script **[gen_corrmap.R](https://github.com/alffajardo/mri_data/blob/master/tutorials/sca/gen_corrmap.R)**. Este script corre desde la terminal de bash pero llama a R para poder funcionar. En breve explicaremos cómo funciona. Para correrlo simplemente teclea desde bash:

`./gen_corrmap.R < NIFTI 4D > < ROI 3D > < nombre del output > `

**Ejemplo:** `./gen_corrmap.R  sub-001_bandassed_denoised_warp_FWHM4.nii.gz  pcc_mask.nii.gz pcc_map_R`

A continuación se explica lo que hace el script. Nota que se incluye sólo como realizar el análisis en la consola de R y para fines prácticos se excluyeron aquellos comandos necesarios para correr el script desde bash.

**1. Cargar los paquetes necesarios para trabajar**
  ```
library(magrittr)
library(oro.nifti)
library(neurobase)
```
**2. Definir nombre del output:**
 
```output <- "sub-001_pcc_corrmap_R"```

**3. Leer la imagen funcional y el ROI.** Se leen con paquetes diferentes
```
func <- RNifti::readNifti("sub-001_bandassed_denoised_warp_FWHM4.nii.gz")
roi <- readNIfTI("pcc_mask.nii.gz",reorient = FALSE)
```
**4. Obtener las dimensiones de la imagen funcional**

```
d <- dim(func)
```
**4. Crear una máscara para hacer el análisis**

```
func_mask <- niftiarr(img= roi, arr = 0)
func_mask@.Data <- func[,,,1]
func_mask[func_mask !=0] <- 1
```
Si lo deseas puedes visualizar  la máscara utilizando el comando `orthographic(func_mask,crosshairs=F)`

![](https://github.com/alffajardo/mri_data/blob/master/tutorials/sca/func_mask.png)

### **5. Extraer la serie temporal del ROI**

```
ts <- matrix(func[roi!=0],ncol = d[4]) %>%
  colMeans()
```
**6. Aqui se estan haciendo dos pasos. Primero se están extrayendo los datos de la imagen funcional que se encuentran dentro la máscara y transponiendolos a una matriz de dos dimensiones el cual el número de columnas será el número de puntos temporales de la imagen 4d. Una vez vectorizados los datos,cada una de las filas de la matrix (series temporales de cada vóxel en la máscara) se correlaciona con la serie de tiempo obtenida el paso anterior y se almacenan los coeficientes de pearson en un objeto llamado rvalues.**

```
rvalues <- matrix(func[func_mask !=0],ncol=d[4]) %>%
  apply(.,1,cor,ts)
```

**NOTA:** Quizás te preguntes por qué no hicimos directamente las correlaciones con un ciclo for iterando sobre las coordenadas de cada uno de los voxeles de la  imagen funcional. la respuesta es que al realizar literalmente miles de procesos iterativos en un ciclo for, eso haría que tu código fuera asquerosamente lento. Realmente no quieres eso.

**7. Utilizamos la máscara creada previamente para llenarla con los datos recién computados (coeficientes de pearson).**
```
rmap <- func_mask
rmap[rmap !=0] <- rvalues
```
 **8. Escribir el output** 

```
write_nifti(rmap,output)
```
### Si observas con atención notarás que los resultados de ambos scripts son identicos. Así que puedes usar el que te sea más fácil. Si deseas adquirir un nivel mayor de experiencia sobre lo que estás haciendo te recomendamos estudiar el código de R que se ha provisto.Recuerda que para hacer analisis de grupo aún necesitas aplicar la transformada de Fischer a los datos.

![](https://github.com/alffajardo/mri_data/blob/master/tutorials/sca/sub-001_pcc_corrmap_R.png)Cómo evaluar el calibre de axones

Esto se logra a partir de histología. En este ejemplo, trabajaremos con una imagen con tinción de azul de toluidina, con un grosor de 1 micra, y con un aumento de 100X. Esta imagen es cortesía del Dr. Larriva, y se trata de un nervio óptico de rata, cortado de manera perpendicular al eje longitudinal de los axones.


La imagen original está en tif. La que se anexa aquí está en png por requisitos del dokuwiki. 

[[images/n_opt.png]]

Lo primero que hice fue convertirlo a escala de grises desde la línea de comandos utilizando imagemagick

```
 convert [[images/n_opt.png]] -colorspace gray [[images/n_opt_grayscale.png]]
```
[[images/n_opt_grayscale.png]]

Ahora abrimos ImageJ (versión 1.51j8).
(Hay que instalar los plugins [[https://imagescience.org/meijering/software/featurej/|FeatureJ]] y [[http://example.com|CLAHE]] y reiniciarlo la primera vez)

Abrimos la imagen en escala de grises. 

Ahora corremos el algoritmo CLAHE dos veces. Está en Plugins-CLAHE. Usamos los defaults (blocksize=127, histogram bins=256, max slope=3.0). La imagen queda mucho más homogénea.

[[images/n_opt_grayscale_clahex2.png]]

Tenemos que encontrar un umbral que separe membranas/mielina del resto de la imagen. Para esto, vamos a Image-Adjust-Auto local threshold. Seleccionamos el método Bernsen con radio=15 y dejamos seleccionado White objects on black bacground. Nota: He probado solo parcialmente los otros métodos, y éste ha dado buen resultado, aunque no descarto que otro pueda ser mejor.

La imagen quedará binarizada. 

[[images/n_opt_grayscale_clahex2_bin.png]]

Ahora sí ya solo queda encontrar los axones. Usaremos Analyze-Analyze particles.
En Circularity seleccionamos 0.5-1, lo que hace al algoritmo buscar partículas semi o casi ciruclares, e ignorar cosas lineales. Aquí debemos tener cuidado cuando tengamos un corte no perfectamente perpendicular a los axones. Además, debemos jugar un poco con el tamaño de la partícula, que aquí está de cero a infinito. Quizás con ésto podemos controlar más el algoritmo, y/o dividir los axones chicos de los grandes. Esto y las estadísticas están mejor si tenemos claro las dimensiones de cada pixel en micras y se lo decimos a [[ImageJ dimensions]]. 

[[images/analyze_particles_003.png]]


El resultado son los perfiles del lúmen de los axones, y una tabla donde se resumen sus áreas.

[[images/resultado_analyzeparticles.png]]



**NOTA** Para especificar las dimensiones físicas de una imagen cargada en ImageJ:

Cargar la imagen.

Image-Properties.

Unit of length = um
Pixel width&height=0.0645 (ejemplo, no es siempre así, útil para probar magnificación 100X).


El resonador GE Discovery MR750 recientemente recibió una actualización de software a versión 29.1 (2022), lo que incluyó importantes mejoras para DWI.

Una de las principales mejoras es la capacidad de incorporar protocolos DWI multi-shell sin necesidad de realizar cada shell como una adquisición independiente. La otra buenísima es la posibilidad de adquirir múltiples rebanadas de forma simultánea (SMS; Hyperband), con lo que el tiempo de adquisición se reduce de manera lineal en función del número de rebanadas simultáneas.

Para adquirir DWI multi-shell, se debe seleccionar la opción `Tensor`, y escribir el número de direcciones _totales_ (la suma de todas las direcciones en todos los shells), y como `bvalue` escribir el máximo valor de _b_ en nuestras shells. 

![](https://github.com/c13inb/c13inb.github.io/blob/master/images/q-space-sampling_diffusion-setup.png)


El sistema incluye algunos protocolos famosos pre-cargados. Para utilizarlos, vamos a la pestaña `Advanced` y en `Tensor filename` ponemos el número entero que corresponde a un archivo llamado `Tensor????.dat` que está grabado en la carpeta `/usr/g/bin` del resonador. 

![](https://github.com/c13inb/c13inb.github.io/blob/master/images/q-space-sampling_advanced-setup.png)


En caso de querer colocar nuestros propios archivos de protocolos multishell, los pondremos en esa ruta, con la ayuda del físico médico de la URM. Los archivos pueden consultarse [aquí](https://drive.google.com/drive/folders/1l8ZdOjHbMcL4t4z_8ALl78SQya3ZYP_G?usp=share_link) y se resumen a continuación:

|protocolo       | archivo        | nDirs en consola | bval en consola | nb0 | b1   | dirs1 | b2   | dirs2 | b3   | dirs3 | b4   | dirs4 | Notas                                       |
| -------------- | -------------- | ---------------- | --------------- | --- | ---- | ----- | ---- | ----- | ---- | ----- | ---- | ----- | ------------------------------------------- |
|HCP             | tensor1090.dat | 90               | 2000            | 0   | 1000 | 45    | 2000 | 45    |      |       |      |       | Especificar nb0 en consola                  |
|ADNI-3          | tensor1127.dat | 126              | 2000            | 6   | 500  | 6     | 1000 | 48    | 2000 | 60    |      |       | Recomendado para gradientes >70 mT/m        |
|ADNI-3          | tensor1127.dat | 100              | 2000            | 9   | 500  | 6     | 1000 | 38    | 2000 | 47    |      |       | Recomendado para gradientes menos poderosos |
|ABCD            | tensor4321.dat | 102              | 3000            | 6   | 500  | 6     | 1000 | 15    | 2000 | 15    | 3000 | 60    |                                             |
|ABCD            | tensor4321.dat | 96               | 3000            | 0   | 500  | 6     | 1000 | 15    | 2000 | 15    | 3000 | 60    | Especificar nb0 en consola                  |
|UK Biobank      | tensor521.dat  | 104              | 2000            | 4   | 1000 | 50    | 2000 | 50    |      |       |      |       |                                             |
|UK Biobank      | tensor521.dat  | 6                | 2000            | 3   | 2000 | 3     |      |       |      |       |      |       | Para revpe                                  |
|Desconocido     | tensor8313.dat | 296              | 3000            | 26  | 1000 | 90    | 2000 | 90    | 3000 | 90    |      |       |                                             |
|Desconocido     | tensor8313.dat | 270              | 3000            | 0   | 1000 | 90    | 2000 | 90    | 3000 | 90    |      |       | Especificar nb0 en consola                  |


El manual de usuario del software del resonador GE está disponible [aquí](https://drive.google.com/file/d/1NfvfB3EoYON41HucbuNLgt9Rq6X1Yo9i/view?usp=sharing). Se recomienda revisar página 1807.

Hay más explicaciones y scripts para generar nuestros propios archivos `tensor????.dat` en [este fabuloso link](https://github.com/naveau/qspacesampling2GE).


## User CVs
Para evitar que se interpolen las imágenes en el plano (no bueno para dwidenoise), usar CV `rhmethod=1`.
Para cambiar la polaridad del _phase encoding_ para poder usar [eddy y topup](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/topup), usar `revpe`.## Procesamiento de Imágenes Pesadas a Difusión ##
Procesar datos de imágenes de difusión es bastante complicado, y hay muchos aspectos qué vigilar para lograr obtener un análisis optimo. En esta página se describen algunas técnicas.

+ [Preprocesamiento en imágenes de humanos.](./DWMRI:-Preprocesamiento-humanos)
+ [Preprocesamiento en roedores](./DWMRI:-Preprocesamiento-roedores)
+ [Preprocesamiento con Designer](./DWMRI:designer)
+ [Tractografía](./MRtrix3:-Tractografía) con MRtrix3.
+ [DSIstudio](./DWMRI:DSIstudio)
+ [Multi-resolution discrete-search](./DWMRI:-Multi-tensor)
+ [Registro](./DWMRI:-Registro)
+ [Resonador GE](./DWI_GE)



## MULTI-RESOLUTION DISCRETE-SEARCH

En este manual repasaremos paso por paso como implementar el método multi-tensor MRDS desarrollado por el Dr. Ricardo Coronado-Leija, para literatura mas extensa de como funciona el método, porfavor consulta el artículo [aquí](https://www.sciencedirect.com/science/article/abs/pii/S1361841517300956).


MRDS sigue una serie de pasos para poder ser implementado, primero antes que nada vamos a cargar los módulos necesarios:

```python=
module load mrtrix/3.0.4
module load mrds/1.0
```
MRDS lo puedes ejecutar en toooodo el cerebro o en una rebanada o en solo la corteza, eso dependerá de tu análisis. Para fines didácticos, vamos a hacer todo el cerebro de rata de una sola rebanada.

Antes de empezar, necesitamos preparar algunos datos que MRDS nos pedirá para su ejecución:

#### 1. Scheme
El scheme no es nada mas que la información de los gradientes de difusión de la imágen, es decir, tus archivos `.bvec` y `.bval`. Sin embargo, MRDS pide que estos esten juntos en un archivo de texto organizados de manera específica con 4 columnas en el orden *X Y Z b*, donde *x y x* es la dirección de los gradientes y *b* es el b-value asociado. 

Por ejemplo, si vemos como esta ordenado tu archivo `.bvec` original, vemos que esta de esta manera:

![Captura de pantalla 2024-04-15 203253](https://github.com/c13inb/c13inb.github.io/assets/129544525/444f378c-fb2c-414c-8790-34460953ebd2)

Lo mismo sucede para el archivo `.bval`. Lo que necesitamos hacer es juntar ambos archivos y acomodar los datos en formato columna/tabla. Para esto, podemos usar un script que forma parte de los `inb_tools` que hace el trabajo!

```python=
# Unimos los archivos .bvec y .bval:

cat 64A_dwi.bvec 64A_dwi.bval > bvec_bval

# Usamos el script para modificar la estructura

transpose_table.sh bvec_bval > scheme
```
Teniendo como output lo siguiente:

![Captura de pantalla 2024-04-15 204054](https://github.com/c13inb/c13inb.github.io/assets/129544525/f8b6cc05-97bf-46b3-b821-69464157fbac)

Vemos que las columnas siguen sin alinearse adecuadamente y esto es debido a que tenemos numeros muy largos despues del punto. Esto lo corregimos con el siguiente código:

```python=
cut -d' ' -f1-4 scheme | while read a b c d; do printf "%.5f %.5f %.5f %.4f\n" "$a" "$b" "$c" "$d"; done > scheme_nuevo
```
> Aprende [aquí](https://linuxize.com/post/linux-cut-command/) mas acerca de como usar el comando `cut`.


Ahora vemos que ahora las columnas estan bien alineadas y en orden:

![Captura de pantalla 2024-04-15 210516](https://github.com/c13inb/c13inb.github.io/assets/129544525/f1434b1c-3852-4173-b6a8-a1bda1ca6c1a)

Como ultimo paso para el scheme, hay que remover los primeros bvals (b=21.01.08) y convertirlos en ceros, ya que MRDS no puede ser ejecutado sin volúmenes b=0, en este caso puedes tomar los mas bajos y convertilos. Aquí un código para poderlo hacer:


```python=
shells=`mrinfo -bvalue_scaling false -grad scheme_nuevo 64A_dwi.nii -shell_bvalues`
firstbval=`echo $shells | awk '{print $1}'`
if (( $(echo "$firstbval > 0 " | bc -l)  ))
then
sed -i -e "s/${firstbval}/0.0000/g" $scheme
fi
```
![Captura de pantalla 2024-04-16 142629](https://github.com/c13inb/c13inb.github.io/assets/129544525/8644f26b-375a-4407-8145-bac56a8d1606)



#### 2. Máscara
Primero necesitamos una máscara del cerebro o del área de interes donde quieres que se implemente MRDS. Sin embargo, dado que MRDS se ejecuta utilizando una *response function*, asegurá que tu máscara incluya una estructura de alta anisotropía, como por ejemplo el cuerpo calloso. 
> La *response funcion* es definida como la señal esperada/ideal en un voxel que contiene una organización altamente coherente y perfecta de un solo manojo de fibras. Un gran ejemplo es el cuerpo calloso en su porción medial. 

Aquí hay de dos sopas, o creas una máscara general del cerebro utilizando `dwi2mask` o creas tu propio ROI/máscara binaria de la estructura y rebanada que quieras. Esta ultima opción requere que el ROI se dibuje manualmente (al menos que tengas un pipeline que lo haga por ti). Con fines didácticos y de tiempo, voy a crear un ROI utilizando `mrview`:

```python=
mrview 64A_dwi.nii.gz 
## Aquí haces tu ROI y lo guardas
```
Alternativamente puedes simplemente utilizar: 
```python=
dwi2mask -grad scheme_nuevo 64A_dwi.nii.gz mascara_64A.nii.gz
```

![Captura de pantalla 2024-04-16 160229](https://github.com/c13inb/c13inb.github.io/assets/129544525/e1a33c5e-6651-43af-817a-b682edfcaf4d)


### Ajuste de MRDS primera parte:

Una vez que tenemos estos preparativos, estamos listos para correr la primera parte de MRDS que es ajustando el DTI con un método no-linear. También puedes ajustarlo de manera más tradicional, etre otros, para esto hay que revisar la documentación y ajustar `dti` a tus necesidades y objetivos específicos:

```
dti

dti [ options ] dwi_input scheme tensor_output

        dwi_input
                name of the input dwi file (.nii).
        scheme
                name of the scheme (.txt) corresponding to the dwi image. Each line of the file must be:
                         x1 y1 z1 b1
                         x2 y2 z2 b2
                         x3 y3 z3 b3
                         .  .  .  .
                         .  .  .  .
                         .  .  .  .
                         xn yn zn bn
        tensor_output
                name of the output diffusion tensor (.nii).

Compute Diffusion Tensor from Diffusion Weighted Magnetic Resonance Images.

Options:

         -save option
                Which files to save: (0) tensors; (1) diff parameters; (2) both. Default: 2.
         -mask file(.nii)
                mask for selecting the voxels that will be processed.
         -nonorm
                Work with original signals Si (not recommended). By default the algorithm works with A_i = S_i/S_0.
         -beta num
                For the spatial bilateral estimation of S0^{s}_{snr}, S0^{s}_{std} and S0^{s}_{mean}.
                The estimation includes close voxels inside the range S0^{v}_{mean} +/- beta*S0^{v}_{std}.
                (s) -> spatial, (v) -> voxel.
                Default: beta = 0.5.
         -method name
                select the method used for estimate the diffusion tensor coefficients.
                the choices are:
                        -method naive      -> Log Linear Least Squares. Very simple implementation.
                        -method linear     -> Log Linear Least Squares. GSL Implementation.
                        -method nonlinear  -> Non Linear Least Squares. GSL Implementation.
                        Default: -nonlinear.
         -response nvoxels
                Estimate and compute the mean of the diffusion tensor eigenvalues using the voxels
                in the volume where there is high probability only one fiber bundle exist.
                This could be used for starting point on other multi-fiber algorithms.
                The algorithm will use the nvoxels with maximum FA in a confidence interval.
                Setting nvoxels = 0 will use all voxels in the confidence interval.
         -adc
                compute the apparent diffusion coefficient on each orientation of the scheme.
         -lps
                compute the linear, planar and spherical coeficients of the diffusion tensor.
         -fa
                compute the fractional anisotropy of the diffusion tensor.
         -md
                compute the mean diffusivity of the diffusion tensor.
         -dec
                compute the direction encoding color of the diffusion tensor DEC = FA*PDD.
         -mse
                compute the mse of the signals for the estimated diffusion tensors and the measured signal.
         -correction num
                Apply a transformation on the diffusion data in order to correct the Rician bias.
                This is not a denoising, it is just a bias correction. The choices are:
                        -correction  0, 1, 2 -> No correction: y = x.
                        -correction  3, 4, 5 -> Gudbjartsson correction: y = sqrt(fabs(x*x - sigma*sigma)).
                        -correction  6, 7, 8 -> Gudbjartsson correction modified: y = sqrt(max(x*x - sigma*sigma,0.0)).
                        -correction  9,10,11 -> Manjon correction: y = sqrt(max(x*x - 2.0*sigma*sigma,0.0)).
                        -correction 12,13,14 -> Maximum Likelihood correction y_ML = max_y(p(x;y,sigma)).
                                                Exhaustive evaluation.
                        -correction 15,16,17 -> Mean Posterior correction y = sum x*p(x).
                                                Exhaustive evaluation.
                        -correction 18,19,20 -> Mean Posterior correction adaptive according to each measurement.
                        Aditional consideration.
                        num % 3 => 0 - min value = 0.
                        num % 3 => 1 - min value = estimated from data.
                        num % 3 => 2 - min value = physically plausible exp(-b*3e-3).
                        Default: -correction 8.
         -help
                show this help

```
Entonces, nosotros podemos ajustar `dti` de la siguiente manera:

```python=
dti 
-mask ROI.nii \
-response 0 \
-correction 0 \
-fa -md \
-64A_dwi.nii \
-scheme_nuevo.txt \
-dwi.nii
```
> Ojo, si tus archivos los tienes en `.nii.gz`, utiliza `mrconvert` para cambiar a `.nii`.

Checamos nuestros outputs:

```python=
ls dwi_DTInolin_*

dwi_DTInolin_COMP_SIZE.nii    
dwi_DTInolin_ISOTROPIC.nii  
dwi_DTInolin_PDDs_CARTESIAN.nii           
dwi_DTInolin_ResponseIsotropicMask.nii
dwi_DTInolin_EIGENVALUES.nii  
dwi_DTInolin_MD.nii        
dwi_DTInolin_ResponseAnisotropicMask.nii  
dwi_DTInolin_ResponseIsotropic.txt
dwi_DTInolin_FA.nii           
dwi_DTInolin_NUM_COMP.nii   
dwi_DTInolin_ResponseAnisotropic.txt      
dwi_DTInolin_Tensor.nii
```
Vemos que tenemos de regreso una serie de archivos que nos serviran para ejecutar el segundo segmento de MRDS que es precisamente ajustar el multi-tensor. Como práctica, te recomiendo que abras todos los archivos con `mrview` y explores que es cada output. Pero por lo pronto, vemos que el comando `dti` nos generó los mapas de fracción de anisotropía (FA) y de difusividad media (MD), asi como el archivo de la *response function* `dwi_DTInolin_ResponseAsotropic.txt` que necesitaremos para el siguiente paso.

### Ajuste de MRDS segunda parte:

En esta segunda parte vamos a ajustar los multi-tensores voxel por voxel tomando algunos de los outputs de la primera parte. Esta segunda parte es un poco mas compleja en cuanto a los parámetros y también mucho mas tardado en correr. Veamos el manual del comando `mdtmrds`:

```
mdtmrds
 
mdtmrds [ options ] dwi_input scheme mt_output

        dwi_input
                name of the input dwi file (.nii).
        scheme
                name of the scheme (.txt) corresponding to the dwi image. Each line of the file must be:
                         x1 y1 z1 b1
                         x2 y2 z2 b2
                         x3 y3 z3 b3
                         .  .  .  .
                         .  .  .  .
                         .  .  .  .
                         xn yn zn bn
        mt_output
                name of the output multi-diffusion tensor file (.nii).

Compute the Multiple Radially Symmetryc Diffusion Tensor from Diffusion Weighted Magnetic Resonance Images.
Multi-Resolution Discrete-Search method is used.

Options:

         -mask file(.nii)
                mask for selecting the voxels that will be processed.
         -response l1,l2(,Diso)
                By default the eigenvalues l1 = 1.5e-3, l2 = 0.3e-3 are used as initial response function.
                Using this option, they could be specified so the eigenvalues of the tensor be [l1,l2,l2].
                If isotropic compartment flag is set, Diso can be supplied as the third value. Default 0.8e-3.
         -nonorm
                Work with original signals Si (not recommended). By default the algorithm works with A_i = S_i/S_0.
         -beta
                For the spatial bilateral estimation of S0^{s}_{snr}, S0^{s}_{std} and S0^{s}_{mean}.
                The estimation includes close voxels inside the range S0^{v}_{mean} +/- beta*S0^{v}_{std}.
                (s) -> spatial, (v) -> voxel.
                Default: beta = 0.5.
         -modsel name
                select the criteria used for estimate the number of fiber bundles (#param k) on each voxel.
                the choices are:
                        -modsel bic   -> Bayesian Information Critearia: BIC = -2 log L + n * log(k).
                        -modsel aic   -> Akaike Information Critearia:   AIC = -2 log L + 2 * k.
                        -modsel aicc  -> Akaike Information Critearia corrected for finite samples.
                        -modsel hqic  -> Hanan-Quinn Information Critearia: HQIC = -2 log L + 2k log(log(n))
                        -modsel l0    -> pseudo-l0 norm. n*MSE + lambda*sigma*sigma*log(n)*k (BIC: lambda = 1)
                        -modsel ftest -> F-test: F = [(RSS1-RSS2)/(p2-p1)] / [(RSS2)/(n-p2)] < pvalue.
                        -modsel bhq   -> compute BIC and HQIC.
                        -modsel all   -> compute all: bic, aic, aicc and hqic (sometimes needed).
                        Default: -ftest.
         -reg value
                If the option modsel is ftest, this option sets the pvalue for performing the f-test.
                If the option modsel is any other, this option will be ignored.
                Defaults: 0.001.
         -alt
                For the model selection, by default, the sigma dependent Gaussian Log Likelihood is used:
                'log L(sigma) = -(n/2)[ log(2pi) + log(sigma^2) + (1/sigma^2) MSE ]'.

                With this option a sigma free approximation of the Gaussian Log Likelihood is used instead:
                'log L = -(n/2) ln(MSE).

                If the option modsel is ftest, this option will be ignored.
         -method name
                Select the method to use (based on the estimation of the eigenvalues).
                        -method fixed: The eigenvalues are not estimated, they are kept fixed during the process.
                        -method equal: The eigenvalues are estimated equal for all the bundles inside the voxel.
                        -method diff:  The eigenvalues are estimated different for each bundle inside the voxel.
                Default: -method equal (is more stable).
         -iso
                Adding the isotropic compartment to the estimation (Still not working properly).
         -each
                By default, only the multi-tensor with the selected number of bundles is saved.
                With this option the multi-tensors with N = 1,2,3,... are also saved.
         -intermediate
                By default, only the multi-tensor(s) of the final stage are saved.
                With this option, the multi-tensor(s) of the intermediate stages are also saved.
         -stages np1,np2,np3,...
                Define the number of stages (resolutions of the orientation sets) used in the method.
                npi defines the number of orientations for the orientation set used in the ith stage.
         -fa
                compute the fractional anisotropy of the multi diffusion tensors on each voxel.
         -md
                compute the mean diffusivity of the multi diffusion tensors on each voxel.
         -mse
                compute the mse of the signals for the estimated multi diffusion tensors and the measured signal.
         -correction num
                Apply a transformation on the diffusion data in order to correct the Rician bias.
                This is not a denoising, it is just a bias correction. The choices are:
                        -correction  0, 1, 2 -> No correction: y = x.
                        -correction  3, 4, 5 -> Gudbjartsson correction: y = sqrt(fabs(x*x - sigma*sigma)).
                        -correction  6, 7, 8 -> Gudbjartsson correction modified: y = sqrt(max(x*x - sigma*sigma,0.0)).
                        -correction  9,10,11 -> Manjon correction: y = sqrt(max(x*x - 2.0*sigma*sigma,0.0)).
                        -correction 12,13,14 -> Maximum Likelihood correction y_ML = max_y(p(x;y,sigma)).
                                                Exhaustive evaluation.
                        -correction 15,16,17 -> Mean Posterior correction y = sum x*p(x).
                                                Exhaustive evaluation.
                        -correction 18,19,20 -> Mean Posterior correction adaptive according to each measurement.
                        Aditional consideration.
                        num % 3 => 0 - min value = 0.
                        num % 3 => 1 - min value = estimated from data.
                        num % 3 => 2 - min value = physically plausible exp(-b*3e-3).
                        Default: -correction 8.
         -help
                show this help

```


Como indica el manual en la opción de `response` (leer arriba), debemos de especificar los dos primeros lamdas. Esta información esta contenida en el archivo `dwi_DTInolin_ResponseAnisotropic.txt`. Para extraer esos datos y guardarlos en una variable puedes utilizar el siguiente código:

```python=
responsef=`cat dwi_DTInolin_ResponseAnisotropic.txt | cut -d" " -f1,2 --output-delimiter=,`
```
Hasta aquí ya tenemos los datos suficientes para correr el multi-tensor. Como puedes ver, hay diferentes opciones para correr la función, recuerda que hay que adaptarlo de acuerdo a lo que necesites. 
Sin embargo, algunos de los puntos son claves:
* La selección del modelo (`-modsel`), donde eliges como se resuelve el número de poblaciones de fibras por voxel. Donde BIC (Criterio de Información Bayesiano) es de los mas robustos,  
* El método para estimar los eigenvalores (`-method`), este punto es crucial si lo que buscas es que tus tensores sean completamente **independientes** entre sí, si es así, `diff` es la opción. 


El siguiente código es un ejemplo de como puedes ajustarlo:
```python=
mdtmrds
-mask ROI.nii \
-response $responsef \
-correction 0 \
-modsel bic \
-fa -md \
method diff 1 \
each \
64A_dw.nii \
scheme_nuevo.txt \
dwi.nii
```
> Ten mucha paciencia por que MRDS tarda horas en correr, incluso días, dependiendo de que tanto cerebro estes procesando....

Ahora vemos nuestros outputs:

```python=
 ls dwi_MRDS_Diff*
 
dwi_MRDS_Diff_BIC_COMP_SIZE.nii
dwi_MRDS_Diff_BIC_EIGENVALUES.nii
dwi_MRDS_Diff_BIC_FA.nii
dwi_MRDS_Diff_BIC_ISOTROPIC.nii
dwi_MRDS_Diff_BIC_MD.nii
dwi_MRDS_Diff_BIC_NUM_COMP.nii
dwi_MRDS_Diff_BIC_PDDs_CARTESIAN.nii
dwi_MRDS_Diff_V1_COMP_SIZE.nii
dwi_MRDS_Diff_V1_EIGENVALUES.nii
dwi_MRDS_Diff_V1_FA.nii
dwi_MRDS_Diff_V1_ISOTROPIC.nii
dwi_MRDS_Diff_V1_MD.nii
dwi_MRDS_Diff_V1_NUM_COMP.nii
dwi_MRDS_Diff_V1_PDDs_CARTESIAN.nii
dwi_MRDS_Diff_V2_COMP_SIZE.nii
dwi_MRDS_Diff_V2_EIGENVALUES.nii
dwi_MRDS_Diff_V2_FA.nii
dwi_MRDS_Diff_V2_ISOTROPIC.nii
dwi_MRDS_Diff_V2_MD.nii
dwi_MRDS_Diff_V2_NUM_COMP.nii
dwi_MRDS_Diff_V2_PDDs_CARTESIAN.nii
dwi_MRDS_Diff_V3_COMP_SIZE.nii
dwi_MRDS_Diff_V3_EIGENVALUES.nii
dwi_MRDS_Diff_V3_FA.nii
dwi_MRDS_Diff_V3_ISOTROPIC.nii
dwi_MRDS_Diff_V3_MD.nii
dwi_MRDS_Diff_V3_NUM_COMP.nii
dwi_MRDS_Diff_V3_PDDs_CARTESIAN.nii
```

Nuevamente te recomiendo mucho que explores tus outputs para que no sean una caja negra. Por lo pronto, podemos observar que hay cuatro sets de datos: `V1`, `V2`, `V3` y `BIC`. Donde `BIC` son el resultdado final una vez aplicado el criterio de información bayesiana y son los que al final puedes utilizar para el análisis.

Entonces por el momento nos concentraremos en los output más relevantes:

``` 
dwi_MRDS_Diff_BIC_COMP_SIZE.nii
dwi_MRDS_Diff_BIC_FA.nii
`dwi_MRDS_Diff_BIC_MD.nii`
dwi_MRDS_Diff_BIC_NUM_COMP.nii
dwi_MRDS_Diff_BIC_PDDs_CARTESIAN.nii
```

Donde `dwi_MRDS_Diff_BIC_NUM_COMP.nii` nos va a decir cuantos compartimentos (tensores) encontro en tus datos. En este ejemplo podemos ver que MRDS encontro en su mayoría tres compartimentos:

![image](https://github.com/c13inb/c13inb.github.io/assets/129544525/f619b3af-b2e7-4bcf-9e57-158f6b56082e)

Una vez sabiendo que hay tres compartimentos, `dwi_MRDS_Diff_BIC_COMP_SIZE.nii` nos dirá el tamaño de cada uno, y tanto `dwi_MRDS_Diff_BIC_FA.nii` como `dwi_MRDS_Diff_BIC_MD.nii` será los mapas cuantitativos de cada compartimento. Ejemplo:

![image](https://github.com/c13inb/c13inb.github.io/assets/129544525/c3716a90-aedd-4aa4-b655-d72f58a4b5b4)

Ahora, para visualizar tus fixels vamos a necesitar el archivo `dwi_MRDS_Diff_BIC_PDDs_CARTESIAN.nii` que contiene información de la dirección principal. Si bien odemos cargar los datos de la siguiente manera:
```
mrview 64A_dwi.nii.gz -fixel.load dwi_MRDS_Diff_BIC_PDDs_CARTESIAN.nii
```
<img width="946" alt="Captura de pantalla 2024-06-17 a la(s) 10 54 22 a m" src="https://github.com/c13inb/c13inb.github.io/assets/129544525/ca56181e-5048-4c5a-9468-e8614494285b">

También puedes escalar tus PDD's de acuerdo al tamaño de cada tensor/compartimento para entender mejor la distribución de estos por voxel. Puedes hacerlo usando el siguiente script:
```
#!/bin/bash

PDDs=$1
COMPSIZE=$2
scaled_PDDs=$3

tmpDir=$(mktemp -d)

mrconvert -coord 3 0:2 $PDDs ${tmpDir}/PDD_0.mif
mrconvert -coord 3 3:5 $PDDs ${tmpDir}/PDD_1.mif
mrconvert -coord 3 6:8 $PDDs ${tmpDir}/PDD_2.mif

mrinfo $COMPSIZE

mrconvert -coord 3 0 $COMPSIZE ${tmpDir}/fraction_0.mif
mrconvert -coord 3 1 $COMPSIZE ${tmpDir}/fraction_1.mif
mrconvert -coord 3 2 $COMPSIZE ${tmpDir}/fraction_2.mif

mrcalc ${tmpDir}/PDD_0.mif ${tmpDir}/fraction_0.mif -mul ${tmpDir}/scaled_PDD_0.mif
mrcalc ${tmpDir}/PDD_1.mif ${tmpDir}/fraction_1.mif -mul ${tmpDir}/scaled_PDD_1.mif
mrcalc ${tmpDir}/PDD_2.mif ${tmpDir}/fraction_2.mif -mul ${tmpDir}/scaled_PDD_2.mif


mrcat -axis 3 ${tmpDir}/scaled_PDD_{0,1,2}.mif $scaled_PDDs

rm -fR $tmpDir

```
 
Ahora sí visualizamos esos fixels escalados:

```
mrview 64A_dwi.nii.gz -fixel.load scaled_PDDs.nii
```

<img width="946" alt="Captura de pantalla 2024-06-17 a la(s) 10 54 01 a m" src="https://github.com/c13inb/c13inb.github.io/assets/129544525/0283b442-f15d-4c51-a98f-b931aa93e981">




Antes de empezar, algunos detalles:

* Para un ejercicio más extenso, usando datos de roedor, visita [esta entrada](./dwipreproc-rat).
* Visita [Andy's brain book](https://andysbrainbook.readthedocs.io/en/latest/MRtrix/MRtrix_Course/MRtrix_04_Preprocessing.html) para más información (y más actualizada).
* [Lista de herramientas para preprocesamiento](https://hackmd.io/@c13lab/preproc) compilada por Ricardo Ríos.


## Conversion de datos 
+ Convertir de [DICOM a NIFTI](./Procesamiento-Imagen:-De-DICOM-a-NIFTI)
+ Convertir de [PARREC a NIFTI](./Procesamiento-Imagen:-De-PARREC-a-NIFTI)


## Corrección de inhomogeneidades del campo magnético
Lo que conviene ahora es corregir los errores de movimiento y los artefactos inducidos por [corrientes eddy](http://es.wikipedia.org/wiki/Corriente_de_Foucault). Existen dos versiones, la clásica es con:
``` eddy_correct_rotbvecs.sh ```

Este método es anticuado y sub-óptimo, pero lo único que se puede hacer en caso de no contar con imágenes con adquisición reversa de fase. En caso de contar con ellas, entonces utilizar la opción **Eddy correct revpe**. Por el momento no se ha utilizado completamente esta herramienta, pero en esta [página](http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/topup) se encuentra toda la información necesaria.

## Reacomodo de la tabla de gradientes para la compatibilidad de mrtrix
Si queremos usar mrtrix debemos cambiar el formato de la tabla de gradientes a como le gusta a mrtrix. Para ello usamos: 

``` inb_mrtrix_nii2mif.sh ```

El formato preferido de mrtrix es ``` .mif ```, pero es perfectamente feliz leyendo  ``` .nii ``` y ```.nii.gz ```, así que por comodidad utilizamos estos últimos. Esto quiere decir que no vamos a generar ningún archivo ``` .mif ```, pero sí nuestra tabla de gradientes. Entonces vamos a engañar un poco al script para que no genere el archivo ``` . mif ```, utilizando la opción ``` -onlyGrads ```. Por ejemplo:

``` inb_mrtrix_nii2mif.sh dwi_ec.nii.gz dwi_ec.mif dwi.bvec dwi.bval -flip_y -flip_z -onlyGrads ```

Esto generará el archivo ``` dwi_ec_encoding.b ``` en el cual el sentido de los componentes  ``` y ``` y  ``` z ``` de los gradientes están invertidos. Esto se requiere por el cambio de formato, y es dependiente de cada protocolo de imagen. Para saber qué componentes hay que invertir se hace por ensayo y error.


Antes de empezar, algunos detalles:

* Visita [Andy's brain book](https://andysbrainbook.readthedocs.io/en/latest/MRtrix/MRtrix_Course/MRtrix_04_Preprocessing.html) para más información (y más actualizada).
* [Lista de herramientas para preprocesamiento](https://hackmd.io/@c13lab/preproc) compilada por Ricardo Ríos.


## Conversion de datos 
+ Convertir de [DICOM a NIFTI](./Procesamiento-Imagen:-De-DICOM-a-NIFTI)
+ Convertir de [PARREC a NIFTI](./Procesamiento-Imagen:-De-PARREC-a-NIFTI)


## Corrección de inhomogeneidades del campo magnético
Lo que conviene ahora es corregir los errores de movimiento y los artefactos inducidos por [corrientes eddy](http://es.wikipedia.org/wiki/Corriente_de_Foucault). Existen dos versiones, la clásica es con:
``` eddy_correct_rotbvecs.sh ```

Este método es anticuado y sub-óptimo, pero lo único que se puede hacer en caso de no contar con imágenes con adquisición reversa de fase. En caso de contar con ellas, entonces utilizar la opción **Eddy correct revpe**. Por el momento no se ha utilizado completamente esta herramienta, pero en esta [página](http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/topup) se encuentra toda la información necesaria.

## Reacomodo de la tabla de gradientes para la compatibilidad de mrtrix
Si queremos usar mrtrix debemos cambiar el formato de la tabla de gradientes a como le gusta a mrtrix. Para ello usamos: 

``` mrconvert -fslgrad dwi.bvec dwi.bval dwi.nii.gz dwi.mif ```

El formato preferido de mrtrix es ``` .mif ```, pero es perfectamente feliz leyendo  ``` .nii ``` y ```.nii.gz ```, así que por comodidad utilizamos estos últimos. Esto quiere decir que no vamos a generar ningún archivo ``` .mif ```, pero sí nuestra tabla de gradientes. Entonces vamos a engañar un poco al script para que no genere el archivo ``` . mif ```, utilizando la opción ``` -onlyGrads ```. Por ejemplo:

``` inb_mrtrix_nii2mif.sh dwi_ec.nii.gz dwi_ec.mif dwi.bvec dwi.bval -flip_y -flip_z -onlyGrads ```

Esto generará el archivo ``` dwi_ec_encoding.b ``` en el cual el sentido de los componentes  ` y` y  `z` de los gradientes están invertidos. Esto se requiere por el cambio de formato, y es dependiente de cada protocolo de imagen. Para saber qué componentes hay que invertir se hace por ensayo y error.

Analizar datos de difusión puede ser bastante sencillo, pero para lograrlo se requiere que los datos estén en buenas condiciones. Estos pasos buscan corregir algunos artefactos de adquisición y limpiar los datos lo más posible, de manera que la estimación de parámetros de difusión sea adecuada. El preprocesamiento es habitualmente más tardado y latoso que el procesamiento mismo, y cada paso es toda un tópico en constante investigación y desarrollo. Aquí se describen los pasos que seguimos habitualmente (2024). El ejercicio está orientado a datos de roedor adquiridos con nuestro Bruker de 7 T, pero los conceptos son los mismos para datos de humanos. Estos pasos pueden usarse en su mayoría sin modificaciones con adquisiciones EPI3D.

En esta entrada vamos a repasar paso por paso como se realiza el preprocesamiento para fines didácticos. Al final podrás encontrar como utilizar el script `inb_dwi_bruker_preproc.sh` (disponible el 24 de agosto de 2021 en Don Clusterio) que encapsula todos estos pasos. Recuerda que tambíen puedes invocar el comando sin argumentos para aprender su uso. El script tiene la ventaja que además de hacer todo ésto, utiliza `eddy_quad` para hacer un reporte de control de calidad. Como bonus, se generan imágenes `png` para una rápida visualización de mapas RGB antes y después de pre-procesar los datos. **Ojo, que aunque existe el script, se recomienda leer esta entrada para que sepas qué hace esa caja negra.** El script está pensado en datos EPI-2D de rata, pero es probable que funcione en ratón, y con datos 3D-EPI. 

***

## Convertir del bruker a formato nifti.
El primer paso es convertir/exportar tus imágenes del bruker a un formato nifti. Aquí voy a utilizar de ejemplo unos datos que adquirí durante la maestría y que pertenecen al laboratorio C13. Visita esta [entrada]() donde se explica a más detalle paso por paso el como exportar tus imágenes.

Primero localizo el archivo de mis adquisiciones en el directorio del bruker y para facilitar la explicación las conviertiré en una variable:
```
BRUKERFOLDER=/misc/bruker7/data02/user/conchalab/20220104_085643_INB_C13_hluna_irm150d_rata64A_INB_C13_hluna_1_1
SCANNUMBER=6
```
Ojo, aquí **yo sé a priori** cual es mi imágen pesada a difusión, en este caso es la imágen número 6. Recuerda que en esta [entrada]() se explica este proceso.

Segundo paso, cargo el módulo de `brkraw`:
```
module load brkraw/0.3.11
```
Y ahora puedes ejecutar la conversion de la siguiente manera:

```
brkraw tonii $BRUKERFOLDER -o ./64A_dwi -r 1 -s $SCANNUMBER
```
En otras palabras:

`tonii` es el comando que convierte de Bruker a Nifti.

```-o``` es el output de como quieres que se llame tu imagen y en donde quieres guardarla, en este caso 64A_dwi es el nombre que yo le doy y `./` hago referencia de que se guarde en el directorio actual.

```-r``` es la reconstruccion que queremos, en este caso es la primera y por eso ponemos 1

```-s``` es la imagen que queremos convertir, en este caso es la numero 6 porque es la DWI


Vamos a ver que despues de la conversion tendremos **tres** outputs:

```
ls

64A_dwi.bvec
64A_dwi.bval  
64A_dwi.nii.gz
```

Los archivos `.bvec` contiene información acerca de los autovectores, mientras que el archivo `.bval` son los autovalores. Fundamentales para las DWI. Y por ultimo tenemos la imagen `.nii.gz`.

⚠️ Siempre siempre revisa tus imágenes crudas para asegurarte que se convirtieron adecuadamente y segundo para saber el estado en el que estan y lo que se espera del preprocesamiento para mejorarlas!

# Preprocesamiento

## 1.- Denoising
Este paso es fundamental y normalmente el primer paso antes de cualquier otro. Consiste en remover el ruido proveniente de la señal. Aquí puedes utilizar el comando `dwidenoise`:

`dwidenoise 64A_dwi.nii.gz 64A_dwi_denoised.nii.gz -noise 64A_dwi_noise.nii.gz`

> Donde `dwidenoise` es el comando, despues viene el `input` (DWI cruda), seguido del `output` (mi nueva imagen con denoise) y por ultimo `-noise` y su correspondiente `output` para el ruido estimado.
> Si quieres saber mas en como funciona haz clic aquí [aquí](https:/mrtrix.readthedocs.io/en/dev/dwi_preprocessing/denoising.html/)

Ten paciencia que el denoising es tardadito... pero una vez completado puedes ver tu nueva imagen:

![image](https://github.com/c13inb/c13inb.github.io/assets/129544525/b2013c6c-eefa-4647-ab5d-6965b27533df)

💡 Una bonita alternativa para el denoising es el algoritmo de [LPCA de José Manjón](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0073021), encapsulado en el script `inb_dwidenoise_LPCA_manjon.sh`. Suele quitar aún más ruido que `dwidenoise` (a veces demasiado, pero pruébalo!).

## 2.- Unringing
Este proceso trata de minimizar los [anillos de Gibbs](http://mriquestions.com/gibbs-artifact.html) que pueden verse alrededor de bordes anatómicos muy prominentes. Para que sea eficiente, las imágenes deben adquirirse con llenado total del espacio k (es decir, sin Partial Fourier). Si se hizo denoising, este paso debe seguir inmediatamente, y por ningún motivo se debe hacer después de Eddy. 

```
mrdegibbs 64A_dwi_denoised.nii.gz 64A_dwi_denoised_gibbs.nii.gz
```

## 4.- Eddy
Este paso corrige inhomogeneidades geométricas inducidas por los gradientes de difusión. Además elimina rebanadas con adquisiciones comprometidas (outlilers), en las que la señal es demasiado baja en comparación a lo esperado. Esto último es común en adquisiciones 2D-EPI, y se debe a que los gradientes de plano no aguantaron el ritmo solicitado para llenar el espacio k tan rápido. Es de esperar un 10% de rebanadas outliers en toda la adquisición (algo común es una o dos rebanadas outliers por cada volumen, y la posición espacial de las rebanadas outliers deben ser aleatorias entre volúmenes).
> ⚠️ Asegurate de que la computadora que estes utilizando tenga CUDA. Para instalarlo en tu laptop entra [acá](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html). Si estas trabajando en el Don Clústerio y no sabes si tu compu tiene CUDA, checa [aquí](https://github.com/c13inb/c13inb.github.io/wiki/CUDA).
Para correr Eddy, los desarrolladores de FSL crearon una herramienta llamada `eddy_cuda10.2` (actualizado 2024) que ejecuta esta corrección y mucho más. Sin embargo, antes de correr eddy, necesitamos hacer una serie de  primeros pasos para preparar los datos de acuerdo a como lo pide el software. En su [pagina web](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/eddy/UsersGuide/) tienen toda la información detallada de como hacerlo. Aquí lo resumiré con el ejemplo de la rata 64A.

1) Primero necesitamos sacar una máscara binaria del cerebro de la rata. Aquí me iré por la fácil que es usar `dwi2mask`, pero existen muchas otras herramientas para hacerlo, incluso de manera manual. Usa la que más se acomode a tu análisis y la que mejor te realice la máscara. 

```
dwi2mask -fslgrad 64A_dwi.bvec 64A_dwi.bval 64A_dwi.nii.gz mascara_64A_dwi.nii.gz
```

2) Ahora necesitamos un archivo que describa los parametros de la adquisición de cada imágen.
```
topup= 0.04
echo "0 -1 0" $topup > acqp_64A_dwi.txt
```
```
cat acqp_64A_dwi.txt
0 -1 0 0.05
```
Vemos que en el output tenemos `0 -1 0` que no es nada mas que la codificación en fase y `0.05` es la multiplicación entre el factor EPI y los ms de espacio entre ecos. Toda esta información al final son los parámetros de adquisición. Más información [aquí](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/eddy/Faq#How_do_I_know_what_to_put_into_my_--acqp_file)

3) Hay que crear un archivo índice que ayude a indicar que volúmenes (aquí 285) de DWI fueron tomadas con ciertos parametros de acuerdo al archivo acqp_64A_dwi.txt. En este caso, todos los volúemenes fueron adquiridos de igual manera.
```
indx=""

for ((i=1; i<=285; i+=1)); do indx="$indx 1"; done

echo $indx > indice_64A_dwi.txt
```
```
echo $indx
1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
```
⚠️ IMPORTANTE, estos archivos son particularmente importantes cuando uno tiene adquisiciones con inversión de la polaridad del gradiente de fase, pero en nuestro caso no hay tal cosa, así que los podemos generar fácilmente con estos comandos que siguen. Para adquisiciones con inversión de polaridad de fase, consulta la documentación en la página de [topup](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/topup/TopupUsersGuide), donde se describe cómo generar un B0map a partir de pares de adquisiciones con fases invertidas, que después se alimentan a `eddy`. Yo (lconcha, abril-julio 2021) hice varias pruebas con adquisiciones 2DEPI en el Bruker y no encontré mucha ventaja a usar adquisiciones con pares de dirección de fase y el uso de `topup`, por lo que en este ejercicio no se utiliza.

Cargamos el módulo:
```
module load fsl/6.0.7.4
```
Y corremos Eddy:

```
eddy_cuda10.2 /
--imain=denoised_64A_dwi.nii.gz /
--mask=mascara_64A_dwi.nii.gz /
--index=indice_64A_dwi.txt /
--acqp=acqp_64A_dwi.txt /
--bvecs=64A_dwi.bvec /
--bvals=64A_d
--out 64A_dwi
```
No olvides checar tus outputs!

```
ls eddy*

64A_dwi.nii.gz  
64A_dwi_eddy_parameters
64A_dwi_eddy_command_txt        
64A_dwi_eddy_post_eddy_shell_alignment_parameters
64A_dwi_eddy_movement_rms      
64A_dwi_eddy_post_eddy_shell_PE_translation_parameters
64A_dwi_eddy_outlier_map              
64A_dwi_eddy_restricted_movement_rms
64A_dwi_eddy_outlier_n_sqr_stdev_map 
64A_dwi_eddy_rotated_bvecs
64A_dwi_eddy_outlier_n_stdev_map      
64A_dwi_eddy_values_of_all_input_parameters
64A_dwi_eddy_outlier_report

```
Donde entre los outputs más relevantes son:
+ `64A_dwi.nii.gz`: Nuestro output principal. Incluye las imágenes ya corregidas, a las que se les minimizaró el movimiento entre volúmenes, así como las inhomogeneidades geométricas inducidas por corrientes eddy. Además, las rebanadas outliers fueron remplazadas por datos factibles dado un modelo simple. Estas son las imágenes que se usarán después para cualquier modelo de DWI.


<img src="https://github.com/c13inb/c13inb.github.io/assets/129544525/91417b1b-17ba-4745-8722-a712108621af" width="450" height="300">


+ `64A_dwi.eddy_rotated_bvecs`. Los vectores de los gradientes de difusión, una vez que fueron corregidos de acuerdo a las transformaciones geométricas que se le hicieron a cada volumen correspondiente. Por ejemplo, si un volumen se rotó 10 grados, el gradiente se rota también. En conjunto con `64A_dwi.bval` podremos usar cualquier modelo de difusión. 

### 👁️  **Aquí hay unas consideraciones bastante importantes respecto a Eddy:**

1. Los volúmenes considerados como b=0 no tienen vector asociado. Por alguna razón, en este archivo aparecen sus componentes x,y,z como `nan`. Esto va a hacernos la vida difícil para los siguientes pasos. Es fácil remplazar todas las ocurrencias de `nan` por un cero usando el fabuloso [`sed`](https://www.grymoire.com/Unix/Sed.html#uh-1):
```
sed -i 's/nan/0/g' 64A_dwi_eddy_rotated_bvecs
```

<img src="https://github.com/c13inb/c13inb.github.io/assets/129544525/52811ba4-9c84-494e-9567-73405a632841" width="700" height="350">


2. De forma similar, el archivo `.bval` no tiene entradas con b=0 s/mm². El resonador calcula la contribución de los gradientes de codificación espacial al valor b, y habitualmente resulta en b=15 a 30 s/mm². Cambiar estas entradas a cero hará cambios realmente despreciables en toda estimación de parámetros de difusión, así que lo vamos a hacer ahora. 

Solo debemos saber qué valor tenemos que cambiar, y suele ser el shell más bajo. Una manera simple es abrir el archivo `.bval` y revisar el número a cambiar, habitualmente en la primera entrada. Si la adquisición no inició con imágenes no pesadas a difusión, entonces usemos un método más robusto para encontrar el valor del shell con valor despreciable.
```
mrinfo -fslgrad 64A_dwi.bvec 64A_dwi.bval 64A_dwi.nii.gz -shell_bvalues

## 21.010828
```
Y ahora podemos hacer el cambio a 0. Escribimos un nuevo archivo `bval_zeros`. Esto también lo podemos hacer en la terminal con `sed`: 
```
sed 's/21.010828/0/g' 64A_dwi.bval > bval_zeros
```
+ `64A_dwi_eddy_outlier_report`.  Un archivo de texto que nos dice qué rebanadas en cada volumen resultaron ser outliers. 

+ `64A_dwi_eddy_outlier_map`.  Un archivo de texto con una simple visualización como tabla que nos dice por cada rebanada (columnas) en cada volumen (renglones), si es un outlier.

3. La mera verdad no logra registrar bien los volúmenes con SNR muy bajo, lo que suele suceder con alta resolución y bvalues altos (por ejemplo b=3000 s/mm²). Para el modelo del tensor no son útiles los bvalues altos, por lo que se sugiere no llegar más allá de 1200. Sin embargo, la mayoría de los solvers modernos para ajustar el tensor le dan un peso mayor o menor a cada dato dependiendo de su potencial de ser outlier. Por lo tanto, incluso dejando los volúmenes de bvals altos, los mapas resultantes son harto bonitos.

![](https://i.imgur.com/nsElYei.gif)

En esta animación se aprecia que la posición espacial no es homogénea entre volúmenes. Los volúmenes con bvalue más alto están mal registrados con respecto a los otros shells.

## 3.- Corrección de inhomogeneidad de intensidades (biasfield correction)
Este paso es también innecesario en caso de que se vaya a usar cualquier modelo que involucre dividir las DWI entre las b=0, como el modelo del tensor. De hecho, la enorme mayoría de los modelos hacen tal división en algún momento, pues lo que les interesa es la atenuación de la señal. 

La notable excepción es deconvolución esférica (CSD), que estima la distribución de la probabilidad de orientaciones de fibras directamente de la señal DWI (no de la atenuación), a partir de la deconvolución de una función de respuesta que actúa como un prototipo de cómo se porta la señal DWI en el caso de una sola población de fibras. Como se estima una sola función de respuesta por set de datos, es crucial que la señal DWI tenga intensidades homogéneas en toda la extensión de la sustancia blanca. Esta última suposición se rompe fácilmente, sobre todo si adquirimos nuestras imágenes con una antena de superficie (como la 2x2 o la cryoprobe). 

Usaremos `dwibiascorrect` de mrtrix, que en realidad es una envoltura para `N4BiasFieldCorrection` de [ANTS](http://picsl.upenn.edu/software/ants/). Por lo tanto, debes tener ANTS instalado. Los defaults de ambos comandos están diseñados para datos de humanos, así que es posible que se requiera un poco de ensayo y error hasta encontrar los adecuados. El comando en sí es muy fácil, mandando las opciones para ANTS a través de switches en `dwibiascorrect`. A continuación un ejemplo con opciones pasadas a ANTS que resultan en una buena corrección:

```
dwibiascorrect ants \
  -fslgrad 64A_dwi.eddy_rotated_bvecs bval_zeros \
  -mask mascara_64A_dwi.nii.gz \
  -ants.s 2 \
  -ants.b [10,3] \
   64A_dwi.nii.gz \
   64A_dwi_biascorr.nii.gz 
```
![](https://i.imgur.com/yVnbtRp.png)

## Checando el resultado del preprocesamiento
Para terminar, veamos la diferencia entre un ajuste del modelo del tensor a los datos originales, y a los datos preprocesados. Usaremos mrtrix para hacer esta estimación, y truquitos para hacer todo en un jalón. Aprende a usar los pipes de mrtrix por [acá](https://mrtrix.readthedocs.io/en/latest/getting_started/command_line.html#unix-pipelines). Haremos mapas RGB del vector principal de difusión, a los que llamaremos `*_v1.nii.gz`.

Primero, a partir de los datos originales:
```
dwi2tensor -fslgrad 64A_dwi.bvec 64A_dwi.bval 64A_dwi.nii.gz - | tensor2metric -vector original_v1.nii.gz -
```

Ahora, a partir de los datos con denoise y eddy (no requerimos corrección de intensidad para el modelo del tensor, y no podemos hacer unring porque los datos tienen partial fourier):
```
dwi2tensor -fslgrad 64A_dwi_eddy_rotated_bvecs 64A_dwi.bval 64A_dwi_denoised_eddy.nii.gz - | tensor2metric -vector preproc_v1.nii.gz -
```
Y los vemos con `mrview`:

<img src="https://github.com/c13inb/c13inb.github.io/assets/129544525/6b5687ec-6477-405c-87d7-36fe41e73320" width="900" height="380">

Los mapas RGB son notablemente más claros cuando son derivados de imágenes preprocesadas. Hay mucho menos verde, que era causado por el drift de las imágenes a lo largo de la adquisición en dirección dorso-ventral, cosa que fue minimizada con el registro logrado con `eddy`. Aún quedan detalles, pero ciertamente estas imágenes ya están trabajables, sobre todo en sustancia blanca.

***

# Script Don Clusterio

Siempre es bueno aprender a procesar tus imágenes paso por paso para entender el proceso y que no sea una caja negra (muy muy obscura)... y también porque no, crear tu propio código de pre-procesamiento. Sin embargo, el profesor Dr. Luis Concha (Lab C-13) nos hizo la vida mucho mas fácil y creo un script que hace tooooooodo en una sola exhibición!

El primer paso es cargar el modulo `inb_tools`, aun que este modulo debería de estar ya **cargado automaticamente**. 

El script lo puedes mandar a llamar con solo escribir en la terminal `inb_dwi_bruker_preproc.sh` y al dar `enter` podemos ver un manual de que es lo que hace y que opciones tiene. Vemos que utiliza basicamente los mismos pasos que vimos antes, incluyendo el bias field correction:

```
inb_dwi_bruker_preproc.sh

inb_dwi_bruker_preproc.sh <-i dwi.nii.gz> [-i dwi2.nii.gz] <-o outbase>

Take one or more 2D-EPI DWI acquisitions and preprocess them according to:

0. Concatenate the input DWIs if there is more than one input.
1. dwidenoise (mrtrix, Exp2 estimator - Cordero-Grande 2019).
2. eddy (fsl), including eddy_quad for quality check
3. bias-field correction (N4BiasFieldCorrection). Parameters set for rat imaging.
```

Vemos que primero pide un `-i` input (imágen DWI cruda) y despues un `-o` output (tu nueva imágen)

También el script viene con una serie de opciones de acuerdo a tus necesidades. Ya sea el permutar los axes, re-escalar el voxel, corregir el movimiento (muy recomendado) y/o voltear alguno de los vectores. Este ultimo es necesario ya que al convertir desde Bruker,  uno de los vectores sale volteado! Hay que corroborar cual es de acuerdo a tus imágenes. 
```
Options:

-p            Permute axes to 0,2,1,3 (don't do it)
-s <factor>   Scale the image voxel dimensions by some factor (e.g. 2, or 10).
              Useful for eddy, as it is expecting human data, not from rodents.
-m            Perform motion correction (mcflirt) before running eddy.
              This is useful for removing image drift during acquisition.


Flip diffusion gradient vector components:
              You can use none, one or any combination of the following.
              This is useful if your conversion from bruker data messes up the gradients.
-x            Flip x component of diffusion gradient direction
-y            Flip y component of diffusion gradient direction
-z            Flip z component of diffusion gradient direction
-t            Keep temporary directory.
```

Listo, una vez que sabemos que hace el script, lo podemos correr! (spoiler, tarda unos minutos)

```
module load ANTs/2.4.4
module load fsl/6.0.7
module load mrtrix/3.0.4


inb_dwi_bruker_preproc.sh -i 64A_dwi.nii.gz -o inb_64A_dwi -m -s 10 -z
```

Veamos nuestros outputs:
```
ls inb*
 
inb_64A_dwi_d.bval
inb_64A_dwi_d.bvec
inb_64A_dwi_deb.bval
inb_64A_dwi_deb.bvec
inb_64A_dwi_deb.nii.gz
inb_64A_dwi_de.bval
inb_64A_dwi_de.bvec
inb_64A_dwi_de.nii.gz
inb_64A_dwi_d_mask.nii.gz
inb_64A_dwi_d.nii.gz
inb_64A_dwi_de.files
```
Ahora, vas a notar que hay tres archivos `.nii.gz`, `.bvec` y `bval`, pero cada uno tiene le antecede ya sea`d`, `de` y `deb`. ¿Que significa esto? Esto no es nada mas qué los outputs deribados de cada parte del pre-procesamiento y que el script los nombra asi como guía para saber que datos pertenecen a cada paso del pre-procesamiento:

denoising:
```
inb_64A_dwi_d.bval
inb_64A_dwi_d.bvec
inb_64A_dwi_d.nii.gz
```
denoising + eddy:
```
inb_64A_dwi_de.bval
inb_64A_dwi_de.bvec
inb_64A_dwi_de.nii.gz
```
denoising + eddy + bias field correction:
```
inb_64A_dwi_deb.bval
inb_64A_dwi_deb.bvec
inb_64A_dwi_deb.nii.gz
```
...y todos los archivos deribados del eddy:
```
inb_64A_dwi_de.files
```

Y nuestra nueva imágen!
```
mrview inb_64A_dwi_deb.nii.gz
```
![image](https://github.com/c13inb/c13inb.github.io/assets/129544525/3ae921f0-e405-409d-88e7-e8a7b2422d3b)


Y al final, esta es la imágen que utilizarás para comenzar tus análisis. Mucha suerte! 😃 



:warning: OJO, en 2024 ya tenemos una mejor herramienta, [`inb_synthreg.sh`](https://github.com/lconcha/inb_tools/blob/main/inb_synthreg.sh#L9).

Registrar dos imágenes distintas es muy fácil cuando son del mismo sujeto y tienen el mismo contraste; si son de diferentes sujetos, todas del mismo contraste, pero las queremos llevar a un espacio estándar, estamos hablando de normalización, y como puede verse [[registration]], eso tampoco es difícil. El siguiente paso de complejidad es registrar dos imágenes del mismo sujeto pero con contrastes distintos (p.ej. una T1 con una T2). Habitualmente eso lo logramos utilizando una función de costo apropiada, *como mutual information*. Pero hay un caso muy difícil, aunque se trate de imágenes del mismo sujeto, que es cuando existen inhomogeneidades geométricas distintas entre las dos imágenes a registrar. Estas inhomogeneidades geométricas son, desgraciadamente, la norma en imágenes eco-planares (EPI) como las de contraste BOLD y las DWI, mientras que las imágenes T1 (SPGRE, por ejemplo), son inmunes a estos problemas. 


Por ejemplo si hacemos un registro lineal con flirt entre la T1 hacia un mapa de ADC, vemos que la parte mas anterior del cuerpo calloso de la T1 (rojos) está más anterior que la del mapa del ADC (grises):

[[images/selection_029.png]]

En esta página vamos a describir una estrategia para lograr el registro entre estas imágenes. Es importante hacer una aclaración: Es prácticamente imposible hacer un registro perfecto entre  imágenes T1 y EPI (algo que es casi garantizado, por ejemplo, entre T1 y T2). Esto es solo una estrategia que ha funcionado moderadamente bien, pero tiene mucho qué mejorar aún. 

La estrategia es utilizar mapas de volumen parcial de el LCR derivados de FAST de las imágenes T1, y vamos a registrar eso contra el mapa de ADC derivado de las imágenes DWI.

Para este ejemplo, vamos a asumir algunas cosas:
**$t1** es mi imagen pesada a T1 (a la que ya le hicimos [[brain_extraction_tool_bet]] )
,
**$adc**  es mi mapa de ADC derivado de mis DWIs (habiendo usado bet). 



``` bash 
fast -v -S 1 -n 3 -t 1 -I 1 -g -N 

  -o Fast_t1 

  $t1 

```  

Ahora haremos un primer registro entre la estimación del LCR de las imágenes T1 con el mapa de ADC. Ojo, la imagen fija es el ADC.

``` bash 

flirt 

  -in Fast_t1_pve_0 

  -ref $adc 

  -omat lin.mat 

  -out lin_csf2adc_transformed 

```

Excelente, ahora vamos a afinar este registro entre imágenes utilizando un registro no lineal:

``` bash

fnirt -v 

  --in=Fast_t1_pve_0 

  --ref=$adc 

  --fout=field 

  --aff=lin.mat

applywarp -v 

  -i $t1 

  -o t1_to_dwi 

  -r $adc 

  -w field 

```

Ahora, si vemos cómo se ve la imagen T1 (rojos) registrada no-linealmente con el mapa de ADC como referencia (gris), vemos que el cuerpo calloso encaja mucho mejor:

[[images/selection_030.png]]

Dado que esta es una operación que se realiza frecuentemente, existe un escript en el laboratorio para automatizar la tarea:

``` bassh
inb_register_t1_to_dwi_via_csf.sh
 
inb_register_t1_to_dwi_via_csf.sh <t1> <adc> <outbase> [Options]
 
Note that t1 and adc must be skull-stripped


Options

  -keep_tmp
  -tmpDir </some/folder>

 
 LU15 (0N(H4
 INB, Feb 2015.
 lconcha@unam.mx

```###### tags: `Tutorial`
# Tutorial DWI 2022

:star: **Se pueden descargar los datos desde [esta liga.](https://drive.google.com/drive/folders/1Nj_ECQ0qwe4l3Mr-vdUuESGwaLifsUiM?usp=sharing)**
:tv: **El video del tutorial [está en youtube](https://youtu.be/QG6rU1RbcBQ)**
:information_source: Los datos fueron adquiridos en un resonador GE MR Discovery 750 de 3 teslas.


## Archivos:
1. `dwis.nii.gz` : Imágenes de difusión
1. `dwis.bvec`   : Vectores del gradiente de difusión
1. `dwis.bval`   : b-valores
1. `revpe.nii.gz` : Dos imágenes b=0 con codificación de fase en sentido inverso. Se usará para pre-procesamiento de `dwis.nii.gz`
1. `revpe.bvec` : vectores de difusión
1. `revpe.bval` : b-valores.

Todos estos archivos fueron convertidos usando [`dcm2niix`](https://github.com/rordenlab/dcm2niix).

![](https://i.imgur.com/FqToTEV.png)

Las imágenes `dwis.nii.gz` tienen los ojos alargados, porque fueron adquiridas con _EPI positive blips_ (P>>A); son muchos volúmenes (106). En cambio, las imágenes revpe (4.nii.gz) tienen negative blips y son solamente 2 volúmenes (una b=0 y una DWI).


# Pre-procesamiento
No entraremos en detalles de preprocesamiento en este tutorial. Se recomienda leer [la documentación de eddy en el sitio de fsl](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/topup/TopupUsersGuide). Se sugiere usar una máquina con CUDA y fsl versión 6.0.2 o superior. No correrlo con CUDA implica varias horas de preprocesamiento.

Al terminar veremos que las imágenes están mucho menos distorsionadas:

![](https://i.imgur.com/qBuEtJY.png)


**Las imágenes preprocesadas de este tutorial, pre-cocinadas para fines prácticos, se llaman `dwi_preproc_corrected.{bvec,bval,nii}`.**

# Tensor de difusión
Revisamos que todo esté en orden. Usaré mrtrix3 para generar el tensor de difusión. Me gusta el formato `.mif`, pero bien podría escribir `.nii.gz` si me diera la gana.

Primero genero una máscara:

    dwi2mask -fslgrad dwi_preproc_corrected.{bvec,bval,nii} dwi_preproc_corrected_mask.nii

Ahora estimo el tensor de difusión:

    dwi2tensor -fslgrad dwi_preproc_corrected.{bvec,bval,nii}  -mask dwi_preproc_corrected_mask.nii  dt.mif
    
extraigo métricas del tensor:

    tensor2metric -fa fa.mif -vector v1.mif -adc adc.mif dt.mif
    
Y para visualizar los tensores sin que me distraigan los tensores gigantes del LCR, le pongo una máscara basada en ADC:

     mrcalc adc.mif 0.001 -lt dt.mif -mul dt_masked.mif

Para finalmente visualizar:

![](https://i.imgur.com/tAb2zHY.jpg)


# Tractografía

Aunque yo soy muy feliz con [mrtrix](https://www.mrtrix.org/), en este documento utilizaré [dsi-studio](https://dsi-studio.labsolver.org/) para hacer tractografía de manera automática. Existen versiones para todos los sistemas operativos. El programa es muy lógico y nos muestra el orden de los pasos que haremos. En este tutorial nos quedaremos en la creación de tractografía, y no lo llevaremos al análisis de conectividad (_connectometry_).

Empezamos cargando los datos. Primero que nada, nos aseguramos que tenemos archivos `.bvec` y `.bval` con el mismo nombre que nuestro archivo `.nii.gz`. En mi caso tenemos `dwi_preproc_corrected.nii`, `dwi_preproc_corrected.bvec`, y `dwi_preproc_corrected.bval`. 

![](https://i.imgur.com/E9FNODn.png)
![](https://i.imgur.com/7rkB3e0.png)

Al terminar de cargar (unos cuantos segundos), nos mostrará la _B-table_, una tabla que nos muestra los valores $b$, y la dirección del gradiente de difusión. Podemos notar que comenzamos con imágenes $b=0$ (sin vector asociado), y después muchas imágenes DWI con $b=2500 s/mm^2$,  luego otras $b=0$ y finalmente unas DWIs con $b=800$

![](https://i.imgur.com/szy8dSQ.png)
...
![](https://i.imgur.com/zgCZJfM.png)

La parte inferior de esta tabla me pregunta dónde guardar el archivo que se generará, y con qué nombre. Este archivo contendrá toda la información de las imágenes y los bvecs y bvals.

![](https://i.imgur.com/Wps9vCw.png)

En la pantalla principal de dsi-studio, ahora vemos el archivo que creamos (terminación `.src.gz`). Le damos doble clic para comenzar a procesar.

En la primer pestaña podemos hacer control de calidad de nuestros datos. Dando clic en cada columna de la _B-table_ podemos ver la imagen correspondiente, y cambiar rebanadas. Los botones nos permiten identificar rebanadas o volúmenes como datos a ignorar (en caso de que tengan artefactos).

![](https://i.imgur.com/ZeBaQg1.png)

![](https://i.imgur.com/NrlnfNQ.png)

En el siguiente paso generamos una máscara binaria para únicamente procesar donde hay tejido. También seleccionamos el modelo de difusión a ajustar (DTI, GQI, o QSDR). Seleccionaré GQI, y doy clic a **Run Reconstruction**. Como podemos ver, podríamos seleccionar únicamente DTI si nos interesara, pero GQI de todas maneras va a hacer DTI, así que tenemos ambos con mínimo esfuerzo.


![](https://i.imgur.com/Hk6k3Nr.png)

Esto generará un archivo `.fib` en la misma carpeta donde habíamos creado el archivo `.src.gz`, y podremos encontrarlo en la pantalla principal de dsi-studio. Le damos doble clic.

![](https://i.imgur.com/eOIXyTj.png)

Esto abrirá una nueva pantalla para todo lo relacionado a tractografía.

Agreguemos la imagen T1 para que podamos hacer un mejor registro de imágenes hacia el atlas y que la tractografía automática funcione mejor. Esto lo hacemos en **Slices** -> **Insert other images**. Y seleccionamos nuestra imagen T1 en formato `.nii.gz`. En **Slices**-->**Adjust registration** podemos ver qué tan bien o mal fusionadas están.

Ahora habilitamos _autotrack_.

![](https://i.imgur.com/1fDps7f.png)

Y en **Target** Podemos seleccionar el fascículo que queramos ver, y le damos **Fiber tracking**


Por ejemplo, el _Arcuate_Fasciculus_L_ :
![](https://i.imgur.com/vzb46KZ.png)

Esto aún lo podemos editar, usando regiones de interés que dibujamos en el panel inferior izquierdo, donde pueden apreciarse los streamlines que intersectan con el plano de imagen.

Por ejemplo, vemos unos streamlines que se van demasiado inferiores en el lóbulo temporal,  y queremos quitarlos:

![](https://i.imgur.com/Ly1F1lF.png)

Dibujamos una región donde intersectan, y la convertimos en **ROA** (_region of avoidance_).

![](https://i.imgur.com/U5JBu0n.png)

Damos clic derecho a nuestro tracto _Arcuate_Fasciculus_L_ y seleccionamos **Filter Tracks by ROI/ROA/END**.

![](https://i.imgur.com/MApBwzB.png)

Veremos que esos streamlines desaparecen.

![](https://i.imgur.com/zbEWM6b.png)
## Preprocesamiento de datos con DESIGNER2 ##

[Designer](https://nyu-diffusionmri.github.io/DESIGNER-v2/) es un pipeline muy completo y fácil de usar para preprocesamiento de DWIs. Igual que [`dwifslpreproc`](https://mrtrix.readthedocs.io/en/dev/reference/commands/dwifslpreproc.html) , encapsula muchas herramientas disponibles en fsl y mrtrix, como [topup](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/topup), [eddy](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/eddy), y [mrdegibbs](https://mrtrix.readthedocs.io/en/dev/reference/commands/mrdegibbs.html). Pero quizás su herramienta más poderosa sea su [denoiser](https://nyu-diffusionmri.github.io/DESIGNER-v2/docs/designer/background/#dwi-denoising-with-mppca).

La manera más fácil de usarlo es con [Singularity](singularity_presentation.md) (Apptainer).

```bash
module load singularity

designer_container=/home/inb/soporte/lanirem_software/containers/designer2.sif

singularity run --nv $designer_container \
  designer \
  -eddy \
  -mask \
  -denoise \
  -rpe_pair bids/sub-26651/fmap/sub-26651_acq-hb_epi.nii.gz \
  -pe_dir AP \
  bids/sub-26651/dwi/sub-26651_acq-hb_dwi.nii.gz \
  outputdesigner.nii
```


El switch `--nv` permite a singularity utilizar CUDA. No es necesario usarlo si la máquina no tiene tarjeta NVIDIA (podemos revisar eso con `lspci | grep VGA`).

![alt text](images/designer.png)


La mejoría de Designer2 con respecto a `dwifslpreproc` es notoria.
![alt text](images/designervsmrtrix.png)

:information_source: Revisa esta [tabla comparativa de denoisers](https://github.com/c13inb/c13inb.github.io/blob/master/images/denoisers.pdf).## Algunos Enlaces Interesantes ##

**3D Slicer**

Es un programa gratuito para el análisis de imágenes y visualización científica

[[images/3dslicer.png]]
 

**ITKsnap**
 
Es un programa para visualización y segmentación de imagenes 3D

 [[images/itksnap.png]]


**Volbrain**

Es un sistema de volumetría de imágenes de resonancia magnética en línea 

[[images/image10.png]]


**DSI Studio**
 
Es un programa para análisis, corregistro y visualización de imágenes de difusión

[[images/dsistudio.png]]


**Camino**

Es un programa para procesamiento de imágenes de difusión

 [[images/camino.png]]

 

**Noodi**

Neurite Orientation Dispersion and Density Imaging (NODDI) es una nueva técnica de difusión en MRI para imágenesde microestructura del tejido del cerebro.

 [[images/noodi.png]]


**Mrtrix3**

[[https://github.com/jdtournier/mrtrix3|MRtrix3]] provee un set de herramientas para realizar varios análisis avanzados de difusión en MRI, incluyendo: constrained spherical deconvolution (CSD), tractografía probabilística, track-density imaging y apparent fibre density# Preguntas Frecuentes

¿Por qué no abre Firefox?
:     Si bien puede haber  algún problema con la aplicación, en la mayoría de los casos el problema se debe a que una sesión de Firefox quedó abierta en alguna otra máquina. Firefox no permite dos sesiónes de usuario al mismo tiempo por el mismo usuario en diferentes máquinas. Esto se puede solucionar abriendo la máquina dónde está la sesión de Firefox y cerrarlo. Sin embargo si la máquina en cuestión está ocupada, es posible hacer una sesión [ssh](./SSh) a la máquina en cuestion y ya ahí [matar el proceso](./Bash:-Kill), de preferencia a través de la terminal.

Cuándo cambio de usuario la máquina no responde y la pantalla se pone negra
:     Esto se debe a que hubo algún error en la carga del sistema de gráficos en el equipo. Puede deberse a un fallo de la tarjeta de video, que puede agravarse por programas que quedan abiertos por alguno de los usuarios. Es recomendable cerrar los programas en ejecución y de ser posible salir de la sesión. Si este problema se presenta, lo mejor es llamar al administrador del sistema para que restablezca el sistema.


¿Por qué cuándo paso mis PAR/REC del Philips a Penfield no se ven los archivos NIfTI?
:     Es dificil de saber la causa de esto, en ocaciones puede ser por errores en el clúster mientras se copiaban los datos, lo cuáles pueden llegar incompletos. Hay que volver a pasarlos desde la base de datos del resonador.
NO debes borrar los datos de la base de datos del Philips hasta que se este seguro que se tienen las imágenes íntegras.

# Alertas

¿Cómo lograr que médicos clínicos vean la IRM?
:     Para compartir las imágenes de IRM con médicos clínicos los datos tienen que extraerse directamente de la máquina de dónde se hayan exportado en una memoria externa, ya que la mayoría de los programas médicos usados en clínica no pueden leer el disco grabado en VIRTUAL. Los archivos pueden ser enviados de forma comprimida (.zip) para mayor velocidad y eficiencia.


# Trucos de Luis Concha ##
Algunos trucos de cosas truculentas, y otras muy bobas pero que me tardé en entender cómo hacerlas.

Lo que hago más frecuentemente es un for loop, que directamente en la terminal debe usar punto y coma en sustitución de un script formal en dónde se hace una nueva línea. Por ejemplo:

``` bash
for sujeto in 301 302 303
do
  echo "trabajando en sujeto $sujeto"; done
```
en la terminal quedaría:

```bash
for sujeto in 301 302 303; do echo "trabajando en sujeto $sujeto"; done
```
Nótese la ausencia de punto y coma entre do y echo.

En caso de tener organizados a los sujetos cada uno con una carpeta, y con identiricadores claros, como en el caso de freesurfer, es muy fácil hacer algo repetitivo:

```bash
for sujeto in 3??; do recon-all -all -subjid $sujeto;done
```

## Poner resultados FEAT en Freesurfer ##
Una manera muy fácil se explica [aquí](./FSL:-project-to-fsaverage).

Una alternativa más viejita y complicada está [acá](./FEAT2FS).


# Tutorial básico
:tipping_hand_person: Para un tutorial paso a paso para el análisis de un diseño de bloques, pulsa [aquí](./FSL-tutorialFeat).


## Para iniciar el uso de FEAT 

1.- Convertir archivos al formato adecuado 

Los archivos T1 y Funcional pueden estar en formato DICOM o en formato PARREC y ambos deben ser convertidos a formato NIFTI.

Para realizar dichas conversiones revise las siguientes ligas:
+ [De DICOM a NIFTI](./Procesamiento-Imagen:-De-DICOM-a-NIFTI)
+ [De PARREC a NIFTI](./Procesamiento-Imagen:-De-PARREC-a-NIFTI)

2.-  Utilizar BET (Brain extraction tool) 

Para poder utilizar la imagen estructural en FEAT, esta no debe tener tejido ajeno al encéfalo como lo las meninges o el cráneo. Para quitar estas estructuras de la imagen se usa en la terminal el comando [BET](./FSL_-Brain-extraction-tool-BET).

3.- Abriendo FEAT 

Para abrir la herramienta, escribir en la terminal:**Feat** (¡No olvidar la mayúscula!)

## Tips para uso de FEAT
+ ¿Qué datos ingresar en [cada pestaña]?(./FEAT-Datos-en-pestañas)
+ [FEAT alto nivel](./FEAT:-Análisis-de-alto-nivel) (segundo y tercer nivel): En esta sección se describe cómo hacer un **análisis de alto nivel** con sus diferentes opciones.
+ [FEAT render highres](./FEAT:-render-highres): En este apartado podrás aprender a **fusionar una imagen funcional o anatómica** base con un mapa estadístico.
+ [FEATQuery](./FEAT:-FEATQuery): Con esta herramienta puedes analizar el **flujo de cambio de la señal BOLD** en una región específica y obtener su porcentaje de cambio en relación a una condición experimental en particular. 
+ [Intersección](./FEAT_-Intersección): Este análisis te permite encontrar las **regiones en común** entre dos categorías o contrastes de interés (ej.  A > B  +  C > B = intersección AC > B).
+ Dual Regression: Este análisis es utilizado para identificar de manera individual en los sujetos los mapas espaciales y cursos temporales asociados (componenetes), que fueron generados con un análisis ICA para multiples sujetos.

+ [Ejemplo sin GUI](./FEAT:-Modificar-sin-GUI) Aquí aprenderás a **engañar a FEAT** para modificar el modelo sin la GUI.

## ¿Qué hay dentro de la carpeta FEAT?
Descripción breve de los archivos dentro de una [carpeta FEAT](./FEAT_-Archivos-carpeta-FEAT).
This tutorial is fantastic
https://surfer.nmr.mgh.harvard.edu/fswiki/FsTutorial/FslFeatFreeSurfer

Basically:

  -  Register the functionals to the freesurfer's T1 volume.

``` reg-feat2anat --feat /path/to/analysis.feat --subject subjectID ```

If registration to std space has not been performed, you need to do it first.
If it is a gfeat, then you may need to copy the ''/reg'' directory from the first level analysis.

However, step 1 was failing for me, specifically during reg-feat2anat. I tracked the bug to this:
[[http://www.mail-archive.com/freesurfer@nmr.mgh.harvard.edu/msg29122.html]]

All that is needed to fix the registration bug is to replace the script as provided in the above link. The only difference between the old version and the new one is that the new one specifies the file suffix, while the old one does not. Stupid bug, I lost a whole morning on this.


While you can see the volume overlaid on the surface with tksurfer, as the tutorial suggests, freeview works much smoother.

First, load the backround, subject-space t1 and surface

```freeview -v subject/mri/brain.mgz -f subject/surf/lh.white ```

now, load the overlay, but taking care to specify the registration needed to go from fMRI subject space to T1 subject space. The registratin is featDirectory ''/reg/freesurfer/anat2exf.register.dat''


[[images/selection_027.png]]

And, to load data that is in standard space onto the subjects surface, for example after comparing two copes of the same subject using a fixed effects model, we need another transformation, this time anat2std.register.dat.

[[images/selection_028.png]]


That same transformation can also be used to load the volumes (e.g. zstat1.nii.gz) to overlay on top of brain.mgz of the subject.
## FEATs DE ALTO NIVEL

Los análisis de alto nivel se dividen en dos tipos: segundo y tercer nivel. Los análisis de segundo nivel incluyen, por ejemplo, contrastes en un mismo sujeto (utilizando sus diferentes COPES), mientras que los análisis de tercer nivel constituyen el promedio de un grupo de sujetos en una condición o contraste particular (directorios FEAT).

## Segundo nivel 

1. En la pestaña de Data se selecciona la opción: **inputs are 3D images from FEAT directories**, en input se seleccionan los COPES a utilizar (pertenecientes a un mismo sujeto). En el recuadro de **Output directory** se indica la ruta a la carpeta dónde se quiere guardar el archivo (si no se indica la ruta el default es la carpeta de dónde se están obteniendo los archivos FEAT ) y el nombre del análisis.

`Ejemplo: /datos/maquina/usuario/carpeta/subcarpeta/NOMBRE_DEL_ANALISIS` 

2. En la pestaña de **Stats** se elige entre **fixed effects** o **mixed effects** ; si son diferentes sesiones del sujeto se considera la opción de **Mixed effects**, pero si es una misma sesión se elige **fixed effects**. Dependiendo de cómo se realizó el primer nivel (condiciones A-B-A-B ) se elige **Model setup wizard** donde se permite elegir un promedio para un solo grupo así como opciones para dos grupos. La opción de **Full model setup** permite modelar el análisis e incluir contrastes entre los COPES utilizados como inputs. Dependiendo del número de inputs (COPES) aparecerán cierto número de EVs, sin embargo se pueden añadir más EVs y crear otras categorías (ej. la suma de dos EVs ). Además en esta opción (**Full model setup**) se pueden realizar contrastes o comparaciones entre las EVs:

[[images/full_model_setup.png]]

3.**Post-stats** aquí se puede seleccionar una máscara para delimitar posteriormente la región de interés y reducir de esta forma el número de comparaciones entre voxeles. Aquí se indica si se quiere, o no,  hacer corrección y de qué tipo, el valor de Z y el valor de la P. Además existen otras opciones para desplegar los resultados con una imagen de fondo que corresponde a un sujeto (sea su anatómica o su funcional) o al promedio de todos. Otras opciones permiten homogeneizar los valores de la Z, o bien, hacer transparentes los blobs para poder apreciar la imagen de fondo.
*Se puede elegir que aparezcan en nuestros resultados las gráficas con el curso temporal de la señal  (**time series plots**). 

## Tercer nivel

1. **Data** aquí se selecciona la opción: **inputs are lower-level FEAT directories**. En el recuadro de **number of inputs** se indica el número de FEATs que vamos a incluir, después se seleccionan sus directorios: COPES en particular ''(/datos/maquina/usuario/carpeta/subcarpeta/ejemplo.gfeat/cope1.feat)'',  o bien,  seleccionar todo el directorio ''(/datos/maquina/usuario/carpeta/subcarpeta/ejemplo.gfeat)'' y se corren todos los COPES simultáneamente. El recuadro de **output** es igual que en el segundo nivel.

2. En la pestaña de **Stats** se presentan varias opciones de **mixed effects** para modelar los datos, el comunmente usado porque es rápido y preciso es **FLAME 1** (para más información sostener el cursor sobre el recuadro o visitar http://fsl.fmrib.ox.ac.uk/fsl/fsl4.0/feat5/detail.html). Las opciones de ajuste del modelo son iguales a las de segundo nivel. 
En la opción de **Full model setup** tendremos una EV , si tenemos un solo grupo esa columna nos generará la media de todos los inputs que hayamos incluido (se incluyen poniendo un 1 en cada casilla); si tenemos alguna otra variable (ej. edad, respuestas correctas) que nos interese ingresar al modelo se pueden agregar más EVs y en cada input se van colocando sus valores. Si tenemos dos o más grupos, lo indicamos en la columna de **Group** numerando los inputs según el grupo (ej. 1,1,1,1,1,2,2,2,2,2,), además añadimos una EV por cada grupo (separarlos como variables explicativas nos permite hacer contrastes entre ellas, separar las medias, sacar medias considerando la influencia de cada una, etc.). Abajo de los rótulos de EV1, EV2.... hay una casilla para indicar su nombre. 
En la pestaña de **Contrasts & F-tests**  podemos especificar de qué EV queremos una promedio, ejemplo:   EV1 música , EV2  habla.

[[images/full_model_setup_3level.png]]

3. En **Post-stat**s se siguen las mismas indicaciones que para el segundo nivel.# Archivos dentro de una carpeta FEAT 

## Carpetas 

### Custom_timing_files 
En esta carpeta se encuentran tus archivos .times, con el nombre ev#.tx. El número se relaciona con el orden en que fueron ingresados.

### logs 
Aquí se encuentran archivos que indican qué hizo fsl para realizar el analisis FEAT.

### mc (motion correction) 
Aquí se encuentran los archivos referentes al análisis mcflirt de corrección de movimiento.

### reg 
Aquí se encuentran los archivos relacionados con el registro de la imagen funcional a la anatómica. 

### reg_standar 
Aquí están los archivos sobre el registro hacia la imagen standar.

### stats 
Aquí estan los archivos relacionados al análisis estadístico. Estos archivos muestran los mapas estadísticos en la imagen funcional, desde archivos pe, cope, varcope e incluso los zstats. 

### tsplot 
Aquí tienes archivos relacionados a tu señal BOLD y como se ajusta a tus diferentes variables. 

## cluster_mask_zstat#.nii.gz 
Estos archivos son máscaras de los clusters de cada uno de tus contrastes. Al abrirlos en fslview, verás cada cluster con intensidades diferentes. El que tiene mayor intensidad tinene mayor número de voxeles, y así sucesivamente. 

## cluster_zstat#.txt/.html 
Estos archivos te muestran los cluster que pasaron el umbral estadístico en espacio del sujeto, es decir, las coordenadas están en voxeles.

## cluster_zstat#_std.txt/.html 
Al igual que el archivo anterior, éstos te muestran los clusters que pasaron el umbral estadístico pero en el espacio estándar, por lo tanto las coordenadas estarán en milímetros (mm).

## lmax_zstat#.txt 
Estos archivos te muestran los voxeles con mayor valor estadístico de cada uno de los clusters.

## rendered_thresh_zstat#.nii.gz 
Ente archivo lo puedes abrir con fslview. Muestra los clusters que pasaron el umbrar estadístico sobre la imagen funcional del sujeto, en una escala de color rojo. 

## thresh_zstat#.nii.gz 
Te muestra los clusters que pasaron el umbral estadístico. Es en este archivo en donde puedes especificar el color de la escala y los valores mínimos/máximos de brillo en fslview.

"" desing.con/.mat/.frf/.fsf/.min 
Estos archivos tienen que ver con el diseño de tu modelo. Principalmente el archivo [[enganar|desing.fsf]],  el cual es la receta que sigue fsl para realizar todos los análisis que usualmente especificas con la GUI de FEAT. 
## ¿Qué datos ingresar en cada pestaña?

### Data
Pulsar el botón **Select 4D** data para seleccionar el archivo en formato NIFTI ya reorientado con las imágenes funcionales.

**Output directory:** seleccionar la carpeta de destino.

Colocar el **TR** usado durante la adquisición.


### Pre-stats
**Slice timing correction:** 

       Pulsar el botón y elegir el modo en que fueron adquiridas las imágenes.
	   
### Stats
Activar opción **Add motion parameters to model**

Pulsar el botón **Full model setup**
 
  **EVs**

       En la opción Number of original Evs colocar el número de bloques.
       En la opción EV name colocar el nombre designado a cada bloque.
       En la opción Basic shape: elegir Custom (3 column format). Se desplegará la opción para elegir el archivo .times convertido de eprime.

   **Contrasts & F-tests**

	Elegir el número de contrastes deseado
	Pulsar el botón Done y aparecerá una ventana con el modelo
	
### Registration
Activar la opción **Main structural image**. Elegir el archivo de la imagen anatómica en formato NIFTI y reorientado.

Después de esto se generará una carpeta con la extensión FEAT que es el resultado final.
1.Abrir FEATQuery desde la terminal:   ''arafat@tanner:~$ Featquery'' o abrirlo desde la interfaz de FSL (**Misc**)


2. Ingresa el número y la ruta de los directorios FEATs (promedios o contrastes) en el recuadro de **Number of FEAT directorie**s.  Se puede elegir un sólo sujeto o un promedio de varios los sujetos, la diferencia será que en la lista final, en el primer caso, cada línea será un punto temporal en el que se evalúa la respuesta hemodinámica (en el mismo sujeto), mientras que para el análisis de un grupo cada linea en la lista es un sujeto. 

3. La segunda opción es seleccionar la región de interés ya sea definida anatómicamente o funcionalmente: 

  a) seleccionar una máscara de los atlas ya disponibles en FATQuery  con la opción de **Use atlas**; 

  b) seleccionar una máscara de otros atlas que no estén ahí (ej. FSLview) cargando el archivo;
 
  c) seleccionar una máscara de una región de interés (ROI) definida funcionalmente (de algún resultado FEAT). En esta última podemos considerar la opción de darle las coordenadas específicas de un voxel, o bien, analizar una región más grande usando una máscara de algún cluster.

4. **Output options** , en esta sección se especifican los datos que queremos que se desplieguen como resultado del análisis. La primera opción (**use atlas**) nos permite utilizar el pico máximo de activación y buscar en el atlas que elijamos la estructura que se superponga con nuestro voxel. Las siguientes opciones permiten  :

  a) **Convert PE/COPE values to %** , transformar los valores de nuestros parámetros en porcentajes, está opción es casi obligatoria.

  b) **Do not binarise mask**  respeta y mantiene los valores de cada voxel de la máscara (funcional), como resultado del FEAT.

  c) **Change post-interpolation thresholding of mask**, esta opción permite interpolar la máscara de un espacio estándar o de alta resolución a un espacio de baja resolución (imagen funcional).

  d) **Threshold stats images as well as masking**, esta opción se selecciona si se desea considerar unicamente los voxeles (de la máscara) que pasen un determinado umbral estadístico (el valor se debe de especificar en el recuadro).

  e) Las opciones de **Create timeseries plots** y **popup results in the web browser** son seleccionadas por default y son similares a las que se obtienen en los análisis FEAT.

  f) **Featquery output directory name**, si no se especifica nada (ni nombre ni ruta) el resultado se guarda en una carpeta denominada featquery dentro del archivo que contiene el FEAT que se está utilizando. 

5. Simplemente  **GO**1. Realizar un análisis FEAT de alto nivel (**higher-level analysis**) donde se promedie la activación de la primera condición A > B (ej. música > silencio) en todos los sujetos. En la pestaña de **Post-stats** se debe de seleccionar una máscara en el recuadro de **Pre-threshold masking**, esta máscara debe salir del resultado obtenido del análisis de alto nivel la segunda condición de interés
C > B (**cluster_mask_zstat#.nii.gz**).

2. Realizar un análisis FEAT de alto nivel de la segunda condición  C > B (ej. habla > silencio). Se repiten los pasos del punto 1, para este análisis se escoge la máscara del contraste de la primera condición A > B (**cluster_mask_zstat#.nii.gz**).

3. Los dos análisis FEAT nos arrojarán las regiones en común, éstos serán muy similares pues en ambos casos la áreas de búsqueda se delimitan por el contraste opuesto:

     ```a) música > silencio (delimitado por la máscara de habla > silencio)```

     ```b) habla > silencio (delimitado por la máscara de música > silencio)```
# Para hacer modificaciones a tu modelo sin utilizar el GUI

Este truco te ayudará cuando el GUI de FEAT:

* no te deja hacer algunos cambios específicos
* tu modelo tiene muchas variables (al generar el modelo, FSL se traba!!)

Lo que tienes que hacer es buscar y abrir el archivo desing.fsf que se encuentra en la carpeta nombre.feat o nombre.gfeat (inciso a de la imagen). 

[[images/wikidesing.png]] 

Al abrirlo verás un archivo como el del inciso c de la imagen. Sólo falta que realices los cambios específicos que quieras, algunos de estos cambios están indicados con flechas rojas. Al final guarda los cambios. 

Para correr el análisis con los cambios, abre el GUI de FEAT (recuerda indicarle que tipo de análisis es: Bajo o Alto nivel) y da click en el boton de __Load__, carga tu archivo desing.fsf, da click en __Go__ y LISTO!

Incluso puedes crear un análisis y guardarlo con el nombre que quieras, como se muestra en el inciso b de la imagen.  

### ¿Para qué sirve el comando render highres?
Este comando permite integrar como una sola imagen un fondo anatómico o funcional con un mapa estadístico de activación.

La estructura del comando es la siguiente:

    renderhighres <directorio feat> <espacio> <fondo> <autoumbral> [mínZ máxZ]
  
    directorio feat: Seleccionar la carpeta FEAT que contenga el mapa estadístico a emplear.

    espacio: Seleccionar entre "standar" o "highres".

    fondo: Seleccionar entre "standar" o "highres".

    autoumbral: Seleccionar "0" o "1". En caso de elegir "1", se emplearán los umbrales calculados para el mapa estadístico; de lo contrario, se utilizaran los valores de mínZ y máxZ.**FIJI** (**F**IJI **I**s **J**ust **I**mageJ) es una herramienta muy útil para el procesamiento y análisis de imágenes, especialmente histológicas. En esta entrada abordaremos algunas de sus características principales. 

Este software esta lleno de opciones para procesar las imágenes y ademas cuenta con una librería muy vasta de plugins para realizar diferentes tipos de análisis. Toda la comunidad que desee compartir sus trucos en FIJI para sus análisis es bienvenido a colaborar en esta wiki!

### Descarga FIJI
En el siguiente [link](https://imagej.net/software/fiji/downloads) podrás encontrar los enlaces de descarga dependiendo de tu sistema operativo.

### Tutoriales de supervivencia

* Videos en su canal de YouTube [aquí](https://www.youtube.com/@fijichannel) 
* Tutoriales y guias básicas de procesos y análisis [aquí](https://imagej.net/imaging/index)
* Cómo hacer _stitching_ (mosaicos) con [Fiji-stitching](./Fiji:stitching)


***

## Análisis de imágenes

[Tensor de Estructura (Structure Tensor)](./TensorEstructura) es una herramienta que se utiliza para procesar y analizar la información direccional y de coherencia local de una imagen. Es un método análogo al tensor de difusión de la resonancia magnética sensible a difusión, pero aplicado en imágenes histológicas. En el link encontraras mas información y un tutorial de como aplicarlo.





# Tutorial FEAT
Luis Concha
Instituto de Neurobiología, UNAM Campus Juriquilla
lconcha@unam.mx

En este tutorial usaremos las computadoras del Lanirem. En caso de querer instalar fsl en su computadora, [sigue éstas instrucciones]
(https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FslInstallation).

Una vez que entremos con nuestras credenciales, abrimos una terminal.



## Conversión de formato
Ahora vamos a convertir nuestros archivos desde formato DICOM hacia formato NIFTI (nii). Para ello usaremos el programa [`dcm2niix`](https://github.com/rordenlab/dcm2niix), pero primero debemos navegar hacia nuestra carpeta. Para fines de este tutorial, todos los archivos estarán grabados en la ruta `/misc/hahn2/nobackup/fMRI2021`

Por lo tanto, en la terminal tecleamos:
```bash=
cd /misc/hahn2/nobackup/fMRI2021
```

Si queremos ver el contenido de la carpeta, usamos el comando:
```bash=
ls
```

Y veremos que existe una carpeta llamada `datos`. Ahí están los Dicoms. Podemos ver el contenido:
```bash=
ls datos
```
Vemos que tiene dos carpetas, una para los datos anatómicos `1401_T1W_3D_SENSE` y otra para los datos funcionales `1101_fMRI_SMA`. Adentro de cada una de esas carpetas hay muchos, muchos archivos con extensión `.dcm` (uno para cada rebanada).

Los archivos dicom serán compartidos por todos en el tutorial, pero cada quien requiere su carpeta para todos sus resultados. Necesitamos hacer una carpeta personal, a la que llamaremos de acuerdo a nuestro nombre de usuario (en este tutorial, es `fMRI_test`) y la haremos dentro de este mismo directorio, así que es fácil:

```bash=
mkdir fMRI_test
```

:warning: **No escribas `fMRI_test`, sino tu nombre de usuario.** Tu nombre de usuario se puede ver en la terminal, justo antes de la `@`. Y también puedes conocerlo tecleando el comando `whoami`.


Para convertir los datos de DICOM a NIFTI, el programa `dcm2niix` espera una ENTRADA (carpeta donde están los dicoms), y opcionalmente una SALIDA (carpeta donde queremos grabar los niftis, `-o`; el default es la carpeta de entrada, pero no es recomendable mezclar ambos tipos de archivos). Por lo tanto, para convertir los datos anatómicos el comando queda como:

```bash=
dcm2niix -o fMRI_test datos/1401_T1W_3D_SENSE/
```

Igualmente, convertimos los datos funcionales:
```bash=
dcm2niix -o fMRI_test datos/1101_fMRI_SMA/
```

Si vemos el contenido de nuestra carpeta personal, encontraremos archivos nifti:
![](https://i.imgur.com/KLIdKOL.png)


:information_source: Los nombres de los archivos se generan a través de los meta-datos de los archivos DICOM, que por default son la fecha de adquisición y tipo de imagen. Por lo tanto, los nombres de los archivos quedan muy largos.  El comportamiento de dcm2niigui se puede modificar en Help-Preferences, pero por ahora dejaremos los valores por defecto.


Ahora que tenemos nuestros datos, podemos procesarlos.

# FEAT

En la terminal, escribimos `fsl`. Se abrirá el menú de fsl. Seleccionamos el quinto, `FEAT FMRI analysis`.
![](https://i.imgur.com/tSlUA52.png)

En la parte superior, dejaremos puesto `First-level analysis` y `Full analysis`. Si quisiéramos hacer análisis de grupo, cambiaríamos esa opción a `Higher-level analysis`, y si quisieramos brincarnos algunos pasos del análisis, quitaríamos `full analysis` y seleccionaríamos alguna de las otras opciones.

Primero, indicamos nuestro archivo con las imágenes funcionales. Para ello, presionamos el botón que está en la pestaña *Data*, que dice `Select 4D Data`. Usamos el ícono del folder para navegar a donde está nuestro archivo, que es en la carpeta `/misc/hahn2/nobackup/fMRI2021/USUARIO` (eecuerda cambiar `USUARIO` por tu login). El archivo se llama `1101_fMRI_SMA_fMRI_SMA_SENSE_20121004193706_1101.nii`. Seleccionamos `OK`, y nuevamente `OK` en la ventanita de `Select Input Data`.

Aprovechamos y ponemos la ruta del `Output directory`, que en este tutorial será en `/misc/hahn2/nobackup/fMRI2021/USUARIO/miprueba` (eecuerda cambiar `USUARIO` por tu login). Para ello podemos escribirlo directamente en el recuadro de texto, o utilizar el ícono del fólder y navegar a la carpeta /home/vagrant/cursofmri y ahí escribir `miprueba`. 

:information_source: El programa FEAT siempre agregará el sufijo `.feat` a la carpeta output que nosotros indiquemos. Sin embargo, esto no lo muestra en la caja de texto de `Ouptut directory`. Así, el resultado quedará en la ruta: `/misc/hahn2/nobackup/fMRI2021/USUARIO/miprueba.feat` 

:information_source: los nombres de archivos en linux son sensibles a mayúsculas/minúsculas, y no deben contener espacios.

![](https://i.imgur.com/keRoP3W.png)

Saldrá una advertencia:
![](https://i.imgur.com/jVO9s1g.png)

Esto nos está diciendo que el default del programa es hacer extracción de cerebro en las imágenes anatómicas, así que debemos poner imágenes anatómicas también con extracción de cerebro (ver adelante). Ahora, decimos `OK`. Podemos ver que en la pestaña *Data*, el software ya reconoció que nuestro archivo tiene 110 volúmenes, y que el TR es de 2 segundos. Si no lo hubiera reconocido, tenemos la opción de escribirlo (este dato lo sabríamos de acuerdo a nuestra adquisición). Dejamos las otras opciones intactas, pues no necesitamos eliminar volúmenes, y el filtro pasa-altas está en 100s (de forma predeterminada aparece 60, o 100), que es un buen valor por default.

Vamos a la pestaña *Pre-stats*. Lo único que cambiaremos es `Slice Timing correction`, a `Interleaved`. Este parámetro depende de cada tipo de adquisición. Podríamos cambiar el nivel de suavizado de la imagen mediante FWHM, pero el valor 5 mm por ahora es bueno (normalmente se utilizan FWHM con valores de 1.5 a 2 veces la dimensión del voxel).

![](https://i.imgur.com/jZXBNw6.png)


Pasamos a la pestaña *Registration*.

Activamos el botón `Main Structural image`. Aquí vamos a poner una imagen anatómica de nuestro sujeto, pero primero debemos hacerle extracción de cerebro. 



### Extracción de cerebro

Regresemos a la ventana principal FSL y presionemos el primer botón, `BET brain extraction`.

En `Input Image`, usemos el botón del fólder para ir a buscar nuestra imagen anatómica, que se llama `1401_T1W_3D_SENSE_T1W_3D_SENSE_20121004193706_1401.nii`. La salida se pone automáticamente, con el mismo nombre del archivo de entrada, pero con un `_brain` agregado.

![](https://i.imgur.com/Cm0mjFi.png)


**Regresamos a la ventana FEAT**, pestaña *Registration*. Usemos el botón de fólder para incluir una `Main Structural Image`, y seleccionamos nuestra nueva imagen (poner la que termina con `_brain`), presionamos `OK`.

![](https://i.imgur.com/wMhNYiE.png)


Vamos a la pestaña *Stats*. 

Dejamos activado `Use FILM prewhitening`. En el primer botón, apretamos el botón `Don’t Add Motion Parameters`, y en el menú que se abrirá, seleccionamos `Standard Motion Parameters`. Y ahora presionamos `Model setup wizard`.

![](https://i.imgur.com/Axsct70.png)


Nuestro paradigma fue de movimiento de mano, 30 seg sí, 30 seg no, iniciando con reposo. Por lo tanto, seleccionamos el modelo `rArA...`, y dejamos en 30 los periodos `rest` y `A`.

![](https://i.imgur.com/bDZGf9n.png)

Presionamos `Process`. Veremos el paradigma, con la línea de tiempo en la vertical. Hay tres columnas, la primera es el tiempo, con barras blancas cada 20 segundos. La segunda columna es nuestro paradigma experimental (reposo-actividad), pero convolucionado con la respuesta hemodinámica. La tercer columna es la derivada de la primer columna, y se calcula automáticamente.

![](https://i.imgur.com/2pBpqiC.png)


Por ahora no haremos nada en la pestaña *Post-stats*.

![](https://i.imgur.com/h1xMD2U.png)


**Estamos listos!** Presionamos `GO`. El proceso tardará 10 a 15 minutos. Se abrirá una página web (local) en el navegador de internet, donde veremos el progreso. En caso de que cerremos la ventana, o que ésta no se haya abierto por default, podemos encontrar el archivo `.html` en la siguiente ruta:
`/misc/hahn2/nobackup/fMRI2021/fMRI_test/miprueba.feat/report.html`

![](https://i.imgur.com/Sb9K4F7.png)


## Revisando resultados.

Esta página tiene 5 pestañas. *Registration* mostrará los resultados del registro de las imágenes funcionales con las T1, y éstas con el atlas. *Pre-stats* nos mostrará resultados de la corrección de movimiento y otros pre-procesos. *Stats* nos indica el modelo estadístico que estamos probando. *Post-stats* nos muestra el resultado de la evaluación estadística por voxel, después de haber hecho las correcciones pertinentes por comparaciones múltiples (Random-field theory, en nuestro caso). Finalmente, *Log* es una bitácora de los procesos que hizo el programa, y es útil para revisarlo en caso de que algo haya fallado.

En la pestaña *post-stats* podemos ver que nuestro modelo muestra un muy buen ajuste con la señal BOLD en la región motora izquierda, correspondiente al paradigma experimental (mover la mano derecha).

![](https://i.imgur.com/lg0tGH1.png)

Si damos clic en el mapa de resultados, nos aparecerá una tabla que indica los clústers encontrados, su volumen, sus coordenadas,  y su significancia estadística.


Regresando a la página de *post-stats*, más abajo, podemos ver la señal temporal BOLD en el voxel que mayor significancia estadística tuvo de todo el cerebro. En rojo la señal BOLD de nuestro sujeto, y en azul y verde el modelo experimental (es decir, el diseño de bloques convolucionado con la respuesta hemodinámica canónica).

![](https://i.imgur.com/jB5T4wE.png)

Si damos clic en la serie temporal, veremos más información relevante. En el caso de modelos de bloques, es fácil ver la respuesta hemodinámica asociada al bloque, si se alinean todos los eventos para iniciar en t=0.

![](https://i.imgur.com/LPl2O85.png)



## Visualización interactiva de resultados

Usaremos el programa `fsleyes`, dándole como argumento (entrada), la carpeta `.feat` que se hizo como resultado de nuestro análisis.

```bash=
fsleyes -s feat fMRI_test/miprueba.feat
```

:information_desk_person: La opción `-s feat` le dice a `fsleyes` que vamos a querer ver los resultados de un análisis de FEAT, así que automáticamente abre varias sub-ventanas para hacernos la vida fácil.

Agregaremos nuestro mapa estadístico, en `File->Add from file->`, y navegamos hacia dentro de nuestra carpeta de resultados `.feat`, a buscar el archivo `thresh_zstat1.nii.gz`.

![](https://i.imgur.com/3aES11o.png)

Teniendo seleccionada la imagen `thresh_zstat1` en la sub-ventana *Overlay list*, vamos a la parte superior derecha, donde vemos los diferentes mapas de color.  Seleccionamos el segundo (`Red-Yellow`), o algún otro que nos agrade.

![](https://i.imgur.com/VGk29uj.png)

Y cambiemos el rango de intensidades. Dado que lo que vemos en color es el valor *z* del ajuste estadístico para cada voxel, y habíamos elegido en el software que para ser considerado parte de un cluster, el voxel tendría que tener *z*>3.1, pongamos dicho valor como mínimo. El máximo depende de los valores resultantes de nuestro mapa, y el elegido automáticamente fue el valor máximo encontrado. Podemos cambiarlo, si queremos.

![](https://i.imgur.com/c52M0gh.png)


Ahora podemos navegar por el volumen, y ver en tres planos el resultado, de manera interactiva. Podemos dibujar un recuadro con el botón derecho del mouse, y se hará un zoom automáticamente a esa zona. Para restablecer el zoom, podemos poner 100 en el factor zoom, o usar el botón de la lupa que tiene una flecha.


Podemos usar la tabla de los clústers que habíamos visto en la página html, pero ahora interactiva. Para ir a ver cada cluster, podemos dar clic en el ícono de la flecha que apunta a la derecha, y nos llevará al centro del clúster (técnicamente, al voxel con *z* más alto).

![](https://i.imgur.com/i7GEznP.png)

# FMRIB Software Library - FSL

FSL es una libreria _open access_ de herramientas para el análisis de imagenes de resonancia magnética, desarrollada por investigadores de la Universidad de Oxford. Al día de hoy cuenta con una colección extensa para el análisis y procesamiento de imágenes estructurales, pesadas a difusión (DWI) y funcionales (fMRI). La librería FSL no le hace el feo a nadie y la puedes descargar en cualquier sistema operativo Linux, macOS o Windows (bueno, poquito a windows, hay que hacerlo mediante WSL). En este [link](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FslInstallation) te dicen como paso a paso.

## Herramientas
En esta sección estan las herramientas más utilizadas de FSL y una breve introducción de qué hace. 

### Imágenes estructurales
+ [fsl_anat](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/fsl_anat) : si lo que buscas es una manera directa de procesar tus imágenes T1w, esta es una opción. El pipeline tiene la ventaja de que envuelve todas las herramientas de abajo.  
+ [BET](./FSL:-Brain-extraction-tool-BET) : esta herramienta elimina todo lo que no sea tejido de cerebro en la imágen, así como las superficies del cráneo. 
+ [FAST](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FAST) : realiza una segmentación de los diferentes tejidos del cerbero, ya sea sustancia gris, blanca, liquido cefaloraquídeo, etc. 
+ [FIRST](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FIRST/UserGuide) : por otro lado, esta herramienta segmenta areas subcorticales. 
+ [FLIRT](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FLIRT) : es una herramienta robusta para registrar imágenes de manera lineal y no lineal con [FNIRT](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FNIRT).

### Imágenes funcionales
+ [FEAT](./FEAT) : herramienta bastante extensa y robusta para procesar y analizar datos funcionales. 
+ [MELODIC](./FSL:-Melodic) : sirve para realizar un análisis de componentes independientes. 

### Imágenes difusión
+ [FDT](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FDT) : es una herramienta para el análisis de las DWI y lo puedes correr desde una interfaz gráfica o desde la terminal. Este pipeline incluye eddy, ajuste de tensores y tractografía. 
+ [TBSS](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/TBSS) : esta herramienta proyecta todos los mapas de FA de todos los sujetos de estudio (a partir de un registro no-lineal) en un "esqueleto" de FA promedio. 
+ [EDDY](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/eddy) : forma parte fundamental del preprocesamiento, ya que corrige tanto el moviemiento del sujetoo como las distorsiones generadas por los cambios en los gradientes de difusion. 
+ [TOPUP](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/topup) : a la par de eddy, esta herramienta esta diseñada para corregir las distorsiones causadas por las inhomogeneidades del campo magnético. Por ejemplo, si adquirimos las imágenes en una dirección postero-anterior, la imágen resultante tendrá la distorsión notoria en la parte mas anterior (donde parece que la cabeza tiene un chipote gigante). 

⭐ Recuerda que si eres miembro de la wiki y usas algunas de estas herramientas puedes colaborar generando nuevas entradas con tus mejores tips!


***

## Manejo de versión de FSL

Gracias a los [módulos](./Modules) ya no tendrás conflicto entre versiones. Hasta el momento (Abril 2024) hay dos versiones en el Cluster:
```
module avail fsl

fsl/6.0.7.1
fsl/6.0.7.4
```
Lo unico que tienes que hacer es elegir la version con la que quieras trabajar y mandarla a llamar con `module load`. Como sugerencia, realiza tus análisis siempre con una misma versión. 


## Algunos tips del uso de FSL

+ [Región de Interés: fslroi](./FSL:-ROI): Extrae una región de interés (ROI region of interest) de una imagen.
+ [Mapas cuantitativos: fslstats](./FSL:-Stats): Extraer valores de un mapa cuantitativo.
+ [Reorientar imágenes](./FSL:-Reorientar-imágenes): Para visualizar las imágenes de forma habitual.
+ [Quitar volúmenes de un archivo niffti](./FSL:-Quitar-volumen-NIFFTI)
+ [Transformar una máscara](./FSL:-Transformar-máscara) (espacio estándar-atlas) al espacio del sujeto (fMRI).
Elimina de las imágenes aquellas estructuras que rodean al cerebro (cráneo y meninges):

  - Se escribe la ruta en donde se encuentra el archivo.
  - Se pone el comando “bet”
  - Se escribe el nombre del archivo con formato “.nii.gz”
  - Se pone el nuevo nombre del archivo.
  - Se escribe el grado de extracción que se desea, usualmente funciona con “-f 0.5”, pero el gradiente va desde 0 a 1, siendo los valores cercanos a 0 los más laxos, y los cercanos a 1 los de mayor extracción.
   
```bash
   Ejemplo:
   datos/purcell/circe/tesis/imágenes bet s408.nii.gz bet408 –f 0.5
```

**Otra manera de explicarlo**

Debe escribirse en el siguiente orden:
  Comando
  Espacio
  Archivo con tejido ajeno al encéfalo (debe escribirse toda la ruta, o bien puede arrastrarse el archivo)
  Espacio
  Nombre final del archivo sin tejido ajeno al encéfalo

    Ejemplo:
    bet 'archivoconmeninges.nii.gz' nombredelarchivosinmeninges.nii.gz 

Al agregar **-f** al final, se puede regular qué tanto tejido se quita de la imagen. Por default, el comando bet está en 0.5 Este número puede ser modificado escribiendo alguno de 0.1 a 0.9

    Ejemplo:
    bet 'archivoconmeninges.nii.gz' nombredelarchivosinmeninges.nii.gz -f 0.6 Para llevar a cabo un análisis de componentes independientes en Melodic es necesario contar con los archivos del "resting state" en formato NIfTI y las imágenes estructurales deben ser sometidas a la extracción de cerebro utilizando la herramienta [brain extraction tool](https://github.com/rcruces/C-13_wiki_demo/wiki/Brain-extraction-tool-bet).  

*Es altamente recomendado que se utilcen las funciones por defecto con las que se ejecuta Melodic a menos de estar seguro que se deben alterar los parámetros*.

En la pestaña **misc** podemos seleccionar si deseamos ocultar la burbuja de ayuda, así como el reporte de progreso que se ejecuta en el explorador de internet. 

En la pestaña de **Data** se introduce el número de "entradas" y los archivos 4D del resting state. Seleccionamos también la carpeta destino para los resultados de análisis (output directory).
Se debe seleccionar el TR utilizado para la adiquisción de las imágenes.
Y tambien se puede seleccionar el valor para el corte del filtro paso banda para establecer el período temporal más largo que se va a permitir.

Pestaña **Pres-stats**

Podemos desactivar la corrección de movimiento que se lleva a cabo con MCFLIRT por defecto. Así mismo especificar el tipo de adquisición de rebandas (slice timing correction). 
Debido a que las imágenes estructurales utilizadas fueron sometidas a un BET esta opción debe estar activada. 
La normaliazción de la intensidad permite elegir la misma media de intensidad para todos los volúmenes.

Pestaña **Registration**

Para el registro de las imágenes usualmente se selecciona "main structural image" dónde se introducen las imágenes estructurales en el mismo orden que los archvios 4D de la pestaña **Data**. Se pueden cambiar los grados de libertad utilzados en el registro lineal. 
El espacio estándar corresponde al atlas utilizado en los registros. 

Pestaña **stats**. Es importante seleccionar aquí el tipo de ICA que queremos realizar, éste depende del número de sujetos a analizar y las secuencias utilizadas en la adquisición de datos. 

Pestaña **post-stats**. En esta ultima sección es posible indtroducir en las secciones "time series model" y "times contrasts model" los archivos **.mat** y **.con** respectivamente, los cuales fueron creados con la herramienta GUI en la elaboración del diseño experimental. 


[[images/gui.png]]
### Quitar volúmenes de un archivo niffti


Cuando hay exceso de movimiento durante una corrida de funcional (puede verse en el apartado Pre-stats del reporte) es posible eliminar los volúmenes donde se registró mayor movimiento.

#### Opción 1. Utilizar fslsplit

##### Separamos los volúmenes.

    fslsplit Input Output_Base -t

Ejemplo:

    fslsplit '/home/inb/lauveri/Desktop/Fun0.nii.gz' Im_1 -t


Detalles: I) El nombre del output debe tener el guión bajo. II) -t se refiere a que va a separar por tiempo, También es posible separar por los tres ejes, aunque no sé en qué circunstancias sería necesario. III) Considera que las imágenes que vas a tener son tantas como volúmenes tiene el input.

##### Borrar los volúmenes deseados.
No hay limitaciones del orden o número de volúmenes que se pueden borrar. Tampoco es necesario renombrar los archivos conservados.

##### Utilizar el comando fslmerge

    fslmerge -t output inputs

En los que he hecho, disminuye mucho el desplazamiento absoluto, pero no el relativo.
**No olvides modificar los vectores de tu matriz de diseño FEAT.**

Es importante mencionar que fslmerge sirve también para concatenar imágenes en las otras dimensiones (x, y, z). Basta cambiar -t por x, y ó z.


#### Opción 2: fslroi
fslroi es capaz de hacer un ''crop'' a nuestros datos, ya sea en espacio 3D o en el tiempo. En nuestro caso, queremos eliminar algunos volúmenes dentro de un set 4D. Supongamos que tenemos 100 volúmenes, y queremos quitar del 50 al 60, que nuestro sujeto se movió. Recordemos que fslroi cuenta a partir de 0, así que los primeros volúmenes son del 0 al 49 y los últimos son del 59 al 99. Tendremos que hacerlo en tres pasos:

    fslroi archivoOriginal.nii primeraParte.nii 0 49
    fslroi archivoOriginal.nii segundaParte.nii 59 41
    fslmerge -t archivoFinal.nii primeraParte.nii segundaParte.nii

En el caso de la primera línea de código, el 0 representa el índice del volúmen inicial, pero el 49 no representa el índice del volumen final, sino la cantidad de volúmenes que quiero tener. Es decir, aquí le estamos diciendo a FSL que comience a contar con el volúmen índice 0 (o el primero de la serie de volúmenes) y tome 49 en total. En la segunda línea de código le estamos diciendo a FSL que comience desde el índice 59 (o el volúmen número 60) y tome 41 volúmenes.

#### Opción 3: mrconvert
Si de plano lo queremos hacer en un solo paso, la opción es usar ''mrconvert'', que es parte de ''mrtrix''. mrconvert es capaz de extraer volúmenes indicandolos como secuencias numéricas. Hay mucha información en [esta liga](http://www.brain.org.au/software/mrtrix/general/cmdline.html)

    mrconvert -coord 3 0:49,59:99 archivoOriginal.nii archivoFinal.nii## Extraer una Región de Interés con fslroi ##
Extrae una región de interés (ROI region of interest) de una imagen.

A) Es posible tomar una ROI de 3 dimensiones (3D) de un conjunto de datos de 3D, o en caso de que sea de 4 dimensiones (4D) la misma ROI se toma de cada punto temporal y se crea un nuevo conjunto de datos de 4D.

B) Extrae solo algunos puntos de un conjunto de 4D.

C) Controla los limites del espacio y tiempo para la ROI. Hay que darse cuenta que los argumentos son index mínimo y tamaño (no máximo index). Así que para extraer los voxeles de 10 al 12 completos se debe especificar 10 y 3 (no 10 y 12).


Utilización:

       fslroi <input> <output> <xmin> <xsize> <ymin> <ysize> <zmin> <zsize> 

  

       fslroi <input> <output> <tmin> <tsize>       

       fslroi <input> <output> <xmin> <xsize> <ymin> <ysize> <zmin> <zsize> <tmin> <tsize>       

  ## Para visualizar de manera "normal" las imágenes (tanto funcionales como estructurales) 

Hay veces en las que al abrir una imagene en FslView se observa con una orientación diferente a la que estamos acostumbrados. En la mayoría de los casos sólo es la visualización la que no está bien, lo cual no interfiere con los análisis que se realicen con las imágenes. 

Lo primero que hay que hacer es verificar si las etiquetas que pone FslView son correctas. Es decir, aunque la imagen esté rotada, ver si ésta conserve sus etiquetas corrrectas (e.g., lo superior lo marca como superior aunque se observe en la parte izquierda). Para evitar esta "incomodidad" se recomienda agregar -reorientar al final del comando para transformar a nifti las imágenes.

inb_dcm2nii.sh Input Output **reorientar**

Si no se soluciona el problema, puede intentarse con el comando fslreorient2std. Este comando asume que la imagen tiene información válida sobre la orientación (que las etiquetas son correctas). Esta no es una herramienta de registro, solamente rota la imagen para mostrarla similar a la imagen estándar.

fslreorient2std Input Output 

Si tu imagen no tiene las etiquetas correctas se considera un problema grave; en la mayoría de los casos relacionados con el header. Para solucionar ese tipo de problemas más específicos, aquí hay información: http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/Orientation%20ExplainedAlgo que se requiere muy frecuentemente es extraer el valor de algunos voxeles dentro de un volumen de mapas cuantitativos, como por ejemplo un mapa de FA. La herramienta más práctica para ésto es fslstats. Vamos a ver un ejemplo:

Me interesa sacar el valor de FA en una región del cuerpo calloso. Lo primero es hacer una máscara, y en este caso lo voy a hacer con fslview, aunque se puede hacer con mrview, con freeview, itksnap, matlab, o cualquier cosa que me sepa grabar un archivo nifti con las mismísimas dimensiones que el mapa que quiero consultar. Esta es mi máscara (o región de interes, ROI), y se llama miROI.nii.gz:

[[images/roi_fa.png]]

Ahora quiero sacar el valor promedio de FA de los voxeles dentro del ROI, así como su desviación estándar y el número de voxeles y volumen correspondiente del ROI:

  fslstats fa.nii -k miROI.nii -M -s -v

lo cual me arroja:

  0.869577 0.055804 30 240.000000

Los resultados van en el orden en que los pedí: la media de FA es de 0.869, su desviación estándar es de 0.055, hay 30 voxeles en el ROI, y eso da un volumen de 240 mm cúbicos.

No estamos casados con fsl, así que podemos usar mrstats (parte de mrtrix):

``` bash
mrstats fa.nii -mask miROI.nii 
channel         mean        std. dev.   min         max         count
[ ]             0.869577    0.0548657   0.745245    0.980753    30  

```

En general, fslstats tiene más opciones de salida que mrstats.

Ojo, que la máscara que acepta fslstats como ROI debe ser binaria (ceros en todos lados, excepto lo que me interesa). En efecto, todo lo que no valga cero, fslstats lo convierte en uno, así que aguas.

Pero, no es raro tener un volumen que tenga varios ROIs, cada uno identificado con un número (por ejemplo, los archivos cluster_mask_zstat que arroja FEAT después de hacer un análisis de BOLD). Si queremos los valores de adentro de un solo cluster, tendríamos que extraer primero ese cluster y generar una máscara binaria. Por ejemplo, si me interesa el cluster con el índice 3:

  fslmaths cluster_mask_zstat1.nii.gz -thr 3 -uthr 3 -bin miROI.nii.gz
  
Con esto logramos extraer el cluster 3, binarizarlo, y ponerlo en el archivo miROI.nii.gz, que ahora podemos utilizar con fslstats como arriba.

Dado que esta es una operación frecuente, existe un script en el lab para facilitar lo arriba mencionado:

```bash
fslstats_rois data.nii.gz rois.nii.gz roi_idx stats

  data.nii.gz : The file from which we want stats
	rois.nii.gz : A file with several ROIs drawn, each one with a different voxel value (ints)
	roi_idx     : The voxel value of the ROI that we want
	stats	    : The list of statistics we want, as in fslstats options. 
		      If using more than one switch, put it between quotes, as in the example.


 Example :
	fslstats_rois data.nii.gz rois.nii.gz 4 "-m -s -c"
```
## Transformar una máscara (espacio estándar-atlas) al espacio del sujeto (fMRI)  

### 1. LLevar la máscara a un espacio nuevo


''arafat@tanner:~/Desktop/$ flirt -in  mascara.nii -ref funcional_sujeto.nii -applyxfm -init standard2example_func.mat -out Mascara_highres.nii''

**-in**       la máscara a utilizar

**-ref**      la referencia o espacio que se toma en cuenta para la transformación

**-applyxfm**  (este no sé qué indica pero va solo)

**-init**     aquí va la matriz de transformación, este archivo termina en .mat; este archivo cambia dependiendo de la referencia (-ref) que se tome, si es un sujeto o un espacio estándar, etc. En este caso es una matriz que se puede obtener de los mismos resultados de un obtenidos en el registro de un sujeto (primer nivel).

**-out**       el nombre de la máscara resultante

### 2. Cambiar el umbral de la nueva máscara y binarizarla  



''arafat@tanner:~/Desktop/$ fslmaths Mascara_highres.nii -thr 0.9 -bin Mascara_highres.nii''

**-thr**   es el umbral seleccionado,(las opciones van desde 0.9 que es muy conservador, hasta 0.5 que es más laxo)

**-bin** opción binarizar. Nota: entre cada opción se utiliza el nombre de la imagen que se va a modificar

* más detalles de las opciones en http://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FLIRT/FAQ)# Proyectar un resultado de grupo de FEAT a la superficie de fsaverage

Para esta acción se utilizarán las herramientas del grupo de Yeo, disponibles [aquí](https://github.com/ThomasYeoLab/CBIG/tree/master/stable_projects/registration/Wu2017_RegistrationFusion).


## Requisitos
1. Nuestro resultado está en formato NIFTI, y normalizado en un espacio MNI152.
1. Tenemos freesurfer instalado y nuestra variable `$FREESURFER_HOME` es válida.
1. Tenemos el script `CBIG_RF_projectMNI2fsaverage.sh` en nuestro PATH (está colocado en `$FMRILAB_SOFTARE/tools`), así que no es necesario hacer nada, sólo checar.
1. Tener matlab. En estos momentos en el laboratorio, está instalado en `/home/inb/soporte/fmrilab_software/MatlabR2018a/bin`



## Ejemplo
* Mi carpeta `feat` de nivel de grupo es `/misc/mansfield/lconcha/arafat/scirep/groupResults/cope1.feat`, y me interesa `zstat5`
* Mi carpeta para los outputs será `misc/mansfield/lconcha/TMP/proj2surf`
* El comando principal es `CBIG_RF_projectMNI2fsaverage.sh`, y recibirá de argumentos `-s` el archivo nifti con los resultados que queremos ver en la superficie, `-o` la carpeta dónde se grabarán los outputs, y `-m` para la ruta de Matlab. En el fmrilab, la ruta de matlab es `/home/inb/soporte/fmrilab_software/MatlabR2018a/bin`. Por lo tanto, nuestro comando queda:
```
 CBIG_RF_projectMNI2fsaverage.sh \
   -s  /misc/mansfield/lconcha/arafat/scirep/groupResults.gfeat/cope1.feat/thresh_zstat5.nii.gz  \
   -o /misc/mansfield/lconcha/TMP/proj2surf \
   -m /home/inb/soporte/fmrilab_software/MatlabR2018a/bin
```

Al correrlo, quedarán los siguientes outputs:
```
lh.thresh_zstat5.allSub_RF_ANTs_MNI152_orig_to_fsaverage.nii.gz
rh.thresh_zstat5.allSub_RF_ANTs_MNI152_orig_to_fsaverage.nii.gz
```

Para visualizarlo, utilizamos `freeview`

```
freeview \
 -v $SUBJECTS_DIR/fsaverage/mri/brain.mgz \
 -f $SUBJECTS_DIR/fsaverage/surf/lh.white:overlay=lh.thresh_zstat5.allSub_RF_ANTs_MNI152_orig_to_fsaverage.nii.gz \
 $SUBJECTS_DIR/fsaverage/surf/rh.white:overlay=rh.thresh_zstat5.allSub_RF_ANTs_MNI152_orig_to_fsaverage.nii.gz
```
Finalmente, tendremos nuestro resultado:
[[images/freeview_mni2surf.png|alt=mni2surf]]
# convertir `.zvi` y hacer mosaicos

## stitching directo en fiji (versión corta y chida)
El plugin de stitching puede leer los `.zvi` directamente, jalando de los metadatos las coordenadas de la adquisición. Eso significa que incluso podemos olvidar si adquirimos el mosaico como _comb_ o como _snake_ (_wander_), y de todas maneras queda bien!

![](https://i.imgur.com/Vn10m54.png)

![](https://i.imgur.com/8KKQ8qO.png)

Y listones.



## Conversión desde zvi (versión larga y tonta)
El formato `.zvi` es propietario de Zeiss, pero en realidad es un tiff modificado con un poco de metadatos al principio. Afortunadamente, [bioformats](https://www.openmicroscopy.org/bio-formats/downloads/) sabe leerlo y convertirlo a otros formatos más modernos y amigables.

Descargamos las "command line tools" de bioformats, y las descomprimimos a una nueva carpeta. Luego, esa carpeta la agregamos al PATH con un `export`. Por ejemplo, en mi compu de la casa:

    export PATH=/datos/syphon/lconcha/software/bftools:${PATH}
    
El comando que queremos es `bfconvert`. Está padre, y nos ayuda a dividir la imagen como queramos. Yo la quiero frame por frame, pero en este caso se llama _series_. Por ejemplo, para convertir una imagen `.zvi` a muchos `.png`, uno para cada frame uso:

     bfconvert -channel 0 69B-30-Foxp2-40x.zvi tostitch/ch_%s_chan1.png
     
El `-channel 0` indica que solo quiero el primer canal (mi ejemplo es una imagen de dos canales; si hubiera querido el segundo canal hubiera indicado `-channel 1`). 

La clave está en el `%s` en el output filename. Es un placeholder que cambiará en función de los archivos de salida. Al final, en la carpeta `tostitch` voy a tener muchos archivos .png diferenciados por su índice. Estúpidamente, bfconvert escribe números sin "padding", por lo que es necesario cambiarlos a tener una longitud similar para que alfabéticamente tengan sentido (que no vaya primero el 1 que el 10). Hay muchas maneras de hacerlo, pero haré uso de `zeropad` de fsl.

```bash=
cd tostitch
for f in *chan1.png
do
  s=`echo $f | awk -F_ '{print $2}'`
  mv $f f_`zeropad $s 3`.png
done
```
![](https://i.imgur.com/s9r4BUR.png)


:information_source: El formato png seguramente no es la mejor opción para lidiar con estas imágenes, debería estar usando tiff, pero para las pruebas basta el png.



## stitching en Fiji

Vamos a `Plugings`, `Stitching`, `Grid/Collection Stitching`. Dependiendo si el mosaico se obtuvo con barrido _meander_ o _comb_, seleccionamos _grid snake by rows_ o _grid row by row_ respectivamente.

![](https://i.imgur.com/zs1GGPi.png)

Hay que decirle de qué tamaño es el mosaico (yo lo saqué por ensayo/error, pero pues hubiera sido mejor haberlo apuntado en una bitácora). Se le indica también dónde está la carpeta con los archivos y la nomenclatura de los mismos.

![](https://i.imgur.com/m6y5sU6.png)

Las `iii` en los _File names for tiles_ indican los índices de los archivos que cambiamos con el `zeropad`.

Le damos `OK` y unos diez segundos después tenemos el resultado:

![](https://i.imgur.com/BmK7Rlj.png)

Si nos equivocamos en lo de meander/comb o el número de cuadros, veremos algun resultado medio loco.
![](https://i.imgur.com/SLU8RIj.png)


## Pendiente
Hacer un script en Fiji que primero haga un _subtract background_ cuadro por cuadro y luego haga el stitching.# convertir `.zvi` y hacer mosaicos

## stitching directo en fiji (versión corta y chida)
El plugin de stitching puede leer los `.zvi` directamente, jalando de los metadatos las coordenadas de la adquisición. Eso significa que incluso podemos olvidar si adquirimos el mosaico como _comb_ o como _snake_ (_wander_), y de todas maneras queda bien!

![](https://i.imgur.com/Vn10m54.png)

![](https://i.imgur.com/8KKQ8qO.png)

Y listones.



## Conversión desde zvi (versión larga y tonta)
El formato `.zvi` es propietario de Zeiss, pero en realidad es un tiff modificado con un poco de metadatos al principio. Afortunadamente, [bioformats](https://www.openmicroscopy.org/bio-formats/downloads/) sabe leerlo y convertirlo a otros formatos más modernos y amigables.

Descargamos las "command line tools" de bioformats, y las descomprimimos a una nueva carpeta. Luego, esa carpeta la agregamos al PATH con un `export`. Por ejemplo, en mi compu de la casa:

    export PATH=/datos/syphon/lconcha/software/bftools:${PATH}
    
El comando que queremos es `bfconvert`. Está padre, y nos ayuda a dividir la imagen como queramos. Yo la quiero frame por frame, pero en este caso se llama _series_. Por ejemplo, para convertir una imagen `.zvi` a muchos `.png`, uno para cada frame uso:

     bfconvert -channel 0 69B-30-Foxp2-40x.zvi tostitch/ch_%s_chan1.png
     
El `-channel 0` indica que solo quiero el primer canal (mi ejemplo es una imagen de dos canales; si hubiera querido el segundo canal hubiera indicado `-channel 1`). 

La clave está en el `%s` en el output filename. Es un placeholder que cambiará en función de los archivos de salida. Al final, en la carpeta `tostitch` voy a tener muchos archivos .png diferenciados por su índice. Estúpidamente, bfconvert escribe números sin "padding", por lo que es necesario cambiarlos a tener una longitud similar para que alfabéticamente tengan sentido (que no vaya primero el 1 que el 10). Hay muchas maneras de hacerlo, pero haré uso de `zeropad` de fsl.

```bash=
cd tostitch
for f in *chan1.png
do
  s=`echo $f | awk -F_ '{print $2}'`
  mv $f f_`zeropad $s 3`.png
done
```
![](https://i.imgur.com/s9r4BUR.png)


:information_source: El formato png seguramente no es la mejor opción para lidiar con estas imágenes, debería estar usando tiff, pero para las pruebas basta el png.



## stitching en Fiji

Vamos a `Plugings`, `Stitching`, `Grid/Collection Stitching`. Dependiendo si el mosaico se obtuvo con barrido _meander_ o _comb_, seleccionamos _grid snake by rows_ o _grid row by row_ respectivamente.

![](https://i.imgur.com/zs1GGPi.png)

Hay que decirle de qué tamaño es el mosaico (yo lo saqué por ensayo/error, pero pues hubiera sido mejor haberlo apuntado en una bitácora). Se le indica también dónde está la carpeta con los archivos y la nomenclatura de los mismos.

![](https://i.imgur.com/m6y5sU6.png)

Las `iii` en los _File names for tiles_ indican los índices de los archivos que cambiamos con el `zeropad`.

Le damos `OK` y unos diez segundos después tenemos el resultado:

![](https://i.imgur.com/BmK7Rlj.png)

Si nos equivocamos en lo de meander/comb o el número de cuadros, veremos algun resultado medio loco.
![](https://i.imgur.com/SLU8RIj.png)


## Pendiente
Hacer un script en Fiji que primero haga un _subtract background_ cuadro por cuadro y luego haga el stitching.## Grosor cortical ##
El grosor cortical es una medida dada por la distancia existente entre la superficie límite sustancia blanca y sustancia gris , y la superficie pial.

### FreeSurfer ###
Es una plataforma desarrollada por el Hospital General de Massachusetts para el análisis de IRM. Facilita la visualización, el análisis volumétrico de algunas estructuras y la obtención del grosor cortical: [[http://freesurfer.net/]]

## Deepprep
En marzo de 2024 apareció [deepprep](https://deepprep.readthedocs.io/en/latest/api.html), que utiliza la GPU para acelerar muchos procesos. Instrucciones para correrlo como contenedor de singularity [aquí](deepprep).

### Archivos a utilizar ###
Para el análisis del grosor cortical utilizando Freesurfer se necesitan imágenes tipo T1-3D. Pueden ser DICOMs o nifti.

## Pasos para el análisis ##

1. Crear carpeta “SUBJECTS_DIR” en la cual se depositaran todos los outputs de los análisis. Por ejemplo, se puede poner en una CarpetaA los dicoms e indicar que los outputs sean depositados en la Carpetab:

   ```/datos/maquina/usuario/CarpetaA$ export SUBJECTS_DIR=/datos/maquina/usuario/CarpetaB ``` 

2. Ahora se procede a asignar un nombre al sujeto, si es DICOM se usa el primero (a) o si es nifti, se usa toda la carpeta (b):

   a) ``` recon-all  -all -subjid nombredelsujeto -i /datos/maquina/usuario/CarpetaA/nombredelsujeto/0001.dcm ```

   b) ``` recon-all  -all -subjid nombredelsujeto -i /datos/maquina/usuario/CarpetaA/nombred ```

:warning: A partir de enero de 2021 la versión por default es la 7.0. 

:warning: Muchos análisis se hicieron en el lab usando la versión 5.3, que ya no corre en ubuntu 18.04 por una [discrepancia](https://www.mail-archive.com/freesurfer@nmr.mgh.harvard.edu/msg47059.html) de `perl`. Por lo tanto, para correr la versión 5.3 es necesario hacerlo a través de un contenedor de [singularity](https://github.com/c13inb/c13inb.github.io/wiki/singularity_presentation), que quedó grabado en `/home/inb/lconcha/fmrilab_software/containers/freesurfer_5.3.sif`. Para correr un sujeto, un puede usar, por ejemplo, el comando: `singularity run /home/inb/lconcha/fmrilab_software/containers/freesurfer_5.3.sif recon-all -subjid XXXX -autorecon1`


:information_source: El gran [Eliseo Domínguez](https://www.researchgate.net/profile/Marcos-Dominguez-Arriola) hizo un magnífico [tutorial que pueden ver en su github](https://github.com/elidom/Cortical-Thickness).Aquí habrá algo de información sobre histología cuantitativa.

[[Cómo evaluar calibre de axones]]# Bienvenidos a la MRI-lab Wiki!

Bienvenido a la wiki del **Laboratorio de Imágenes de Resonancia Magnética**. Esta página contiene el repositorio para la wiki  y herramientas de los usuarios del MRI-lab.



> :star: No olvides también visitar la [wiki del Lanirem](https://github.com/lanirem/documentation/wiki/XCP-Preprocessing), donde puedes encontrar aún más información!

> :warning: Todo usuario del cluster Don Clusterio debe estar inscrito en la Red Lanirem en el canal [#don_clusterio](https://chat-lanirem.lavis.unam.mx/channel/don_clusterio). No hacerlo implica la desactivación de la cuenta.

# Contenido en esta página
1. [MRILab Wiki](#mrilab-wiki)
1. [Advertencias](#advertencias)
1. [Kit de supervivencia](#kit-de-supervivencia)
1. [Tutoriales Avanzados](#tutoriales-avanzados)

## MRILab Wiki
Este wiki intenta facilitar el uso del clúster y las máquinas que lo forman. Cualquier persona puede consultar la wiki desde una computadora con acceso a internet.

Te invitamos a apoyar el desarrollo de esta wiki de las siguientes formas:
1. Si deseas complementar o corregir alguna entrada que ya está en la wiki.
1. Si aprendes algo nuevo y lo quieres incluir en esta wiki para que los demás podamos aprenderlo también.

Si deseas colaborar en esta wiki es necesario tener una cuenta de github y ser colaborador de este repositorio-wiki. Mas info en este [link](./Modificar-Wiki)

## Advertencias
Recuerda que el clúster es un sistema que depende de que los equipos que lo forman estén activos y en condiciones adecuadas.
>  :warning:Evita **reiniciar**, **apagar** o **desmontar** los equipos que se encuentre en el clúster.

>  :warning:Siempre es buena práctica hacer **Cerrar Sesión** al terminar el día.

>  :warning: A veces no funciona bien el cambio de usuario y podrías perder datos. Acostúmbrate a **grabar tu progreso** con alta frecuencia para evitar tristes pérdidas.

>  :warning: **Borra** continuamente la papelera de reciclaje


>  :warning: Si se presenta algún problema que no esté contemplado en este wiki por favor **repórtalo al administrador** del sistema.


## Kit de supervivencia
+ *Aprende a buscar información*
+ [[Clúster]]. Aquí se explica cómo está organizado el cluster, cómo se utiliza y los errores más frecuentes durante su uso.
+ [Modulos](./Modules): Los módulos es una forma de cargar software a tu sesión de temrinal en el clúster. La mayoría de lso móludos están orientados a software de neuroimagen. Esta entrada explica como hacerlo.
+ [/home](./Clúster:-Folder-usuario-(home)): *¿Qué es y cómo se usa?*. En esta sección se mencionan las mejores prácticas para el uso de `home` en un sistema __NFS__, el uso de la carpeta [temporal](./Clúster:-Folder-temporal-(tmp)), cómo se realiza el [respaldo home](./Clúster:-Respaldo-de-datos) y el respaldo de los [datos](./Clúster:-Folder-almacenamiento-(misc)) en general.
+ [/misc](./Clúster:-Folder-almacenamiento-(misc)): *¿Dónde guardar mis datos?*. Si bien `/home` guarda las configuraciones individuales de cada usuario, el respaldo de los datos (como las imágenes) debe realizarse en el directorio `/misc` con el fin de mejorar el uso del cluster.
+ [[Bash]]. **Bash** que es un programa informático cuya función es interpretar ordenes.
+ [Permisos](./Bash:-Permisos). Los permisos de lectura y escritura se deben de asignar tanto a carpetas como a archivos, ya que si los permisos no están debidamente asignados,  puede derivar en un fallo en el procesamiento de la tarea por parte del cluster o en la falta de respaldo de los archivos.
+ [Trabajo remoto](./trabajoRemoto). Cómo entrar al cluster desde tu laptop, en tu casa o en el café.
+ [Tutoriales básicos de manipulación y procesamiento de imágenes](./Procesamiento-Imagen) En esta sección se encuentran descritos los pasos para manipular los archivos de imagen (dicoms o niifti u otros). Aquí se describe como registrar, normalizar, transformar, reorientar, extraer, sumar, acoplar imágenes y más. Además de algunos enlaces a páginas interesantes.
+ [fMRI](./fMRI). Aprende a hacer análisis de resonancia funcional y algunas herramientas de [[fsl]].
+ [BIDS](./BIDS). Aprende acerca del estándar de almacenamiento de datos y cómo usar herramientas en contenedores.
+ [Imágenes Pesadas a Difusión](./DWMEI)
Asuntos relacionados a imágenes pesadas adifusión, su procesamiento y tractografía.
+ [Grosor Cortical](https://github.com/c13inb/c13inb.github.io/wiki/Grosor-cortical) Información acerca del procesamiento de imágenes para la obtención del grosor cortical y otras bondades de **FreeSurfer**
+ Montar dropbox y similares con [[rclone]]
+ [[FAQ, Trucos y Alertas]] Preguntas frecuentes. Apuntes sobre algunas tareas que a los usuarios les han costado trabajo y no quiere que se les olviden, y para que potencialmente les sean útiles a otros usuarios.
+ [[git]]. **Git** es una herramienta que permite el control de versiones de [código fuente](https://en.wikipedia.org/wiki/Source_code).
+ Información adicional para el grupo [[BIOINFO]].
+ [[Amira]] Es un software para visualización científica.
+ [[Anaconda]] Gesto de ambientes y paquetes de Python.


## Tutoriales Avanzados
1. [Grosor Cortical](https://github.com/rcruces/MRI_analytic_tools/tree/master/Freesurfer_preprocessing), por rcruces.
1. [Procesamiento DWI](https://github.com/rcruces/MRI_analytic_tools/tree/master/DWI_preprocessing), por rcruces.
3. [Grosor Cortical con CIVET y FreeSurfer](https://elidom.github.io/Cortical-Thickness/), por elidom

## Enlaces externos
+ [Enlaces Interesantes](https://github.com/c13inb/c13inb.github.io/wiki/Enlaces) con diversas herramientas.
+ [[Histología]]. Links externos con diversas herramientas.
**MRtrix3** es un software bastante popular para procesar, analizar y visualizar imágenes, especialmente las pesadas a difusión. El software fue lanzado allá por el 2019 por Donald Tournier y ha sido actualizado constantemente. Entre los análisis que MRtrix te ofrece esta la estimación de los FODs, tractografía mediante distintos algoritmos, análisis de conectividad cerebral, entre otros. Si estas trabajando con sustancia blanca, MRtrix te podría convenir. Ahora, no toooodo es enfocado en DWI, MRtrix tiene su visualizador `mrview` bastante comodo, tambien tiene muchos comandos que pueden ser muy útiles para el manejo de imágenes de resonancia en general, como por ejemplo `mrconvert`, `mrinfo`, `mrregister`, `mrtransform`, entre otros.

Por último, muy importante resaltar es que MRtrix esta bastante bien documentado y su uso es relativamente sencillo (una vez que le agarras la onda a la sintaxis) en este [link](https://mrtrix.readthedocs.io/en/latest/) te dejo su wiki donde podrás encontrar como instalarlo, conceptos claves, manuales de uso de los comandos y mucho más.  

***
## Configuración de Mrtrix

Hasta el día de hoy (abril 2024) existen dos versiones de `mrtrix` en el clúster:
```
module avail mrtrix

mrtrix/3.0.3
mrtrix/3.0.4
```
Carga la versión que deseas con `module load mrtrix/...`. Ten en cuenta que todos los comandos de mrtrix se ejecutan en la terminal. 


***
## Algunos procesos comunes con MRtrix:

+ [Pre-procesamiento](./MRtrix:-preproc)

+ [Deconvolución esférica de la señal DWI](./MRtrix:-DE)

+ [Anatomically constrained tractography (ACT)](./MRtrix:-ACT)

+ [Sacar AFD de un tracto](https://hackmd.io/@lconcha/ry2S2Fun0)
Para comenzar a hacer la tractografía se necesita primero delimitar una región de interés (ROI) de donde partirán los streamlines (lineas de corriente de difusion). Para esto hay que segmentar adecuadamente el area deseada pudiendo realizarlo en el visor de Mrtrix (mrview), Freesurfer (freeview) o FSL (fslview). Esa area se le denomina comunmente *semilla*, dado que de aquí partirán todos los análisis futuros.

Link para realizar ROIs en mrview: [[http://www.brain.org.au/software/mrtrix/tractography/roi.html]].

Una vez que ya este bien delimitada el area se procede a "sembrar la semilla" con el comando *tckgen*.
Ahora si tenemos nuestro primer resultado de la tractografía!!! sin embargo no siempre es lo que esperamos, ya que queda un poco llena de muchas otras fibras que no son de nuestro interés para esto se procede a realizar una disección virtual o un filtrado con el comando *tckedit* para incluir o excluir otras regiones de acuerdo a la anatomía que deseemos observar (previamente al filtrado se tienen que dibujar los ROIs que serán utilizados para incluir o excluir areas). 
## Anatomically constrained tractography (ACT) ##
Para poder realizar ACT necesitamos una imagen en donde se segmente los tejidos de acuerdo a 

(1) s. gris cortical, 

(2) s. gris subcortical,

(3) s. blanca, 

(4) LCR  

(5) tejido patológico. A esta convención mrtrix3 la llama un archivo 5TT (5-tissue type) y es necesario para correr ACT y SIFT. Lo ideal sería tener imágenes DWI corregidas mediante obtención reversa de fase, y co-registrar imágenes T1 de las cuales podemos derivar este archivo 5TT, pero en caso de no tenerlo, podemos usar un script que trabaja únicamente en espacio DWI:

``` inb_mrtrix3_create_5TT_from_DWI.sh <fa[.gz]> <adc[.gz]> <output5TT.nii[.gz]> ```

Como no tenemos aún los archivos de FA ni ADC, podemos usar ``` inb_mrtrix_proc.sh ``` con el switch ``` -noCSD ``` para generarlos.

## Deconvolución esférica de la señal DWI ##
Como vemos al final del script en preprocesamiento, obtener los FODs es ahora trivial:

``` dwi2fod -grad dti_ec_encoding.b -mask proc_mask.nii.gz proc_dwi_biasCorr_ratios.nii.gz proc_response.txt proc_FOD.nii.gz ```

## Pre-procesamiento ##
Para garantizar que la amplitud de las FOD no esté modulada por inhomogeneidades de B1, y para estandarizar las unidades con la que se miden (en lugar de arbitrarias, que sean un porcentaje de las imágenes b=0), tenemos el script ```
 inb_mrtrix3_preproc.sh ``` . A manera de ejemplo:

1. Obtener una máscara. Primero debemos extraer el primer volumen y luego correr bet.

``` fslroi dti_ec.nii.gz b0 0 1 ```

```bet b0.nii.gz b0 -m -n -f 0.25 ```


2. Ahora sí corremos el script de preprocesamiento de mrtrix3

:warning:  Este script ya está viejo (2014). Se recomienda usarlo como guía, pero no usarlo directamente (lconcha, 2021)

``` inb_mrtrix3_preproc.sh dti_ec.nii.gz dti_ec_encoding.b 1000 b0_mask.nii.gz proc ```

Este paso es tardado, suficiente para un café. Una vez concluido, generará los siguientes resultados:

  * ``` proc_mask.nii.gz ```  Una máscara del cerebro que trata de minimizar la periferia ruidosa del cerebro. No es perfecta, pero es mejor que la previa.
  * ``` proc_dwi_biasCorr_ratios.nii.gz ```  Uno de los dos resultados principales. Son las imágenes DWI pero (a) corregidas por inhomogeneidades de B1 y con unidades [0 1].
  * ``` proc_avDWI_ratios.nii.gz ``` El promedio temporal del archivo ```proc_dwi_biasCorr_ratios.nii.gz ```. Util para usar como fondo anatómico en mrview.
  * ``` proc_dwi_bias_field.nii.gz ``` El factor de compensación B1 aplicado a las imágenes DWI originales.
  * ``` proc_response.txt ``` El otro resultado importante. Es la response_function a utilizar para realizar CSD.  Usando ``` cat proc_response.txt ``` podemos ver el contenido. En este ejemplo es ``` 1.759339452 -0.5281734467 0.1055925936 -0.01716192625 0.0004632802156 ```. El script usará ```lmax ``` tan alto como los datos lo soporten, por lo que el número de coeficientes puede variar, pero los rangos de los valores deben ser similares a éstos.
# Como colaborar en la wiki del C-13

La wiki del C-13 en la actualidad esta albergada como una pagina wiki de gitHub como parte del repositorio: https://github.com/c13inb/c13inb.github.io . Este repositorio es una pagina web hecha por Raul para el lab sin mucho uso.

Lo confuso de este esquema es que la wiki es un sub-repositorio que existe dentro de otro repositorio. Lamentablemente no tienes todas las comodidades que ofrece github para el manejo del repositorio principal (funcionalidades de pull request e interfaz grafica de commits etc) pero aun así podemos trabajar en ella colaborativamente.

Para ello primero necesitas ser colaborador del siguiente repositorio: https://github.com/c13inb/c13inb.github.io
Para esto deberás contactar al Doctor Concha y darle tu usuario de github.

Ya siendo colaborador puedes modificar la wiki con las opciones de manera web o local como se describe por aca: https://docs.github.com/en/github/building-a-strong-community/adding-or-editing-wiki-pages

La wiki esta escrita en lenguaje Markdown. Es muy simple de aprender y utilizar. Una googleada y unos 20 mins bastara. Para ver un cheatsheet de uso puedes empezar en este [tutorial](https://guides.github.com/features/mastering-markdown/)

Algunas reglas básicas para la organización de la Wiki:
- Si trabajas de forma local el archivo del markdown sera el titulo de tu entrada en la wiki. Dale un nombre descriptivo. No usar `\ / : * ? " < > |` para que no haya conflictos en copias locales en algunos sistemas operativos *cough cough* windows *cough cough*.
- Si quieres que tu pagina aparezca en la sidebar de la derecha necesitas modificar el archivo _Sidebar (si estas usando el repo de manera local). En la interfaz web basta con apretar en el botón editar en "Tabla de contenidos".
- Si tu entrada en la wiki pertenece a una subcategoría empieza su titulo con dicha categoría, posteriormente `_` y luego el nombre de tu entrada. Ejemplo> `Categoria_mientrada.md`
- Si ves algo que ya esta super outdated échanos la mano y dale una editada a la entrada que estas revisando. De manera local modificas el archivo (son sus subsecuente `git push`). En la interfaz web basta con con el botón Edit.# Módulos
Los [módulos](https://modules.readthedocs.io/en/latest/) son una herramienta que permite personalizar el software disponible al usuario en una sesión de su terminal mediante archivos de módulos. 

Los archivos de módulo contienen rutas de carpetas y variables de entorno que se agregan al PATH cuando se manda a llamar dicho módulo. Esto permite tener un buen control de las librerías activas en una sesión para evitar conflictos entre las paqueterías de software en una misma sesión.

## Uso básico

Hay dos comandos principales para utilizar módulos:

- `module avail` : Muestra la lista de software/módules disponibles.

- `module load <module>`: Activa el modulo en el ambiente actual.


Por ejemplo, en una terminal nueva escribir el comando `module avail` nos arroja la lista de módulos de don clusterio:

[[images/module_avail.png]]

Como ejemplo activaremos el módulo de mrtrix con `module load mrtrix`. Enlistando los módulos vemos ahora está activo:

[[images/module_load_mrtrix.png]]

Podemos activar varios módulos en una misma línea. Por ejemplo para agregar fsl y brkraw a nuestra sesión actual podríamos escribir `module load fsl brkraw`.

[[images/module_load_fsl_brkraw.png]]

Si escribimos solo el nombre del módulo se carga la última versión disponible. Podemos especificar la versión a cargar del algún módulo escribiendo su nombre/versión. Por ejemplo, para cargar una versión antigua de AFNIpodriamos utilizar `module load afni/22.2.04`. 

[[images/module_load_afni.png]]

Tip: El autocompletar con tabulador funciona en los módulos!

## Otros comandos
- `module list`: Enlista los módulos actualmente activos en la sesión.
- `module unload <module>`: Desactiva un módulo de la sesión actual.
- `module purge`: Desactiva todos los módulos de la sesión actual.

- `ml`: Alias corto para module load. Podemos cargar modulos mediante `ml <module>`.
- `module av`: Alias de module avail.
- `module add`: Alias de modulo load.
- `module rm`: Alias de modulo unload.

## Cargando módulos en todas las sesiones.
Si hay algún modulo que utilizas seguido (y no conflictúa mucho con otros módulos) puedes cargarlo de manera persistente en todas tus sesiones sin necesidad de cargarlo una vez por sesión. 

Para esto sólo requires modificar el archivo `.bashrc` que se encuentra oculto en tu carpeta HOME agregando al final del mismo la línea con la cual cargas tu modulo (i.e. module load <módulo>).

Puedes modificar este archivo con alguno de los editores de texto de Don Clusterio (e.g. micro, nano, vim, gedit) abriendo una terminal nueva y escribiendo (ejemplo con micro) `micro .bashrc` y agregando los módulos que quieras al final (o al menos asegúrate que sea después del source de configuración de Don Clusterio) y guardando el archivo (para el caso de micro es con `CTRL + S`).

## NOTAS
- El módulo inb_tools contiene una serie de joyitas programadas por el Dr. Concha (en su mayoría en bash) a lo largo de los años de Don Clusterio. Este módulo se activa por default para los usuarios. Puedes ver los scripts en su github (https://github.com/lconcha/inb_tools). Te invitamos a contribuior si sale una idea cool para el cluster!
- El módulo de dipy utiliza ambientes de python. Van a generar conflicto con  ambientes locales de conda si los activas a la par. Cabe decir que estamos experimentando ver si vale la pena mantener módulos de ambientes de python de estar forma.Las imágenes médicas, en este caso de resonancia magnética, por si solas solamente nos brindan información cualitativa, lo cual si estamos en el ámbito de la investigación pues no resulta altamente informativa. Por eso el procesamiento de estas imágenes viene de gran relevancia, ya que através del procesamiento nosotros vamos a poder extraer y destacar información importante de modo que facilité su posterior análisis. 

El tipo de procesamiento dependerá absolutamente del tipo de imágen que estes trabajando, es decir, no es lo mismo procesar imágenes anatómicas T1w a imágenes pesadas a difusión. Tambíen te encontraras que la comunidad de científicos que desarrollan estas herramientas es _muy_ activa, por lo tanto existen vaaarias opciones. En esta entrada vas a encontrar los softwares que más se utilizan, que son robustos y sobre todo bien documentados.  

***


## Herramientas para el procesamiento de imágenes.

Aquí abajo encontraras unos de los software más utilizados en la comunidad científica de "resonólogos" con una breve introducción. Dale clic al nombre del software para ver información más detallada jusnto con manuales que han aportado los usuarios de la wiki. 

+ [FSL](./FSL)

FMRIB Software Library es una colección de herramientas muy popular para el procesamiento de imágenes estructurales, funcionales y de difusión. Tmabién cuenta con funciones que incluyen el análisis estadístico de dichas imágenes. FSL es completamente open source y esta bastante bien documentado, en su [wiki](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki) puedes encontrar toda la información necesaria para empezar a procesar tus imágenes. 

+ [MRtrix3](./MRtrix3)

Uno de los favoritos es MRtrix3 que cuenta con una larga colección de herramientas para procesar, visualizar y analizar imágenes sensibles a difusión 
(DWI). Si bien esta muuuy enfocado a las DWI, muchas herramientas son útiles para manejar imagenes en general. Mrtrix esta tambíen super bien documentado, aquí puedes checar su [wiki](https://mrtrix.readthedocs.io/en/latest/).

+ [FreeSurfer](./Grosor-cortical)

Un clásico!, FreeSurfer es de los softwares más utilizados para analizar imágenes de humanos. Dentro de su libreria hay montones de funciones para procesar imágenes estructurales, funcionales y de difusión. Puedes realizar desde registros, hasta  tractografía y mapeo funcional. Aquí te dejo su [wiki](https://surfer.nmr.mgh.harvard.edu/fswiki) para que lo cheques. 

+ [BIDS](./BIDS)

El Brain Imaging Data Structure es una manera estandarizada de organizar y esrtucturar tus datos de neuroimagen. Es altamente recomendable esta practica, sobre todo ya que facilita el compartir los datos o incluso el análisis. En esta entrada viene información de como utilizar los contenedores en el cluster.   

+ [ImageJ](./ImageJ)

ImageJ/FIJI es un software para analizar, procesar, editar y visualizar imágenes de **microscopia**! Si estas haciendo histología como parte de tu proyecto, este es el software que necesitas. Tiene una cgran antidad de plugins y funciones que te van a permitir hacer una muchos tipos de procesos de manera efectiva. Si bien los comandos de cajon estan muy bien documentados, muchos de los plugins tienen una documentación medio irregular y toca aprender a pura prueba y error. Aquí te dejo el [link](https://imagej.net/ij/) de su pagina web.

## Transformación de Datos

+ [Compresión/Descomprensión de imágenes](./Procesamiento-imagen:-Compresion)
+ [Traslado de imágenes](./Procesamiento-imagen:-Traslado)
+ Convertir de [DICOM a NIFTI](./Procesamiento-Imagen:-De-DICOM-a-NIFTI)
+ Convertir de [PARREC a NIFTI](./Procesamiento-Imagen:-De-PARREC-a-NIFTI)
## Compresión de archivo
Comprime las imágenes en formato `.tar` para poder subirlas al cluster, después de la obtención de datos en el resonador:

  - En la máquina de la unidad de resonancia, buscar el nombre del sujeto de estudio (actualmente en la carpeta "dicom2015").
  - Click derecho y poner la opción `7-zip`.
  - Seleccionar la opción `ad to archive`.
  - Seleccionar la opción `Tar`.

## Descomprensión de archivo 
  * Entrar al directorio dónde se encuentran las imagenes:  
```{bash} 
cd datos/purcell/juan/mis_niftis/ 
```  
  * Usar el comando **tar** con la opcion **xvf** para descomprimir. (x-extract, f-file, v-verbose)  
``` {bash} 
tar xfv sujeto_00.nii.gz 
```
  * Si es un archivo **rar** usar el siguiente comando:  
```{bash} 
unrar x archivo.rar 
```  
  
## De DICOM a NIFTI ##
Usar en la terminal el siguiente comando: **inb_dcm2nii.sh**

Debe escribirse en el siguiente orden:
	
* Comando
* Espacio
* Archivo a convertir (debe escribirse toda la ruta, o bien puede arrastrarse el archivo)
* Espacio
* Nombre final del archivo y agregar: **.nii.gz**

Ejemplo:
```
inb_dcm2nii.sh 'miarchivoT1' nombrefinaldelarchivo.nii.gz
```

Si al final de la línea se agrega **-reorientar** esta función hará que la imagen sea orientada de forma convencional.

Ejemplo:
```
inb_dcm2nii.sh 'miarchivoT1' nombrefinaldelarchivo.nii.gz -reorientar
```
## De PARREC a NIFTI ##
Usar en la terminal el siguiente comando: **PARconv_v1.12.sh**

Debe escribirse en el siguiente orden:
* Comando
* Espacio
* Archivo a convertir (debe escribirse toda la ruta, o bien puede arrastrarse el archivo)
* Espacio
* Nombre final del archivo y agregar: **.nii.gz**

Ejemplo:
```	
PARconv_v1.12.sh 'miarchivoT1' nombrefinaldelarchivo.nii.gz
```

Este comando **NO** permite reorientar la imagen de manera directa, por lo que es necesario usar en la terminal otro comando el cual es: **fslreorient2std**

Debe escribirse en el siguiente orden:
* Comando
* Espacio
* Archivo a reorientar (debe escribirse toda la ruta, o bien puede arrastrarse el archivo)
* Espacio
* Nombre final del archivo

Ejemplo:
```
fslreorient2std 'archivoareorientar.nii.gz' nombrefinaldelarchivo.nii.gz
```

En caso de las imágenes **pseudoflair** hay que utilizar el siguiente comando en lugar de PARconv_v1.12.sh. sin la extensión .PAR o .REC, solo el nombre: ej. ID_pseudoFLAIR.PAR
```{bash}
 dcm2nii -o . -v N ID_pseuFLAIR
```

Una vez ya tengan comprimido su archivo:

  - Entrar a la carpeta `WinSCP`.
  - Seleccionar la carpeta `Mansfield`.
  - Escribir tu nombre de usuario y contraseña.
  - Seguir la ruta para llegar a la carpeta donde se guardan los archivos del protocol
Encuentra información sobre uso de resonadores, y cómo transferir datos.

El Laboratorio Nacional enfocado en imagenología por resonancia magnética ([Lanirem](http://www.lanirem.inb.unam.mx/)) cuenta con tres resonadores. Da clic en sus nombres para más información:

1. [Bruker Biospec 70/16 (7 T)permisos](./Resonadores:Bruker)
2. [General Electric Discovery MR750 (3 T)](./Resonadores:GE)
3. [Philips Achieva TX (3 T)](./Resonadores:Philips)Bruker Biospec 70/16

Para usar el resonador Bruker es necesario acreditar un proceso de certificación. Para ello es necesario contactar al Dr. Juan Ortiz.


Algunos datos sobre el resonador:
* Bruker Biospec 70/16: 70 porque es un 7 Tesla, y 16 porque su túnel tiene 16 cm de diámetro.
* El resonador tiene un magneto  [Pharmascan](https://www.bruker.com/products/mr/preclinical-mri/pharmascan/overview.html?gclid=EAIaIQobChMIo-bPoJCW4QIVx7jACh3UYAvBEAAYASAAEgIKrfD_BwE), sin embargo toda la electrónica y los gradientes son de un [Biospec](https://www.bruker.com/products/mr/preclinical-mri/biospec/overview.html?gclid=EAIaIQobChMIrY6ZtpCW4QIVhIbACh3L_wZLEAAYASAAEgJdofD_BwE). Por lo tanto, el resonador es _de facto_ un Biospec.


La transferencia de los datos se puede realizar en varios formatos:

* Formato DICOM: En Paravision seleccionar los datasets que requieres, da clic derecho y elige `convert to Dicom`. Al finalizar te dará la ruta donde se guardaron, que es por default dentro del data set. Ahora tienes dos opciones: Los sacas directamente del resonador usando una USB, o los sacas usando `/misc` (ver adelante).
* Formato NIFTI: Obten primero tus datos en DICOM  y posteriormente conviértelos en tu máquina usando [mrconvert](https://mrtrix.readthedocs.io/en/latest/reference/commands/mrconvert.html) de Mrtrix3, o [dcm2niix](https://github.com/rordenlab/dcm2niix).


***

## Como exportar mis datos desde el Bruker


Los datos que se almacenan en el bruker estan en ruta `/misc/bruker7/data01/` o `/misc/bruker7/data02/` al cual podemos acceder de la siguiente manera: 

```
cd /misc/bruker7/data02/user/mi_usuario
```

Lo siguiente es localizar los archivos que deseas convertir. Puedes buscarlos al usar el comando `ls` o maás fácil, buscarlo utilizando un `*` si sabes el nombre de tu archivo. 

```
ls *irm150d_rata64A*
```
Al hacer este filtro, yo estoy buscando especificamente por la rata 64A y el archivo que me encontro es el siguiente: 

`20220104_085643_INB_C13_hluna_irm150d_rata64A_INB_C13_hluna_1_1 `, y es el que voy a utilizar de ahora en adelante como ejemplo.

Donde `20220104` es la fecha de adquisición y `INB_C13_hluna_irm150d_rata64A_INB_C13_hluna` el nombre que le das a tu estudio. Si nosotros enlistamos (`ls`) esta carpeta para ver que hay adentro, veremos que hay carpetas enumeradas al inicio, estos corresponden a cada adquisición en el orden en el que fueron tomadas y son las que vamos a ir convirtiendo.

```
ls 20220104_085643_INB_C13_hluna_irm150d_rata64A_INB_C13_hluna_1_1/

1  2  3  4  5  6  7  8  AdjResult  AdjStatePerStudy  Mapshim  ResultState  ScanProgram.scanProgram  subject
```

Bien, hasta aqui ya sabemos como acceder a tus imágenes del Bruker, siguiente paso es exportarlas en formato Nifti.

Paso numero uno es cargar el modulo de Bruker (gracias a Ricardo Rios que nos hizo la vida mas facil al crear los modulos, si aun no te familiarizas con ellos, da click [aquí](https://github.com/c13inb/c13inb.github.io/wiki/Modules) y aprende mas a como usarlos.


```
module load brkraw/0.3.11
```

Una vez cargado el módulo estas listo para utilizarlo. Si quieres saber la información detallada de cada una de tus adquisiciones, puedes utilizar el comando `brkraw info` que nos despliega la siguiente información:

```
brkraw info 20220104_085643_INB_C13_hluna_irm150d_rata64A_INB_C13_hluna_1_1/
```

```
Paravision 7.0.0
----------------
UserAccount:    conchalab 
Date:           2022-01-04
Researcher:     rata64A
Subject ID:     INB_C13_hluna_irm150d_rata64A
Session ID:     INB_C13_hluna_irm150d_rata64A
Study ID:       1
Date of Birth:  07 Aug 2021
Sex:            male
Weight:         0.433 kg
Subject Type:   Quadruped
Position:       Prone           Entry:  HeadFirst

[ScanID]        Sequence::Protocol::[Parameters]
[001]   Bruker:FLASH::1_Localizer::1_Localizer (E1)
        [ TR: 100 ms, TE: 2.50 ms, pixelBW: 159.22 Hz, FlipAngle: 30 degree]
    [01] dim: 2D, matrix_size: 256 x 256 x 3, fov_size: 50 x 50 (unit:mm)
         spatial_resol: 0.195 x 0.195 x 2.000 (unit:mm), temporal_resol: 12800.000 (unit:msec)
[002]   Bruker:FLASH::1_Localizer::1_Localizer (E2)
        [ TR: 100 ms, TE: 2.50 ms, pixelBW: 159.22 Hz, FlipAngle: 30 degree]
    [01] dim: 2D, matrix_size: 256 x 256 x 3, fov_size: 50 x 50 (unit:mm)
         spatial_resol: 0.195 x 0.195 x 2.000 (unit:mm), temporal_resol: 12800.000 (unit:msec)
[003]   Bruker:FLASH::1_Localizer::1_Localizer (E3)
        [ TR: 100 ms, TE: 2.50 ms, pixelBW: 159.22 Hz, FlipAngle: 30 degree]
    [01] dim: 2D, matrix_size: 256 x 256 x 3, fov_size: 50 x 50 (unit:mm)
         spatial_resol: 0.195 x 0.195 x 2.000 (unit:mm), temporal_resol: 12800.000 (unit:msec)
[004]   Bruker:FLASH::T1_FLASH::T1_FLASH (E4)
        [ TR: 201.57 ms, TE: 3.50 ms, pixelBW: 98.64 Hz, FlipAngle: 30 degree]
    [01] dim: 2D, matrix_size: 384 x 384 x 13, fov_size: 25.6 x 25.6 (unit:mm)
         spatial_resol: 0.067 x 0.067 x 1.100 (unit:mm), temporal_resol: 309614.466 (unit:msec)
[005]   Bruker:FieldMap::B0Map-ADJ_B0MAP::T1_FLASH
        [ TR: 20 ms, TE: 0 ms, pixelBW: 1860.12 Hz, FlipAngle: 30 degree]
    [01] dim: 3D, matrix_size: 64 x 64 x 64, fov_size: 45 x 45 x 45 (unit:mm)
         spatial_resol: 0.703 x 0.703 x 0.703 (unit:mm), temporal_resol: 81920.000 (unit:msec)
[006]   Bruker:DtiEpi::DTI_EPI_30dir::DWIzoom (E6)
        [ TR: 2000 ms, TE: 22.86 ms, pixelBW: 2289.38 Hz, FlipAngle: 90 degree]
    [01] dim: 2D, matrix_size: 126 x 86 x 25 x 285, fov_size: 22 x 15 (unit:mm)
         spatial_resol: 0.175 x 0.174 x 1.250 (unit:mm), temporal_resol: 4000.000 (unit:msec)
    [02] dim: 2D, matrix_size: 126 x 86 x 22 x 25, fov_size: 22 x 15 (unit:mm)
         spatial_resol: 0.175 x 0.174 x 0.006 (unit:mm), temporal_resol: 0.000 (unit:msec)
[007]   Bruker:DtiEpi::DTI_EPI_30dir::DWI-IVIM-zoom(E11) (E7)
        [ TR: 2000 ms, TE: 22.86 ms, pixelBW: 2289.38 Hz, FlipAngle: 90 degree]
    [01] dim: 2D, matrix_size: 126 x 86 x 25 x 63, fov_size: 22 x 15 (unit:mm)
         spatial_resol: 0.175 x 0.174 x 1.250 (unit:mm), temporal_resol: 4000.000 (unit:msec)
    [02] dim: 2D, matrix_size: 126 x 86 x 22 x 25, fov_size: 22 x 15 (unit:mm)
         spatial_resol: 0.175 x 0.174 x 0.006 (unit:mm), temporal_resol: 0.000 (unit:msec)
[008]   Bruker:RARE::T2_TurboRARE::T2_TurboRARE (E8)
        [ TR: 4212.78 ms, TE: 33 ms, pixelBW: 140.85 Hz, FlipAngle: 141.72 degree]
    [01] dim: 2D, matrix_size: 256 x 256 x 26, fov_size: 30 x 30 (unit:mm)
         spatial_resol: 0.117 x 0.117 x 1.200 (unit:mm), temporal_resol: 269617.981 (unit:msec)

```

Podría parecer mucha información al inicio, pero al final no es mas que los detalles del usuario y cada adquisición enumerada del `[001]` al `[008]`. Aquí tu puedes decidir que imágen te sirve y cual quieres convertir. Como ejemplo yo voy a convertir una imágen anatómica pesada a T2 que es la número 008:

```
brkraw tonii 20220104_085643_INB_C13_hluna_irm150d_rata64A_INB_C13_hluna_1_1/ -o /path/64A_dwi -r 1 -s 8
```
En otras palabras:

`tonii` es el comando que convierte de Bruker a Nifti.

`-o` es el output de como quieres que se llame tu imagen y en donde quieres guardarla, en este caso yo nombro a mi imágen como 64A_T2 `/path/` la ruta donde las quiero guardar.

`-r` es la reconstruccion que queremos, en este caso es la primera y por eso ponemos 1

`-s` es la imagen que queremos convertir, en este caso es la numero 8 


Para ver que tus imagenes se convirtieron exitosamente en formato Nifti, vamos a visualizarlas utilizando `mrview` del software `mrtrix`. Para esto, no olvides cargar tu modulo: `module load mrtrix/3.0.4`

```
mrview 64A_T2.nii.gz
```

Y el resultado es esto:

![image](https://github.com/c13inb/c13inb.github.io/assets/129544525/fe8d393b-9b6f-4df3-9af3-02aadabf23f1)

Una vez que conviertes tus imágenes, estas listo para el siguiente paso que es procesarlas de acuerdo al tipo de estudio. Aprende más acerca de como procesar tus imágenes en esta [entrada](https://github.com/c13inb/c13inb.github.io/wiki/Procesamiento-Imagen). 


***

# Tutoriales para el uso del resonador
Las siguientes páginas de la wiki incluyen algunos tutoriales para el uso básico del resonador.
* [Desconexión de la antena de superficie 2x2 y conexión de la antena cryo.](./Resonadores:Bruker:-Conexión-Cryo)
* [Operación del programa Paravision para la adquisición de imágenes ex-vivo.](./Resonadores:Bruker:-Paravision-EXvivo)
* [Sintonización de la antena de volumen, para escaneos con antena de superficie 2x2.](./Resonadores:Bruker:-Wobble-Superficie)
+ [Generar mapas de B1](./Bruker-B1Map.md)

# Checklists para uso del resonador
Las siguientes ligas contienen algunos google docs con checklist útiles para el cambio de antenas y uso del resonador.
* [Preparación antena Cryo](https://docs.google.com/document/d/1S850dGVnyL1k5UMD0Cf-ebfKXblKklNMRuPto7Vl66M/edit?usp=sharing)
* [Preparación antena de volumen](https://docs.google.com/document/d/1pCrKejx-Q31kqw07g8t0ZBscDQr9n007i6fegMNHtMA/edit?usp=sharing)
* [Checklist inicio Paravision](https://docs.google.com/document/d/1hwDM7ySkY2xqzBnHkGzsFiiu1vH7U6Af9pxxcvGMHR4/edit?usp=sharing)
Desconexión de la antena de superficie 2x2 y conexión de la antena cryo.

1.- En caso de que el anterior usuario haya utilizado la antena de superficie 2x2, será necesario desconectar todos los elementos mencionados a continuación:

* a) El conector con el punto naranja de la antena de superficie conectado en la entrada con el punto café.
* b) El conector con el punto gris y cable de cordón de la antena de volumen (T/R), conectado a la entrada sin cobertura.
* c) El conector del amplificador con el punto rojo, que surge del resonador conectado a la entrada con el punto rojo.

2.- Una vez desconectada la antena de superficie, traccionar el cable de la misma para extraerla por el túnel del resonador hacia la parte posterior, cuidando la presencia de resistencias u obstáculos. Igualmente, desconectar el tubo de la anestesia (tubo de plástico translúcido) del marco de soporte para escanear a la rata y retraerlo hacia la parte posterior del resonador.

3.- Remover la antena de volumen (tubo cilíndrico amarillo pajizo) tomándolo de los extremos posteriores y girándolo levemente hacia la derecha, para que así el gancho que esta presenta en su parte superior no se atore con un anillo plástico que va paralelo a la misma antena. Traccionar la antena hacia la parte posterior y tirar de ella con fuerza moderada.

4.- Ahora se comenzará a instalar el primer componente necesario para el escaneo exvivo con antena cryo. Se trata de un soporte cilíndrico de color verde con un sujetador metálico en un extremo. Se introduce al resonador por orificio anterior del túnel del resonador y una vez dentro, el sujetador metálico tendrá que ajustarse en el borde superior del orificio anterior del túnel, cuidando que las salientes cilíndricas del soporte correspondan con los pequeños agujeros del borde superior del túnel del resonador. Cuando la conexión se coincidente y no quede espacio entre ambas estructuras, se ajustará con las perillas doradas ubicadas a ambos lados del sujetador metálico.

5.- Después se regresará a la parte posterior del resonador y se instalará una cruceta metálica de tres brazos y un anillo plástico en el centro. Para ello, se requiere colocar el anillo plástico alrededor del extremo posterior del soporte cilíndrico verde y simultáneamente, ajustar los brazos metálicos en sus extremos colocando las salientes cilíndricas metálicas en los orificios correspondientes. Cuando se encuentren ajustados, se deberá asegurar el ajuste con las 3 perillas presentes en cada brazo de la estructura metálica.

6.- Luego se busca el cable de la antena cryo {ubicado en la parte posterior del resonador, a un costado de la plataforma de conectores del resonador (espacio vacío a la izquierda)}. Este cable tiene un conector con un punto rojo y se conecta en la entrada con cubierta con punto rojo.

[[images/cryo.png]]

7.- Entonces, se quita la cubierta metálica ubicada al centro de la compuerta posterior del resonador y se cierra esta compuerta.

9.- En este paso se introduce la antena cryo en el orificio de la compuerta posterior. Para lograrlo, es necesario tomar la antena, inclinarla hacia atrás e introducirla en ángulo de 25°. Cuando ya estén dentro los primeros centímetros de la antena, se endereza la antena en sentido paralelo al soporte cilíndrico verde y se introduce el resto de la antena, hasta que la antena esté en el centro del magneto y su soporte metálico se encuentre a unos 2 cm del anillo metálico de la compuerta del resonador.

10.- A continuación, se requiere introducir el arreglo de sintonización de la antena o Wobble (estructura semicilíndrica unida con varillas). Para esto, es preciso introducir el extremo con la parte metálica en una primera instancia y desplazar suavemente el resto de la estructura sobre el tubo de la antena cryo, hasta que el anillo metálico de la compuerta posterior y el extremo plástico de los controladores de la sintonización queden al mismo nivel. Posiblemente, se requiera girar el controlador un poco hacia la izquierda para mejorar el ajuste.

11.- En este momento, se requiere girar las tres perillas alargadas de color dorado, para fijar el arreglo de sintonización al borde posterior de la antena cryo.

12.- Luego, se conecta el cable tipo LAN (Local Area Network) en una sección de conectores ubicada en la cara externa derecha del resonador, en la única entrada LAN libre.

13.- En este paso, se requiere salir del cuarto del resonador y buscar a un costado del monitor del resonador unas llaves con un marco morado que abren la habitación de máquinas del resonador. En esta habitación se encuentran 3 gabinetes.  En el segundo gabinete de adentro hacia afuera, se desconecta el cable que dice HP, es semirígido y tiene un ajuste con rosca. En su lugar, se requiere conectar el cable que dice CR y enroscarlo, hasta lograr un buen cierre.

14.- Si todos los pasos anteriores fueron llevados a cabo de forma correcta, al momento de crear un archivo nuevo, la ventana en la sección de antena activas mostrará RF CP P2300.


Tutorial realizado por Luis Cuauhtémoc Marquez Bravo.
Operación del programa Paravision para la adquisición de imágenes ex-vivo

1.- Para crear un nuevo estudio, se da clic en File de la barra de herramientas. Aparece una ventana y se selecciona la opción de new file.

2.- Entonces, aparecerá una ventana que requerirá llenar los datos del sujeto y del estudio. Se ingresa esta información e igualmente en esta ventana, se confirma si se ha reconocido la antena con la que se trabajará, que en este caso será la antena CRYO (RF CP P2300), y se selecciona la opción TxSuc.

3.- Se arrastra un localizador al área de trabajo, para habilitar la opción de plataforma de ajustes e iniciar el Wobble.

4.- El Wobble se realiza dando clic en el icono de plataforma de ajustes. Entonces, aparece un listado de opciones y se da doble clic a la primera o Wobble. A continuación, se elige el elemento 1, se da clic sobre la opción setup y se abre la pestaña de Acq/Rec display.  En caso, de que la onda deflexión negativa no se encuentre centralizada y con mayor amplitud negativa, se ajustarán estos parámetros al girar los tornillos dorados del arreglo para la sintonización de la antena.

5.- En este momento ya se puede correr el localizador y se ajusta la posición de la muestra y la geometría en la zona de interés, si es necesario.

6.- Ahora, se requiere crear un Pre-Scan o secuencia corta, para habilitar la plataforma de ajustes y realizar el reference power y el mapa de B0, en caso de que nuestra secuencia principal vaya a ser sensible a difusión.

7.- La utilidad del Pre-Scan es obtener una imagen preliminar con sólo ciertas características de la imagen principal y un periodo corto de tiempo. Para ello, es ideal que el Pre-Scan sólo tenga una dirección, con un único valor de B y 1 valor de B0. Igualmente, para este Pre-Scan es necesario realizar el shimming, eligiendo la opción map-shim, auto shim volumen y elipsoide.

8.- Si la imagen preliminar, con el ajuste elegido de FOV y bandas de saturación cumple con las expectativas. Ahora, se puede proceder a realizar la secuencia de difusión completa, duplicando el Pre-Scan, cambiando los parámetros de difusión por los originales y utilizando el shimming anterior, con la opción de current shim.

9.- Para iniciar la secuencia, se da clic en apply y posteriormente, en continue.

10.- Si queremos supervisar a distancia el progreso de la adquisición, esto se puede realizar con la aplicación de teamviewer o similar (rust-desktop está bueno). Llamando a un terminal Ctrl + Alt + T y escribiendo en esta teamviewer. Lo que nos habilitará una ventana con un id y un password para ingresar en otro dispositivo.
Sintonización de la antena de volumen, para escaneos con antena de superficie 2x2.

1.- Una vez que hayamos colocado en el soporte a nuestro sujeto, creado un nuevo archivo y arrastrado el primer localizador al área de trabajo, pero sin iniciarlo, se procederá a realizar el Wobble.

2.- Se da clic en la plataforma de ajustes y después, se da doble clic sobre la opción del Wobble.

3.- Se abre la opción de Acquisition/Reco display para permitir la visualización de la onda de recepción, que aparecerá una vez hayamos conectado los conectores para el Wobble.

4.- Ahora es necesario dirigirse hacia la compuerta posterior del resonador. Ahí se requerirá, desconectar de su sitio al conector de la antena de volumen T/R (transmitter and receiver) y reconectarlo a la entrada del splitter.

5.- Luego, se liberará la entrada con el punto rojo desconectando el conector del amplificador. En esta entrada se conectará el conector con el punto amarillo (elemento 1) del splitter. Es importante mencionar, que para la realización del Wobble no es necesario modificar la conexión del conector de la antena de superficie 2x2, por lo que ésta se mantendrá sin cambios.

[[images/wobble.png]]


6.- Confirmando las conexiones anteriores, se regresa a la consola del resonador y se elige la opción setup. Esto permitirá la visualización de una onda con deflexión negativa que representa el grado de centralización de la recepción de señales para el canal o elemento 1. En caso de que esta onda no se encuentre centrada y paralela al eje y, se movilizará la perilla del tunning (T1 amarilla), para desplazar la onda en el plano de x. Mientras que, para incrementar la amplitud de la onda o profundidad de la misma en el plano y, se movilizará la perilla del matching (M1 amarilla).

7.- Logrando la mayor centralización y profundidad posibles de la onda de sintonización, se procederá a culminar con el Wobble del elemento 1. Para ello, en la consola se da clic en stop y para continuar, se selecciona el elemento 2 en la opción de selección de elementos.

8.- Entonces, se regresará a la compuerta posterior para desconectar el elemento 1 de la entrada roja y conectar en su lugar, al conector del elemento 2 (verde).

9.- Confirmando las conexiones del elemento 2, se regresará a la consola y se seleccionará la opción setup, para repetir los pasos del punto 6, pero ahora para el elemento 2.

10.- Cuando hayamos concluida la sintonización del elemento 2, se da clic en stop. Luego se da clic en start, para que aparezca una paloma verde adelante del indicador del Wobble. Una vez hecho esto, se da clic en apply y finalmente, en back para continuar con las secuencias que se vayan adquirir.
Falta escribir cómo transferir archivos.Falta escribir cómo transferir archivos.* [ssh]:Secure Shell

El protocolo __ssh__ o _Secure SHell_ por sus siglas, permite el acceso remoto
a un equipo en red con un manejo total de este. Este interprete de comandos
puede incluso redirigir las X (interfaz gráfica) y tráfico de red. Es un
protocolo relativamente seguro ya que el tráfico de datos viaja de manera
encriptada entre los equipos.

En linux y mac ssh está instalado y listo para usarse. En windows puedes usar [mobaxterm](https://mobaxterm.mobatek.net/)
o [putty](https://www.putty.org/).

En particular el uso de este protocolo  permite acceder a los diferentes
equipos en el clúster.  Esto es recomendable, por ejemplo, para organizar datos
que se encuentren en determinado equipo, desde el equipo en cuestión. Por lo
que mover archivos y cambiar permisos se vuelve una tarea local y por lo tanto
el ancho de banda queda libre de estos procedimientos.

El comando a ejecutar tiene un arreglo básico:

     ssh usuario@equipo

Este comando se puede modificar en el caso de que se quiera usar la interfaz gráfica a travez de la red. Una vez realizada la conexión es necesario usar [comandos de bash](?id=basicos) para interactuar con el equipo.

    ssh -X usuario@equipo

>  __Nota:__   
 Este comando permite el uso de programas en modo gráfico. Sin embargo la velocidad de conexión entre los equipos debe ser rapida. De lo contrario la interfaz es muy lenta. Incluso puede ejecutarse fuera de la red interna pero nuevamente sera muy lenta la interacción si la conexión es de baja velocidad.

Si se desea crear un tunnel se usa el comando

    ssh -D ##### usuario@equipo

Donde se sustituye el ##### por el número de puerto a usar.

Este comando permite generar un tunel al que se puede redirigir el tráfico del
navegador local para poder acceder a internet a traves de la red del instituto
e interactuar con el clúster.


Por ultimo, como ya se ha mencionado la conexión puede hacerse de manera externa al instituto. El usuario y contraseña son los que se usan en sesiones normales. Para conectarse de manera externa al instituto se requiere la dirección para realizar la conexión.

# Transferir archivos

Es posible transferir archivos de manera sencilla entre los equipos, tan solo poniendo el contenido en la carpeta de datos que nos corresponde.

Sin embargo es puede transferir archivos entre computadoras usando como base el protocolo ssh.

El comando básico de transferencia es `scp`, este comando transfiere datos de manera segura a cualquier zona del equipo objetivo donde tengamos permisos de escritura. Permite enviar algún archivo o directorio , así como descargar un archivo o directorio.

## Envio de archivo

    scp archivo usuario@equipo:/carpetadestino/

## Descarga de archivo

    scp usuario@equipo:/carpetaorigen/ /carpetadestino/archivo

Sin embargo este comando no permite resumir una descarga interrumpida y es básicamente una copia segura. En caso de querer resumir una descarga o poder hacer un copia que seleccione los archivos nuevos, es mejor el uso del comando `rsync`. Rsync permite la copia de un archivo a traves de conexiones seguras, así como de conexiones sin encriptación.

En el caso de una conexión sin encriptación solo se usa el comando que no declara el protocolo.

## Para copiar un archivo a la carpeta destino

    rsync -auvzh /carpetaorigen/archivo /carpetadestino/

## Si se quiere copiar todo el directorio

    rsync -auvzh /carpetaorigen /carpetadestino/

Esto copiaría la `carpetaorigen` completa en la carpeta destino.
Para hacer las transferencias a traves de ssh:

## Para copiar un archivo a la maquina remota

    rsync -e 'ssh' /carpetaorigen/archivo usuario@equipo:/carpetadestino/

## Para copiar la carpeta completa a la maquina remota

    rsync -e 'ssh' /carpetaorigen usuario@equipo:/carpetadestino/

## Para copiar un archivo del equipo remoto a la carpeta local

    rsync -e 'ssh' usuario@equipo:/carpetaorigen/archivo /carpetadestino/

## Para copiar la carpeta completa del equipo remoto a la carpeta local

    rsync -e 'ssh' usuario@equipo:/carpetaorigen /carpetadestino/



# ssh-keygen
Es un utilidad que permite generar, administrar y convertir llaveros de autentificación para el protocolo ssh.
[Revisa este link ](ssh-keygen)

# **Tensor de Estructura con OrientationJ**

OrientationJ es una herramienta poderosa para analizar y caracterizar propiedades de las fibras, como la orientación y la anisotropía. Esta guía te mostrará cómo utilizar el plugin OrientationJ en FIJI, cómo ajustar las configuraciones según tus objetivos de análisis y cómo interpretar los datos resultantes.

Para obtener información más detallada, consulta la documentación oficial en su sitio web: [Documentación de OrientationJ](http://bigwww.epfl.ch/demo/orientation/).


### 1) Descargar e instalar el plugin.
Primero, descarga el plugin `OrientationJ_.jar` desde el sitio web de la documentación. Una vez descargado, arrastra y suelta el archivo en la carpeta "plugins" dentro del directorio de instalación de FIJI. Reinicia FIJI para activar el plugin.

### 2) Accediendo a OrientationJ
Después de reiniciar FIJI, encontrarás OrientationJ en el menú de plugins. El plugin ofrece varias opciones de análisis, cada una adaptada a diferentes aspectos de la exploración histológica.

### 3) Parámetros clave para el análisis
Antes de profundizar en las diferentes opciones, es esencial entender dos parámetros principales que necesitarás configurar:

* **Ventana Local**: El tamaño de la ventana local determina el vecindario de píxeles sobre los cuales se realiza el análisis, funcionando esencialmente como un kernel Gaussiano. El tamaño adecuado de la ventana depende de la estructura anatómica que estés analizando. Es crucial experimentar con diferentes tamaños de ventana para encontrar el más adecuado para tus objetivos de análisis. Una vez que hayas elegido un tamaño de ventana local, asegúrate de mantener la consistencia en todos los análisis para lograr comparabilidad.

* **Gradiente**: Deberás elegir un método de gradiente para el análisis. El gradiente de *Cubic Spline* es recomendado por los desarrolladores por su velocidad y precisión, aunque puedes explorar otras opciones si lo consideras necesario.


![Captura de pantalla 2024-08-13 a la(s) 4.25.32 p.m.](https://hackmd.io/_uploads/B1ep6LF5C.png)

---

Ahora revisemos las opciones de análisis:

## Análisis con OrientationJ

Esta es la opción **cualitativa** del tensor de estructura. Este análisis calculará una serie de imágenes basadas en la textura de la histología. Para este ejercicio, utilicé una tinción por inmunofluorescencia de MBP con un acercamiento a la cápsula interna del cerebro:
![Captura de pantalla 2024-08-13 a la(s) 5.37.16 p.m.](https://hackmd.io/_uploads/r1iZJOYc0.png)

En este caso, seleccioné todas las opciones para mostrar todas las funciones. ¿Qué significan?

* **Gradiente-X y Gradiente-Y**: Estos gradientes son las primeras derivadas de los valores de intensidad de la imagen en las direcciones horizontal (X) y vertical (Y). Proporcionan información sobre cómo cambia la intensidad de la imagen a lo largo de estos ejes, lo cual es crucial para detectar bordes y la orientación de las estructuras dentro de la imagen.

* **Energía**: Esto mide la cantidad total de variación de intensidad dentro de la ventana local. Se calcula a partir de los valores propios del tensor de estructura y refleja la fuerza general de la señal direccional. Por ejemplo, una alta energía puede indicar patrones de orientación fuertes y consistentes, mientras que una baja energía podría significar una distribución de orientaciones más isotrópica o aleatoria.

* **Orientación**: Se refiere a la dirección dominante de las estructuras dentro de la ventana local. Esto se calcula a partir del vector propio principal del tensor de estructura, representando básicamente el ángulo en el que están alineadas las estructuras.

* **Coherencia**: Esto cuantifica el grado de anisotropía, o uniformidad direccional, de la estructura. Una alta coherencia (1) indica que las estructuras están bien alineadas en una sola dirección, mientras que una baja coherencia (0) sugiere una estructura más aleatoria o isotrópica. Matemáticamente, se deriva de los valores propios del tensor de estructura, donde un valor alto de coherencia significa que la diferencia entre los valores propios es grande.

* **Color-Survey**: Esta es una representación visual de las orientaciones, donde diferentes orientaciones se asignan a colores específicos (dependiendo de su dirección). Cada color corresponde a una orientación específica, lo que permite una identificación rápida de patrones y anisotropías en la imagen.

Aquí abajo se muestran ejemplos de cómo se ven:

![Captura de pantalla 2024-08-13 a la(s) 5.37.36 p.m.](https://hackmd.io/_uploads/SktlfuY5A.png)

## OrientationJ Distribution

Esta opción te permite analizar la distribución de las orientaciones dentro de la imagen. Los parámetros en la sección *Structure Tensor* son similares a los de la opción `OrientationJ Analysis`, por lo que no proporcionarán información diferente. Sin embargo, **para este análisis, las configuraciones clave en las que enfocarse son las opciones `Histogram` y `Table`**:

![Captura de pantalla 2024-08-13 a la(s) 6.16.31 p.m.](https://hackmd.io/_uploads/SyG3v_Y9R.png)

Cuando se seleccionan, estas opciones generarán un histograma que muestra la distribución de orientaciones a lo largo de la imagen. El histograma traza la frecuencia de cada orientación en el eje Y en comparación con los grados correspondientes en el eje X. Esta representación visual ayuda a comprender la alineación general de las estructuras.

Además del histograma, y lo más importante, la misma información de distribución de orientaciones también se proporciona en un formato de tabla y se puede guardar como un archivo CSV para un análisis estadístico más detallado. Esta función es especialmente útil para un análisis de datos más detallado o personalizado fuera de FIJI.

![Captura de pantalla 2024-08-13 a la(s) 6.16.40 p.m.](https://hackmd.io/_uploads/S1MhDOKqC.png)

---

## OrientationJ Measure

Esta opción te permite calcular el Tensor de Estructura (ST, por sus siglas en inglés) dentro de Regiones de Interés (ROIs) específicas. Para seleccionar el área que deseas medir, usa la herramienta de rectángulo o círculo en la barra de herramientas de FIJI. Una vez que hayas definido el ROI, haz clic en el botón `Measure` en la ventana `OrientationJ Measure`. Esto superpondrá dos círculos en tu imagen de histología: un círculo morado que representa el ROI y una elipse naranja que representa el ST calculado.

La elipse naranja representa visualmente la anisotropía y la orientación principal (primer valor propio) de la estructura subyacente. Por ejemplo, si la elipse está alargada y alineada con las fibras, indica un alto grado de anisotropía y una orientación clara. En el ejemplo, el tensor número uno muestra una forma bien alineada y más delgada, lo que significa que la anisotropía es mayor en comparación con otros, como la elipse número dos. En el lado derecho de la ventana, encontrarás un resumen de los resultados, que puedes copiar para un análisis posterior.

Puedes medir tantas ROIs como necesites, y cada una será identificada con un número único tanto en la imagen como en la tabla de resultados. También puedes personalizar el color y el grosor de la línea de la elipse y el ROI haciendo clic en la sección `Options`.

![Captura de pantalla 2024-08-15 a la(s) 11.44.01 p.m.-2-2-2](https://hackmd.io/_uploads/SkZ8tw29A.png)

Otra función útil es la capacidad de crear una máscara binaria a partir de los ROIs seleccionados. Esta máscara se puede utilizar para un procesamiento adicional en FIJI que requiera áreas segmentadas.

![Captura de pantalla 2024-08-15 a la(s) 11.55.40 p.m.-2](https://hackmd.io/_uploads/r1rkjv390.png)

## OrientationJ Vector Field

Finalmente, esta opción te permite calcular y visualizar un campo vectorial en toda la imagen de histología. Esta representación vectorial se deriva de la orientación dominante y la anisotropía dentro de cada ventana local, proporcionando una guía visual de patrones y alineaciones en la imagen.

Puedes modificar el tamaño de la cuadrícula del campo vectorial, lo que controla el espacio entre los vectores. A medida que ajustas el tamaño de la cuadrícula, las líneas vectoriales abarcarán más o menos píxeles, cambiando efectivamente la resolución de la ventana local utilizada para calcular los vectores. Los tamaños de cuadrícula más pequeños resultan en un campo vectorial más denso, mientras que los tamaños de cuadrícula más grandes producen una representación más dispersa.

En el ejemplo siguiente, el tamaño de la cuadrícula se ajustó de 80 a 10. Se recomienda elegir un tamaño de cuadrícula que mejor se ajuste a la estructura subyacente de tu imagen para obtener la representación más precisa.

![Captura de pantalla 2024-08-16 a la(s) 12.18.24 a.m.](https://hackmd.io/_uploads/H1rlWMpqC.png)

Si bien la superposición de vectores proporciona una valiosa evaluación visual, la información más valiosa se encuentra en la opción `Table`. Esta tabla contiene datos esenciales como:

* **X y Y**: Las coordenadas de cada vector.
* **Orientación**: La orientación principal de cada vector.
* **Anisotropía (Coherencia)**: El grado de anisotropía asociado con cada vector.

Puedes guardar y exportar esta tabla para un análisis posterior en tu software preferido, lo que te permitirá una exploración más profunda de los patrones de orientación y anisotropía dentro de tu imagen.

![Captura de pantalla 2024-08-16 a la(s) 12.19.59 a.m.](https://hackmd.io/_uploads/B1WZWzTq0.png)

---

Espero que este tutorial le sea útil para cualquiera que esté realizando su análisis con el Tensor de Estructura.
Cualquier comentario o sugerencia para mejorar este tutorial es muy bienvenido! :smiley:
* [ssh]: secure Shell

* [VNC]: Virtual Network Computing 

# Acceso remoto por X2Go

## Opciones de Acceso

Accesar de manera gráfica a los equipos del cluster es sencillo con el uso del programa X2Goclient. Si bien el acceso se puede realizar también mediante **ssh**, este involucra el uso de la terminal o en el caso de usar la opción **-X** se tendrá un entorno gráfico que dependiendo del algoritmo de encriptación puede ser lento. Existen soluciones como **VNC** que requieren de la implementación de un servicio complejo en cada equipo a accesar.

## X2Go

**X2Go** Trabaja sobre ssh así que la seguridad es inherente al programa. Además usa algoritmos de compresión de imágenes que permiten una conexión dinámica con el equipo, que además se adapta modificando la compresión del flujo de imágenes provenientes del servidor con respecto al tipo/calidad de conexión a internet.

### Requerimientos

El software corre en **WINDOWS**, **MAC** y **Linux**. El servidor y el cliente ya se encuentra instalado en todos los equipos del cluster.

Para otros equipos necesitas descargar **X2GoClient** para tu sistema operativo:

* [Linux](http://wiki.x2go.org/doku.php/wiki:repositories:start) *Todas las versiones*
* [Mac](http://code.x2go.org/releases/X2GoClient_latest_macosx_10_9.dmg) *10.9+*
* [Windows](http://code.x2go.org/releases/X2GoClient_latest_mswin32-setup.exe)

> Windows requiere permisos de administrador para su instalación. Si no cuentas con permisos la instalación varía un poco, para más detalles visita el [X2Go wiki](http://wiki.x2go.org/doku.php/doc:installation:x2goclient)


> Mac requiere tener instalado [Xquartz](http://www.xquartz.org/), aunque si ya funciona freesurfer o FSL en tu equipo es probable que ya esté instalado.

En el caso de **Ubuntu** la instalación requiere:

    sudo add-apt-repository ppa:x2go/stable
    sudo apt-get update
    sudo apt-get install x2goclient

## Configuración

### IP de acceso al cluster

El acceso a los equipos del cluster depende de la red en la que nos encontramos trabajando. 

[[images/x2go_cluster.png]]

Como se muestra en la figura, dependiendo de la conexión será la IP que usaremo. Si nos encontramos en ethernet o mediante la red **RII** la conexión a la máquina se hace mediante una IP del tipo `172.24.80.70` *( Ejemplo: Jasper)*. Mientras que de la **RIU** o de **Internet** la conexión se hace a través `132.248.142.55` *PENFIELD exterior*. Afortunadamente, ya está homologado el nombre de penfield en cualquiera de las dos redes, así que lo recomendable es usar el nombre completo: **`penfield.inb.unam.mx`**.

### Acceso externo (penfield.inb.unam.mx o IP:132.248.142.55)

#### Crear nueva sesión

Para el acceso externo es importante recordar la configuración de redes de la figura anterior. Ya que la puerta de acceso al cluster es **PENFIELD** que tiene la IP `132.248.142.55`. Podemos escribir simplemente `penfield.inb.unam.mx`
Con esto en mente, presionamos el botón con una estrella amarilla como se muestra en la figura:

[[images/x2go_crearconexion.png]]

Al hacer click se abre la ventana con las opciones de conexión. En ella se configuran tres parámetros:

* **Host** dónde colocaremos la dirección  de **PENFIELD** `132.248.142.55`, o `penfield.inb.unam.mx`
* **Usuario** es el usuario que usamos al acceder al clúster. 
* :warning: Es muy importante que en la sección *Tipo de sesión*, seleccionemos el gestor **LXDE**. Ya que es el más liviano de los gestores disponibles, además de que **Unity** el típico gestor de **Ubuntu** no está disponible para este servicio.

Es importante que el **nombre de la sesión sea descriptivo** y haga referencia al servidor y a la conexión que se realiza.

[[images/x2go_configuracionPenfield1.png]]

Una opción recomendable es el uso de claves `RSA/DSA`, esto brinda mayor seguridad al acceder al clúster y con esto ya no es necesario introducir el password. De lo contrario cada vez que hagamos *login* nos pedirá el password de nuestra cuenta, de la misma forma que cuando se inicia sesión en los equipos del clúster.

#### Conexión

La pestaña conexión permite cambiar la compresión de las imagenes que se envían del servidor al cliente. Si nuestra conexión es lenta podemos mover el nivel a la opción de **MODEM**, sin embargo esto va en detrimento de la calidad de la imagen.

[[images/x2go_configuracionPenfield2.png]]

#### Propiedades

En esta ventana se puede modificar la resolución de inicio, tanto el ancho y el alto de la ventana dónde interactuaremos con el servidor, hasta los DPI de la misma. Sin embargo si se abre la ventana como en el ejemplo `800x600` al maximizar la ventana se adapta a la resolución de la pantalla.

![[images/x2go_configuracionPenfield3.png]]

#### Carpetas compartidas

Una opción muy interesante en **X2Go** es la posibilidad de compartir una carpeta local con el equipo remoto. Logrando así transferir datos de forma sencilla entre los equipos. 

Primero seleccionamos la ruta del directorio **LOCAL** y presionamos **Añadir**.

![[images/x2go_configuracionPenfield4.png]]

Esto agrega la ruta en el panel mayor donde tenemos la opción de **Automontar** la cual podemos seleccionar para que el directorio se monte inmediatamente despues de que accedemos al equipo.

![[images/x2go_configuracionPenfield5.png]]

Una vez configurada la sesión damos **OK** y se guardará. Para abrir la misma sólo será necesario dar click sobre alguna de ellas.

![[images/x2go_variasconexiones.png]]

### Acceso Interno (IP: 172.24.80.X)

Para crear una nueva conexión interna, debemos estar conectados a la red del **INB** ya sea por cable `ETHERNET` o mediante la red **RII**. El procedimiento es el mismo que el que describimos en la sección anterior. El único aspecto que cambia es la **IP** que se coloca en el **Host** siendo `172.24.142.80.X` dónde **X** es un número que cambia dependiendo del servidor al que se conecte. También podemos usar los nombres de las máquinas, como por ejemplo `hahn.inb.unam.mx` , o `fourier.inb.unam.mx`.

> Nota: En el **INB** también se puede abrir una sesión desde un equipo de bajo rendimiento como Arwen a el resto de los equipos de la red. Dejando el poder de procesamiento al equipo remoto. Tambíen una alternativa para acceder a algún software en la máquina remota.

> En algunos casos habrá que probar el acceso en redes dentro del **INB**, por ejemplo desde las aulas de posgrado el acceso es directo. Pero desde el CAC el acceso es externo.

### Acceso a otros equipos en el cluster (bunny hop)

La conexión externa a **PENFIELD** es de mucha utilidad para la interacción con el ambiente gráfico. Pero esto genera mucha carga al equipo, ya que la conexión de cinco usuarios consumiría muchos de los recursos del sistema. Con esto en mente es recomendable realizar conexiones al resto de los equipos del clúster para realizar un balance de la carga sobre este equipo.
Para ello usaremos una modificación de la configuración de sesión que permitira usar a **PENFIELD** como un proxy y conectarnos al resto de los equipos en el clúster.

Cambios:

* La **IP** del **Host** debe ser la asignada internamente al equipo, esta en general esta en el rango `172.24.80.X`, con una variación en el ultimo número. También podemos usar su nombre completo, como por ejemplo `hahn.inb.unam.mx`.
* Además seleccionamos la opción **Usar servidor Proxy para la conexión SSH**.
* Seleccionamos **Mismos datos de inicio de sesión que en el servidor X2GO**
* Seleccionamos el tipo de servidor como **SSH**
* En el **Host** del Servidor Proxi usamos la **IP** de **PENFIELD** `132.248.142.55`, o su nombre completo, `penfield.inb.unam.mx`.

Podemos usar una clave **RSA/DSA**, aunque si no se usa de cualquier forma al acceder se nos pedira el password relacionado con el usuario.

![[images/x2go_config_01.png]]

## Cerrar sesión

Al terminar de utilizar el equipo se puede salir de dos formas. Cerrando la sesión en el equipo remoto. Primero usamos el botón para cerrar sesión.

![[images/x2go_cerrarsesion2.png]]

Esto desplegará la ventana de sesión y ahí seleccionaremos el botón **Logout** para cerrar la sesión.

![[images/x2go_cerrarsesion3.png]]

> **CUIDADO:** No debemos apagar, reiniciar, Hibernar o Suspender el equipo. Podría causar un problema al funcionamiento del clúster.
 
También podemos cerrar la ventana de X2Go manteniendo los programas y el espacio de trabajo activos. Esto ya sea cerrando la ventana principal de X2Go o presionando `Ctrl + Alt + T`.

> **Precaución:** Si bien los programas se conservan, existe la posibilidad de que la sesión no se pueda recuperar. No es común y se puede deber a un error del sistema pero es recomendable guardar los archivos en los que trabajamos.

## Problemas con recarga de sesión 

Cuando abandonamos la sesión de trabajo, en ocasiones podemos tener problemas al retomarla nuevamente. Esto puede ser por velocidad de conexión, para lo cual modificamos en preferencias la velocidad de conexión. Pero también puede deberse a que algunos de los salvapantallas entorpecen el incio de sesión. Por lo que es recomendable desactivar los salvapantallas de la sesión lxde.

Se logra abriendo el **Menú de inicio** > **Preferencias** > **Screensarver**. En la ventana simplemente cambiamos el nombre del screensaver, que por default esta en alaeatorio y seleccionamos la opción de **"Disable Screen Saver"**, que también puede ser seleccionada la opción **"Black Screen Only"**. Con esto se puede retomar la sesión con mayor facilidad.

## Evitar screensaver (salvapantallas)
El screensaver está activado por defecto en la PC a la que nos estamos conectando (servidor). Cuando se inicia el screensaver (por inactividad en la sesión), los gráficos se transmiten por internet hacia la máquina cliente. Esto genera mucho tráfico innecesario en la red. Afortunadamente, es fácil desactivar el screensaver en LXDE:

Primero buscamos la aplicación del screensaver:

![](https://github.com/c13inb/c13inb.github.io/blob/master/images/screensaver_paso1.png)

Y lo desabilitamos: 

![](https://github.com/c13inb/c13inb.github.io/blob/master/images/screensaver_paso2.png)**Tabla de contenidos**

  + [[Home]]
  + [Como colaborar en la Wiki](./Modificar-Wiki)
  + [rocket.chat](./rocket.chat)
  + [[Resonadores]]
    + [Bruker](./Resonadores:Bruker)
    + [GE](./Resonadores:GE)
    + [Philips](./Resonadores:Philips)
  + [[Bash]]
    + [Comandos Básicos](./Bash:-Comandos-Básicos)
    + [Avanzado](./Bash:-Avanzado)
  + [[Clúster]]
    + [Organización de datos](./Clúster)
    + [Respaldo de datos](./Clúster:-Respaldo-de-datos)
    + [Gestión de procesos](./Bash:-Gestión-de-procesos)
    + [Módulos](./Modules)
    + [Uso del clúster](./Clúster:-Uso-del-clúster)
    + [Errores del clúster](./Clúster:-Errores-del-clúster)
    + [Agilizando tu sesión](./Cluster:XDG)
  + [Procesamiento de Imágenes](./Procesamiento-Imagen)
    + [Herramientas](./Procesamiento-Imagen)
       * [FSL](./FSL)
       * [MRtrix3](./MRtrix3)
       * [FreeSurfer](./Grosor-cortical)
       * [BIDS](./BIDS)
    + [Transformación de datos](./Procesamiento-Imagen?id=Transformación-de-Datos)
  + [fMRI](./fMRI)
    + [FEAT](./FEAT)
    + [fMRI en roedores](./fMRI-roedores)
    + [Conectividad Funcional Basada en Semilla](https://github.com/c13inb/c13inb.github.io/wiki/Conectividad-Funcional-Basada-En-Semilla)
  + [DW-MRI](./DWMRI)
    + [Preprocesamiento humanos.](./DWMRI:-Preprocesamiento-humanos)
    + [Preprocesamiento roedores.](./DWMRI:-Preprocesamiento-roedores)
    + [Tractografía](./MRtrix3:-Tractografía)
    + [Multi-tensor](./DWMRI:-Multi-tensor)
    + [Registro](./DWMRI:-Registro)
    + [DSIstudio](./DWMRI:DSIstudio)
  + [FIJI - Análisis histológico](./FIJI)
    + [Tensor de Estructura](./TensorEstructura)
    + [Stitching](./Fiji:stitching)
  + Herramientas Software
    + [rclone](./rclone)
    + [X2Go](./X2Go)
    + [SSH](./SSh)
    + [Git](./git)
    + [Anaconda](./Anaconda)
  + Otros
    + [markdown](./markdown)# Convertir con `brkraw`
###### tags: `tutorials` `Cluster` `bruker`

# Anaconda
Hay que instalar anaconda. Hay instrucciones [aquí](https://github.com/c13inb/c13inb.github.io/wiki/Anaconda) para instalarlo en el cluster.
Si no queremos instalar anaconda, podemos usar la instalación de `lconcha`. En ese caso, agregamos lo siguiente a `~/.bashrc`:

```bash=
echo "Use anaconda_on to turn on anaconda".
function anaconda_on() {
echo "[INFO] Initializing anaconda..."
# >>> conda initialize >>>
# !! Contents within this block are managed by 'conda init' !!
__conda_setup="$('/misc/mansfield/lconcha/software/anaconda3/bin/conda' 'shell.bash' 'hook' 2> /dev/null)"
if [ $? -eq 0 ]; then
    eval "$__conda_setup"
else
    if [ -f "/misc/mansfield/lconcha/software/anaconda3/etc/profile.d/conda.sh" ]; then
        . "/misc/mansfield/lconcha/software/anaconda3/etc/profile.d/conda.sh"
    else
        export PATH="/misc/mansfield/lconcha/software/anaconda3/bin:$PATH"
    fi
fi
unset __conda_setup
# <<< conda initialize <<<
echo "   anaconda is ready."
}
```

Ahora prendemos anaconda:

    anaconda_on
    
Y activamos el ambiente de brkraw

    conda activate /home/inb/lconcha/fmrilab_software/inb_anaconda3/envs/brkraw
    
Listo, brkraw está listo para usar.

# Convertir archivos
Podemos usar la forma gráfica de brkraw con el siguiente comando, y seguir los cuadros de diálogo que son bastante intuitivos para navegar a la carpeta que queremos convertir. 

    brkraw gui

![](https://i.imgur.com/V7KkJtG.png)
![](https://i.imgur.com/4t95zed.png)



Pero abajo vemos una forma más fácil para llegar directamente a los datos que nos importan.

## Encontrar archivos
Primero localizamos los archivos que queremos convertir. En 2023, estamos grabando en el disco `data02` de la consola del resonador, llamada `bruker7`. Este disco está accesible desde las PCs del cluster en `/misc/bruker7/data02`.

Por ejemplo, para encontrar un escaneo realizado el 9 de abril de 2023, podemos hacer:

    ls -d /misc/bruker7/data02/user/conchalab/20230409*
    
:spiral_note_pad: El `-d` es para solo mostrar los nombres de las carpetas, no subcarpetas.

Esto nos arroja:

```bash
lconcha@mansfield:~$ ls -d /misc/bruker7/data02/user/conchalab/20230409*
/misc/bruker7/data02/user/conchalab/20230409_111448_hluna_PTZirm2_rata1_hluna_PTZirm2_rata1_1_1
/misc/bruker7/data02/user/conchalab/20230409_112523_hluna_PTZirm2_rata1_2_hluna_PTZirm2_rata1_2_1_1
/misc/bruker7/data02/user/conchalab/20230409_123543_hluna_PTZirm2_rata3_hluna_PTZirm2_rata3_1_1
/misc/bruker7/data02/user/conchalab/20230409_134323_hluna_PTZirm2_rata4_hluna_PTZirm2_rata4_1_1
/misc/bruker7/data02/user/conchalab/20230409_144815_hluna_PTZirm2_rata5_hluna_PTZirm2_rata5_1_1
/misc/bruker7/data02/user/conchalab/20230409_155337_hluna_PTZirm2_rata6_hluna_PTZirm2_rata6_1_1
/misc/bruker7/data02/user/conchalab/20230409_165719_hluna_PTZirm2_rata5_2_hluna_PTZirm2_rata5_2_1_1

```

Con eso vemos todas las ratas escaneadas en tal fecha. Decidimos que queremos convertir, por ejemplo, la `rata4` y queremos colocar el archivo resultante en la carpeta `/misc/mansfield/lconcha/TMP`, entonces:

## Convertir
Como ya sabemos dónde está la carpeta, se la damos de una vez a brkraw:

    brkraw gui -i /misc/bruker7/data02/user/conchalab/20230409_134323_hluna_PTZirm2_rata4_hluna_PTZirm2_rata4_1_1

Esto abre directamente la carpeta del animal que queremos. A la izquierda vemos la lista de escaneos. En el panel de en medio vemos las imágenes, y podemos usar los _sliders_ para cambiar rebanada/volumen. A la derecha vemos información relevante al escaneo. 

![](https://i.imgur.com/YL4bWR7.png)


:one: El botón *SetOutput* nos permite decir en dónde queremos colocar el archivo resultante. Al darle clic, navegamos a la carpeta donde queremos aventar nuestros archivos NIFTI resultantes (en este ejemplo, en `/misc/mansfield/lconcha/TMP`)

:two: Ahora, seleccionamos la imagen que queremos convertir, y simplemente presionamos *Convert* 

![](https://i.imgur.com/IQxbAZm.png)

Ya con calma, vamos a la carpeta donde se guardó nuestro archivo, y cambiamos el nombre del chorizo que es actualmente a algo que sea más digerible (p.ej. `rata04_PTZ.nii.gz`).


## Pura línea de comandos
Ya vimos cómo hacer la conversión mediante la manera gráfica. Pero como soy flojo y odio los clics, prefiero hacer todo desde la línea de comandos.

Para ver la lista de los escaneos de la rata:

    brkraw  info /misc/bruker7/data02/user/conchalab/20230409_134323_hluna_PTZirm2_rata4_hluna_PTZirm2_rata4_1_1/
    
![](https://i.imgur.com/AgnDpdG.png)

La flecha roja apunta a la que quiero, que es el escaneo `02`

Y de una vez le vamos a decir cómo se va a llamar el archivo, para no tener que andarlo cambiando después. Entonces:

    brkraw tonii -o /misc/mansfield/lconcha/TMP/rata04_PTZ_T1 -s 2  /misc/bruker7/data02/user/conchalab/20230409_134323_hluna_PTZirm2_rata4_hluna_PTZirm2_rata4_1_1/

`tonii` está avisando que vamos a convertir, no a ver. `-o` está diciendo cómo se llamará el output (por eso sigue toda una ruta con el nombre del archivo resultante); `-s` está diciendo qué escaneo queremos (por eso sigue un `2`), y lo último que le dimos es la ruta del origen de los archivos del resonador.

![](https://i.imgur.com/9YesNSJ.png)# deepprep
13 de marzo de 2024

Cómo correrlo.

Debemos tener todo en bids.

```bash!
cd /misc/mansfield/lconcha/exp/glaucoma

ml singularity

lic=/home/inb/soporte/lanirem_software/freesurfer_7.4.1/license.txt 
deepprep=/misc/lauterbur/lconcha/nobackup/containers/deepprep.sif
bids_dir=/misc/mansfield/lconcha/exp/glaucoma/bids
out_dir=/misc/mansfield/lconcha/exp/glaucoma/tmp/out

singularity run \
  --nv \
  -B /home/inb/soporte \
  -B /misc/mansfield/lconcha/exp/glaucoma \
  $deepprep \
  $bids_dir \
  $out_dir \
  participant  \
  --fs_license_file $lic  \
  --anat_only \
  --skip_bids_validation \
  --device 0 \
  --cpus 8 \
  --participant-label sub-74805
```

A pesar de que especifiqué que solo corriera al sujeto `sub-74805`, hizo todas las superficies de freesurfer para >20 sujetos en menos de 3 horas. Sorprendente. Esto fue en `lauterbur`, usando la GPU.# Preproceso de 2D-EPI DWI con eddy

Analizar datos de difusión puede ser bastante sencillo, pero para lograrlo se requiere que los datos estén en buenas condiciones. Estos pasos buscan corregir algunos artefactos de adquisición y limpiar los datos lo más posible, de manera que la estimación de parámetros de difusión sea adecuada. El preprocesamiento es habitualmente más tardado y latoso que el procesamiento mismo, y cada paso es toda un tópico en constante investigación y desarrollo. Aquí se describen los pasos que seguimos habitualmente (julio 2021). El ejercicio está orientado a datos de roedor adquiridos con nuestro Bruker de 7 T, pero los conceptos son los mismos para datos de humanos. Estos pasos pueden usarse en su mayoría sin modificaciones con adquisiciones EPI3D.

:information_source: El comando `dwifslpreproc` de mrtrix encapsula la mayoría de estos pasos. Sin embargo, se sugiere que toda persona involucrada en difusión lea este ejercicio y arme su propio pipeline de preprocesamiento. Esto es por dos razones: Primero, las cajas negras nunca son buenas cuando uno se dedica a aprender cosas, y por éso estamos en el ámbito académico ¿no?. Segundo, los defaults de `dwifslpreproc` están afinados para datos de humanos, y cuando lidiamos con DWIs de roedores, la cosa cambia bastante.

:information_source: Otra fuente de información muy útil para aprender sobre preprocesamiento de DWI es [Andy's brain book](https://andysbrainbook.readthedocs.io/en/latest/MRtrix/MRtrix_Course/MRtrix_04_Preprocessing.html). Aunque los datos ahí preprocesados son de humanos, muchos de los conceptos son similares con lo que hacemos con datos de ratas. De paso date una vuelta por el resto de esa página, que está fenomenal.

:tipping_hand_person: Estos pasos han sido encapsulados en el script `inb_dwi_bruker_preproc.sh` disponible el 24 de agosto de 2021 en Don Clusterio. Invoca el comando sin argumentos para aprender su uso. El script tiene la ventaja que además de hacer todo ésto, utiliza `eddy_quad` para hacer un reporte de control de calidad. Como bonus, se generan imágenes `png` para una rápida visualización de mapas RGB antes y después de pre-procesar los datos. Ojo, que aunque existe el script, se recomienda leer esta entrada para que sepas qué hace esa caja negra. El script está pensado en datos EPI-2D de rata, pero es probable que funcione en ratón, y con datos 3D-EPI. Para datos de humanos sería más conveniente usar `dwifslpreproc`.

## Convertir de bruker a nifti
Hay dos maneras, con las herramientas de mrtrix y scripts del laboratorio, o con brkraw. 

Para este ejercicio, voy a usar unos datos adquiridos por Alejandra Garay e Hiram Luna que están guardados en una ruta de `/misc`  (que **se pueden bajar desde [este link](https://drive.google.com/file/d/1zsYkIuYDUeZZwslLpbwsX156dPn3T8Ci/view?usp=sharing)**), y sobre los que yo sé _a priori_ que el escaneo número `4` contiene los datos de difusión. Para facilitar el ejercicio, los convertiré en variables:

```bash=
BRUKERFOLDER=/misc/hahn2/difusion_aprendizaje/20210712_092738_INB_C13_hluna_irm1_rata277_1_1
SCANNUMBER=4
```


:information_source: Recordemos que si el B0map (map shim) se hace justo antes de la adquisición de difusión, entonces habrá dos reconstrucciones del scan `4`. La primer reconstrucción será siempre la de las imágenes de difusión, y la segunda es el B0map. Además, en el set de difusiones, podremos encontrar como reconstrucción aparte los mapas cuantitativos de DTI calculados por Paravision, los cuales podemos ignorar.

:information_desk_person: Más información sobre cómo convertir de bruker a nifti por [acá](https://github.com/c13inb/c13inb.github.io/wiki/Resonadores:Bruker).


:dizzy_face: Los archivos `.mif` contienen la información de los gradientes dentro de un encabezado en el archivo mismo. Los nifti no pueden hacer ésto, por lo que se requieren dos archivos más que siempre le acompañan, los bvalues y los bvectors. En lo personal odio un poquito tener que andar llamando a esos otros dos archivos cada que quiero hacer algo, así que prefiero usar archivos `mif`, pero nada impide que hagas todo tu procesamiento con archivos nifti.




### Convertir con brkraw
Primero que nada, debemos tener configurada anaconda, lo que logramos en el cluster con un simple `inb_anaconda_on`. [Acá hay más información](https://github.com/c13inb/c13inb.github.io/wiki/Anaconda) sobre anaconda en don clusterio.
Ahora iniciamos el ambiente `brkraw` que instaló lconcha.
```bash=
conda activate brkraw
```
Podemos usar brkraw mediante un ambiente gráfico mediante el comando `brkraw gui`, que es bastante intuitivo. Si así prefieres, adelante. Yo soy fan de la terminal, así que aquí va cómo le hago.

```bash=
brkraw tonii  -o r277 -s $SCANNUMBER $BRUKERFOLDER 
```
Checamos con `mrinfo` y notamos que el archivo generado tiene 202 volúmenes, como esperábamos. Además se generaron los archivos `.bvec` y `.bval` correspondientes.

Solo resta convertir a `mif`:
```bash=
mrconvert -bvalue_scaling false -fslgrad r277-4-1.bvec r277-4-1.bval r277-4-1.nii.gz dwi.mif
```

### Convertir vía mrtrix
Esta es la vía clásica y que usamos en el C13 mucho tiempo. Sin embargo, la opción mediante brkraw es más robusta y regresa archivos `bvecs` sin escalamiento. **Se sugiere usar la opción brkraw**.
```bash=
inb_bruker_recursive_convert_mih.sh $BRUKERFOLDER r277
```
Esto generará los archivos `.mih` de toda la adquisición. Podemos revisar cada uno con `mrview` y asegurarnos que `r277_004_DWI_3shell_E4.mih` es la adquisición que queremos. Veamos su header:
```bash=
mrinfo r277_004_DWI_3shell_E4.mih
```
```
mrinfo: [WARNING] transform matrix contains invalid entries - resetting to sane defaults
************************************************
Image name:          "r277_004_DWI_3shell_E4.mih"
************************************************
  Dimensions:        134 x 120 x 25 x 202
  Voxel size:        0.149254 x 0.15 x 1.25 x ?
  Data strides:      [ 1 2 3 4 ]
  Format:            MRtrix
  Data type:         signed 16 bit integer (little endian)
  Intensity scaling: offset = 0, multiplier = 1
  Transform:                    1           0           0      -9.925
                                0           1           0      -8.925
                                0           0           1         -15
  dw_scheme:         0,0,-0.0,21.0108281961807
  [202 entries]      0,0,-0.0,21.0108281961807
                     ...
                     -0.530627197518155,-0.218121955383739,-0.0463487605318663,1255.66462041204
                     -0.822044119613011,-0.337913080257368,-0.0718031910629095,3002.6031225321
```
Tiene 202 volúmenes y contiene la tabla de gradientes de difusión. Muy bien. 
Solo nos falta convertir a `mif` (recordemos que `mih` es solo un header, no los datos).
```bash=
mrconvert -bvalue_scaling false r277_004_DWI_3shell_E4.mih dwi.mif 
```
:warning: Revisa los bvalues resultantes en `dwi.mif`, pues mrtrix puede escalarlos. El `-bvalue_scaling false` esta ahí para evitar el escalamiento, pero a veces esto puede ser algo confuso. Lee más al respecto en la [documentación de mrtrix](https://mrtrix.readthedocs.io/en/latest/concepts/dw_scheme.html). Para revisar, usa `mrinfo dwi.mif -shell_bvalues`.



## Revisando los datos crudos
:thumbsup: Independientemente de la vía de conversión que elegimos, estamos listos para preprocesar `dwi.mif`

Primero que nada, tenemos que ver las imágenes antes de preprocesar, si no cómo vamos a saber que sí las mejoramos al final.

```bash=
mrview dwi.mif
```

![](https://github.com/c13inb/c13inb.github.io/blob/master/images/raw_50.gif)

(si no se ve un gif animado con las imágenes, da clic [aquí](https://i.imgur.com/EbYzumN.gif).

Se ven primero las imágenes DWI, seguidas por cada dirección de gradiente de difusión con tres distintos valores b, cada una. Por eso la imagen se hace obscura periódicamente. Todas las imágenes son algo ruidosas, pero mientras más valor b, menos SNR; el denoising nos ayudará con ésto. Se aprecia cómo a lo largo de la adquisición la imagen se desplaza hacia abajo (ventralmente). En algunas imágenes se ve un fenómeno de enrollamiento en la parte ventral, donde aparece como fantasma el cerebro, debido a un artefacto común en EPI ([N/2 ghosting](http://mriquestions.com/nyquist-n2-ghosts.html)). 

![](https://i.imgur.com/HM0TKpi.png)
Esta vista triplanar muestra un volumen DWI con al menos dos rebanadas con _signal dropout_. En la vista coronal se nota claramente que la imagen está totalmente desplazada hacia abajo. Esta rebanada es un outlier, y deberá ser detectada por `eddy` como tal.

## Denoising


**Este debe ser siempre el primer paso del preprocesamiento**, para que la estructura del ruido esté intacta.

Usaremos `dwidenoise`, de mrtrix, usando todos sus defaults, lo que incluye que el estimador de ruido está basado en Cordero-Grande 2019. 
:information_source: El algoritmo de Cordero-Grande está disponible en mrtrix  versión 3.0.0 y superiores. Revisa la documentación de `dwidenoise` para asegurarte que lo tengas incluido. 
```bash=
dwidenoise -info -noise noiseestimation.mif dwi.mif dwi_d.mif
```
Este paso tarda unos 10 minutos. Al terminar, podemos ver los archivos `dwi.mif` (original), `dwi_d.mif` (denoised) y `noiseestimation.mif`:

![](https://i.imgur.com/LTLTqaQ.png)


:point_right: Una bonita alternativa para el denoising es el algoritmo de [LPCA de José Manjón](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0073021), encapsulado en el script `inb_dwidenoise_LPCA_manjon.sh`. Suele quitar aún más ruido que `dwidenoise` (a veces demasiado, pero pruébalo!).

## Unringing
Este proceso trata de minimizar los [anillos de Gibbs](http://mriquestions.com/gibbs-artifact.html) que pueden verse alrededor de bordes anatómicos muy prominentes. Para que sea eficiente, las imágenes deben adquirirse con llenado total del espacio k (es decir, sin Partial Fourier). Si se hizo denoising, este paso debe seguir inmediatamente, y por ningún motivo se debe hacer después de Eddy. 

*Las imágenes de este ejercicio tienen Partial Fourier, por lo que no deberíamos hacer unringing y brincarnos a Eddy*. Se incluye aquí para fines didácticos únicamente. Si se hiciera el unringing, el resto del preprocesamiento debe hacerse con el archivo `dwi_du.mif` en lugar de `dwi_d.mif`.

```bash=
mrdegibbs dwi_d.mif dwi_du.mif
```


## Eddy
Este paso corrige inhomogeneidades geométricas inducidas por los gradientes de difusión. Además elimina rebanadas con adquisiciones comprometidas (outlilers), en las que la señal es demasiado baja en comparación a lo esperado. Esto último es común en adquisiciones 2D-EPI, y se debe a que los gradientes de plano no aguantaron el ritmo solicitado para llenar el espacio k tan rápido. 

:point_right: Es de esperar un 10% de rebanadas outliers en toda la adquisición (algo común es una o dos rebanadas outliers por cada volumen, y la posición espacial de las rebanadas outliers deben ser aleatorias entre volúmenes).

`eddy` es un programa que forma parte de la suite fsl. Es notoriamente lento en CPU (varias horas!), pero en GPU corre muy, muy bien y en unos 10-15 min termina. Por lo tanto, no recomiendo usar `eddy` en una computadora que no tenga tarjeta de video Nvidia con los drivers CUDA instalados. 

:information_source: Si vas a instalar CUDA en tu laptop, encuentra las instrucciones por [acá](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html). 

En don clusterio, debemos preparar el ambiente para usar CUDA. Usa el siguiente comando:

```bash=
source /home/inb/lconcha/fmrilab_software/tools/inb_config_cuda9.sh
```
Revisa más información sobre CUDA en Don Clusterio en [este link](https://github.com/c13inb/c13inb.github.io/wiki/CUDA).

:information_source: El comando `nvidia-smi` te debe desplegar información acerca de la tarjeta de video y los procesos que están corriendo en el GPU (de hecho lo puedes usar como una alternativa a `top` para GPU).

:information_source: En una instalación en una computadora personal, lo ideal es hacer un soft link llamado `eddy` que apunte a `eddy_cuda9.1`, ambos dentro de la carpeta `$FSLDIR/bin/`. Así, si mandamos llamar a `eddy`, automáticamente se ejecutará la versión cuda.

La siguiente consideración es la versión de fsl. Para este ejercicio estaremos usando FSL 6.0.2. Asegúrate qué versión de fsl estás usando `cat $FSLDIR/etc/fslversion`

:information_desk_person: En don clusterio es fácil preparar tu ambiente para FSL 6.0.2 usando el alias `fsl602`.



Primero, convertimos nuevamente a nifti, porque fsl no sabe leer archivos `mif`.
```bash=
mrconvert dwi_d.mif dwi_d.nii \
  -export_grad_fsl bvecs bvals
```
Y preparamos algunas variables para hacer más fáciles de leer los comandotes que siguen.

```bash=
dwi=dwi_d.nii
bvec=bvecs
bval=bvals
```

Creamos una máscara. Hay muchas maneras de hacerlo, se puede hacer con [bet](https://github.com/c13inb/c13inb.github.io/wiki/FSL:-Brain-extraction-tool-BET) o similares, o hasta manualmente. En este ejercicio lo haré con `dwi2mask` de mrtrix. Independientemente de la herramienta usada, muy probablemente habría que editar manualmente su resultado para tener una buena máscara de cerebro. Por ahora no lo haré, pero si fuera a hacer un análisis formal, claro que lo haría.

```bash=
mask=${dwi%.nii}_mask.nii.gz
dwi2mask -fslgrad $bvec $bval $dwi $mask
```

Ahora preparamos los archivos que va a requerir `eddy`, que le dicen cómo fueron adquiridas las imágenes. Estos archivos son particularmente importantes cuando uno tiene adquisiciones con inversión de la polaridad del gradiente de fase, pero en nuestro caso no hay tal cosa, así que los podemos generar fácilmente con estos comandos que siguen. Para adquisiciones con inversión de polaridad de fase, consulta la documentación en la página de [topup](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/topup/TopupUsersGuide), donde se describe cómo generar un B0map a partir de pares de adquisiciones con fases invertidas, que después se alimentan a `eddy`. Yo (lconcha, abril-julio 2021) hice varias pruebas con adquisiciones 2DEPI en el Bruker y no encontré mucha ventaja a usar adquisiciones con pares de dirección de fase y el uso de `topup`, por lo que en este ejercicio no se utiliza.

```bash=
acqp=${dwi%.nii}_acqp.txt
index=${dwi%.nii}_index.txt
c4topup=0.0438;# this is just a guess
nvols=`fslnvols $dwi`
echo 0 -1 0 $c4topup > $acqp
indx=""
for ((i=1; i<=$nvols; i+=1)); do indx="$indx 1"; done
echo $indx > $index
```

Si vemos el contenido de los nuevos archivos, veremos que `$acqp` tiene un solo renglón, que dice que la segunda dimensión está codificada mediante fase (negativa). El número 0.0438 por ahora no se va a usar, pero en el caso de `topup` se usa para que el fieldmap quede con unidades correctas. El archivo `$index` es una lista de puros números uno, tan larga como el número de volúmenes. Si hubiéramos tenido diferentes adquisiciones mediante fase, habría más renglones en `$acq` y en `$index` nos diría a qué renglón (tipo de adquisición) corresponde cada volumen. Por ahora no se usa, así que es un solo renglón, y puros unos. Facilito.

Ahora sí, a correr `eddy`:

```bash=
outbase=${dwi%.nii}eddycorr
time eddy_cuda9.1 --verbose \
  --imain=$dwi \
  --mask=$mask \
  --acqp=$acqp \
  --index=$index \
  --bvecs=$bvec \
  --bvals=$bval \
  --residuals=true \
  --repol=true \
  --out=$outbase
```

En `mansfield`, con una pobretona tarjeta Nvidia GeForce GTX 650 Ti con 1 GB de memoria, esto terminó en 15 minutitos. Me hizo varios outputs, señalaré solo los más relevantes (el resto descritos [acá](https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/eddy/UsersGuide#Understanding_eddy_output)):

+ `${outbase}.nii.gz`. Nuestro output principal. Incluye las imágenes ya corregidas, a las que se les minimizaró el movimiento entre volúmenes, así como las inhomogeneidades geométricas inducidas por corrientes eddy. Además, las rebanadas outliers fueron remplazadas por datos factibles dado un modelo simple. Estas son las imágenes que se usarán después para cualquier modelo de DWI.
+ `${outbase}.eddy_rotated_bvecs`. Los vectores de los gradientes de difusión, una vez que fueron corregidos de acuerdo a las transformaciones geométricas que se le hicieron a cada volumen correspondiente. Por ejemplo, si un volumen se rotó 10 grados, el gradiente se rota también. En conjunto con `$bval` podremos usar cualquier modelo de difusión. 

:warning: Los volúmenes considerados como b=0 no tienen vector asociado. Estúpidamente, en este archivo aparecen sus componentes x,y,z como `nan`. Esto va a hacernos la vida difícil para los siguientes pasos. Es fácil remplazar todas las ocurrencias de `nan` por un cero usando el fabuloso [`sed`](https://www.grymoire.com/Unix/Sed.html#uh-1):
```bash=
sed -i 's/nan/0/g' ${outbase}.eddy_rotated_bvecs
```
:warning: De forma similar, el archivo `$bval` no tiene entradas con b=0 s/mm². El resonador calcula la contribución de los gradientes de codificación espacial al valor b, y habitualmente resulta en b=15 a 30 s/mm². Cambiar estas entradas a cero hará cambios realmente despreciables en toda estimación de parámetros de difusión, así que lo vamos a hacer ahora. (de hecho, si se quiere se puede hacer desde el principio de todo el preprocesamiento, es solo que hasta aquí se nota el efecto de la ausencia de valores b=0 en el archivo `$bval`). 

Solo debemos saber qué valor tenemos que cambiar, y suele ser el shell más bajo. Una manera simple es abrir el archivo `$bval` y revisar el número a cambiar, habitualmente en la primera entrada. Si la adquisición no inició con imágenes no pesadas a difusión, entonces usemos un método más robusto para encontrar el valor del shell con valor despreciable.
```bash=
mrinfo -fslgrad $bvec $bval $dwi -shell_bvalues
```
(pero cuidado porque redondea a 4 números decimales).

Vamos a quitarnos de problemas y abrir el archivo `$bval` en `gedit` o el editor de texto de nuestra preferencia, y sustituir todas las ocurrencias del valor b más bajo (en este caso 21.010828) por 0. Escribimos un nuevo archivo `bval_zeros`. Esto también lo podemos hacer en la terminal con el fabuloso `sed`: 

```bash=
sed 's/21.010828/0/g' $bval > bval_zeros
```

+ `${outbase}.eddy_outlier_report`.  Un archivo de texto que nos dice qué rebanadas en cada volumen resultaron ser outliers.
`${outbase}.eddy_outlier_map`.  Un archivo de texto con una simple visualización como tabla que nos dice por cada rebanada (columnas) en cada volumen (renglones), si es un outlier.

### Consideraciones sobre `eddy`
+ La mera verdad no logra registrar bien los volúmenes con SNR muy bajo, lo que suele suceder con alta resolución y bvalues altos (por ejemplo b=3000 s/mm²). Para el modelo del tensor no son útiles los bvalues altos, por lo que se sugiere no llegar más allá de 1200. Sin embargo, la mayoría de los solvers modernos para ajustar el tensor le dan un peso mayor o menor a cada dato dependiendo de su potencial de ser outlier. Por lo tanto, incluso dejando los volúmenes de bvals altos, los mapas resultantes son harto bonitos.

![](https://i.imgur.com/nsElYei.gif)
En esta animación se aprecia que la posición espacial no es homogénea entre volúmenes. Los volúmenes con bvalue más alto están mal registrados con respecto a los otros shells.

## Corrección de inhomogeneidad de intensidades (biasfield correction)
Este paso es también innecesario en caso de que se vaya a usar cualquier modelo que involucre dividir las DWI entre las b=0, como el modelo del tensor. De hecho, la enorme mayoría de los modelos hacen tal división en algún momento, pues lo que les interesa es la atenuación de la señal. 

La notable excepción es deconvolución esférica (CSD), que estima la distribución de la probabilidad de orientaciones de fibras directamente de la señal DWI (no de la atenuación), a partir de la deconvolución de una función de respuesta que actúa como un prototipo de cómo se porta la señal DWI en el caso de una sola población de fibras. Como se estima una sola función de respuesta por set de datos, es crucial que la señal DWI tenga intensidades homogéneas en toda la extensión de la sustancia blanca. Esta última suposición se rompe fácilmente, sobre todo si adquirimos nuestras imágenes con una antena de superficie (como la 2x2 o la cryoprobe). 

Usaremos `dwibiascorrect` de mrtrix, que en realidad es una envoltura para `N4BiasFieldCorrection` de [ANTS](http://picsl.upenn.edu/software/ants/). Por lo tanto, debes tener ANTS instalado. Los defaults de ambos comandos están diseñados para datos de humanos, así que es posible que se requiera un poco de ensayo y error hasta encontrar los adecuados. El comando en sí es muy fácil, mandando las opciones para ANTS a través de switches en `dwibiascorrect`. A continuación un ejemplo con opciones pasadas a ANTS que resultan en una buena corrección:

```bash=
dwibiascorrect ants \
  -fslgrad ${outbase}.eddy_rotated_bvecs bval_zeros \
  -mask $mask \
  -ants.s 2 \
  -ants.b [10,3] \
  $outbase.nii.gz \
  ${outbase%.nii*}_biascorr.nii.gz 
```
![](https://i.imgur.com/yVnbtRp.png)


## Viendo el resultado
Para terminar, veamos la diferencia entre un ajuste del modelo del tensor a los datos originales, y a los datos preprocesados. Usaremos mrtrix para hacer esta estimación, y truquitos para hacer todo en un jalón. Aprende a usar los pipes de mrtrix por [acá](https://mrtrix.readthedocs.io/en/latest/getting_started/command_line.html#unix-pipelines). Haremos mapas RGB del vector principal de difusión, a los que llamaremos `*_v1.mif`.

Primero, a partir de los datos originales:
```bash=
dwi2tensor -mask $mask \
  dwi.mif - | tensor2metric -vector orig_v1.mif - 
```

Ahora, a partir de los datos con denoise y eddy (no requerimos corrección de intensidad para el modelo del tensor, y no podemos hacer unring porque los datos tienen partial fourier):

```bash=
dwi2tensor \
  -fslgrad ${outbase}.eddy_rotated_bvecs $bval \
  -mask $mask \
  ${outbase}.nii.gz - | tensor2metric \
  -vector preprocessed_v1.mif -
```

Y los vemos con `mrview`:
![](https://i.imgur.com/VyYH2of.png)

Los mapas RGB son notablemente más claros cuando son derivados de imágenes preprocesadas. Hay mucho menos verde, que era causado por el drift de las imágenes a lo largo de la adquisición en dirección dorso-ventral, cosa que fue minimizada con el registro logrado con `eddy`. Aún quedan detalles, pero ciertamente estas imágenes ya están trabajables, sobre todo en s. blanca.
# **Paradigma de tarea en fMRI en ratas**

Si vas a trabajar con resonancia funcional en ratas hay varias consideraciones que se deben tener. Ten en cuenta que dependiendo del análisis que vayas a hacer necesitas elegir el preprocesamiento adecuado para tus imágenes. En el caso de secuencias de resting state considera siempre revisar la literatura científica, ya que el preprocesamiento de estas imágenes requiere varios pasos adicionales  que son impresidibles con respecto a los paradigmas de tarea en fMRI.  

Este caso analizaremos un tarea con diseño por bloques después de haber lesionado el nervio óptico derecho de la rata. En este experimento las ratas fueron escaneadas después de la lesión y se realizó la tarea por bloques de 20s de estimulación lumínica en el ojo derecho, 20 s sin estimulación y 20 s de estimulación lumínica del lado izquierdo.

Estos son los pasos que debes realizar previo a poder correr un GLM de primer nivel con FEAT. considera que se requiere de algunos comando de FSL y mrtrix.

### <u>Preparar imágenes para el analísis</u>



**Paso 1**. Copiar la carpeta de /misc/brucker al directorio de trabajo

```bash
cp -r /misc/bruker_pvDatasets3/nmrsu/20190827_112430_INB_C13_melatonina_ct03_7d_1_1/ $PWD
```

**Paso 2**. En entrar en la carpeta del primer sujeto y buscar la secuencia funcional y la estructural. En este caso la carpetas 5 y 6 corresponden las secuencias de interés.

```bash
/misc/purcell/alfonso/prueba_frmri_rata/20190827_112430_INB_C13_melatonina_ct03_7d_1_1/5/pdata/1
```

**Paso 3.** Correr el comando `inb_bruker_recursive_convert_mih.sh` dandole como argumentos la carpeta a convertir y el nombre prefijo a guardar. Esto convierte todas las imágenes a formato .mih

ejemplos:Preparar imágenes para el analísis

```bash
inb_bruker_recursive_convert_mih.sh 5 5;
 inb_bruker_recursive_convert_mih.sh 6 6
```

**Paso 4.** converter los mih a nifti con el comando `mrconvert` de mrtrix3

estructural:

```bash
mrconvert 5_005_T2_TurboRARE_E5.mih T2.nii.gz
```

funcional:

```bash
mrconvert 6_006_T2star_FID_EPI_rsfMRI_20s_uniE6_E6.mih fmri.nii.gz
```

Es normal que aparezca esta advertencia:

```bash
mrconvert: [WARNING] transform matrix contains invalid entries - resetting to sane defaults
mrconvert: [100%] copying from "5_005_T2_TurboRARE_E5.mih" to "T2.nii.gz"
mrconvert: [100%] compressing image "T2.nii.gz"
```

**Paso 5** abrir las imagenes con el visor de tu elección y revisar que hayan sido correctamente transformadas

```bash
fsleyes fmri.nii.gz T2.nii.gz
```

![](https://github.com/c13inb/c13inb.github.io/blob/master/images/rat_t2_fmri.png)


**Paso 6.** Crear una carpeta para el analisis y moverse a ella y también mover las imagenes a esta carpeta

**Paso 7.** Para poder aplicar `BET` es necesario cambiar las dimensiones del header del archivo a unas que el programa pueda leer. esto implica cambiar de micras a milímetros y es necesario hacerlo para ambas imágenes. las nuevas dimenciones 1x1x12mm para la T2 y 4.5x4.5x12mm.  este procedimiento quitará las etiquetas lo cual nos resulta conveniente.

***Nota imporante***: para que transforme todos los volúmenes de la fMRI tiene que agregarse un 1 adicional en el comando*

```bash
## convetir la T2
fslchpixdim T2.nii.gz 1 1 12
## convertir la fMRI
fslchpixdim fmri.nii.gz 4.5 4.5 12 1
```

**Paso 8.**  Voltear el eje  x ambas imagenes con el comando `fslswapdim`

```bash
# T2
T2.nii.gz -x y z T2_oriented.nii.gz
# fMRI
T2.nii.gz -x y z T2_oriented.nii.gz
```

**Paso 9.** Correr  `BET` para quitar cráneo y meninges de la T2. puede hacerse con `bet` o con `rbet` si tienes la fortuna de lograr instalarlo.

con  `bet`:

```bash
# T2
bet T2_oriented.nii.gz  T2_oriented_bet.nii.gz  -f 0.68 -g 0 -m
```

Posteriormente tendrás que hacer correcciones manuales

con `rbet`: primero neceistas estimar a ojo de buen cubero las coordenadas del centro de masa y el readio del cerebro de cada una de las secuencias. Puedes usar mrview o fsleyes para hacerlo. Una vez hecho esto escribes en la terminal: `rbet <input> <output>   -r  < radio en mm> -c <cordenadas (voxel) centro de masa>`

Ejemplo:

```bash
## T2
rbet T2_oriented.nii.gz T2_oriented_rbet.nii.gz -r 65 -c 126 150 11 -m
```

### **IMPRESIONANTI!!!**

![](https://github.com/c13inb/c13inb.github.io/blob/master/images/T2_rbet.png)



**Paso 10.**  Hacer la corrección de movimiento de la imagen funcional.

```bash
## para ver más opciones teclear mcflirt sin argumentos
mcflirt -in fmri_oriented.nii.gz -out mri_oriented_mocorr.nii.gz -mats -plots -report
```

**Paso 11**. Hacer el Bet para la imagen funcional

Con `bet`

```bash
bet fmri_oriented_mocorr.nii.gz bet fmri_oriented_mocorr_bet.nii.gz   -f 0.68 -g 0 -m
```

Con `rbet`

```bash
rbet  fmri_oriented_mocorr.nii.gz bet fmri_oriented_mocorr_bet -r 65 -c 32 38 11 -m
```

**Nota:** en el caso de la funcional solo trasformara un volumen, por lo cual después debes multiplicar la mascara por tu imagen funcional ya corrigida por el movimiento


**Paso 12.** multiplicar la imagen funcional por la mascara generada en el bet y sobreescribir la ya existente

```bash
fslmaths mri_oriented_mocorr.nii.gz -mul fmri_oriented_mocorr_bet_mask.nii.gz fmri_oriented_mocorr_bet.nii.gz
```

### **MARAVILLOSA JUGADA!!!**

![](https://github.com/c13inb/c13inb.github.io/blob/master/images/fmri_bet.png)



**Todo está listo para correr primer nivel en FEAT. No olvides desactivar el BET y la corrección de movimiento. SI deseas incluir como regresores los parámetros de movimiento puedes hacerlo importando el archivo con estos parámetros**

Un excelente **tutorial** que se sugiere siga todo usuario de fMRI es [Andy's brain book](https://andysbrainbook.readthedocs.io/en/latest/index.html). Es buenísimo para iniciarse en este mundo, y también está lleno de joyas para los más expertos.

Ese tutorial se complementa muy bien con [este otro](http://fsl.fmrib.ox.ac.uk/fslcourse/lectures/scripting/) para aprender a hacer scripts para organizar los datos y procesarlos en paralelo.

## Herramientas para fMRI

+ [FSL](./FSL)
+ [FEAT](./FEAT)
+ [Melodic](./FSL:-Melodic). Herramienta de análisis de componentes independientes (ICA). Utilizado para descomponer un único o múltiples conjuntos de datos 4D en diferentes componentes espaciales y temporales. Usualmente utilizado en secuencias de "resting-state".
+ [mni2surf](./FSL:-project-to-fsaverage). Cómo proyectar resultados volumétricos de espacio MNI a la superficie promedio fsaverage.
+ [BIDS](./BIDS). Estándar de almacenamiento de datos para trabajar con fMRI, DWI e imágenes anatómicas, mediante herramientas que favorecen la reproducibilidad de los análisis.

# fmriprep


[fMRIPrep](https://fmriprep.readthedocs.io/en/stable/) es una herramienta desarrollada por el grupo de Russ Poldrack que tiene como objetivo el pre-procesamiento de datos de resonancia funcional (BOLD) para su posterior análisis mediante otras herramientas. El pre-procesamiento de los datos es crucial para cualquier análisis de BOLD, ya sea de tareas, o de resting-state. Existe mucha controversia de cómo deben pre-procesarse los datos (ver, [por ejemplo](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5489207/)), pues algunas elecciones pueden llevar a diferentes resultados. fMRIPrep facilita la tarea de pre-procesamiento y ofrece varias alternativas que pueden calcularse de forma simultánea, facilitando la tarea del proceso de múltiples versiones de análisis.

> :star: No olvides visitar este otro [tutorial](https://github.com/lanirem/documentation/wiki/FMRIPREP-preprocessing) para correr fmriprep en el LAVIS.

Una vez que los datos están organizados en formato [BIDS](./BIDS), podemos utilizar [Singularity](https://singularity.lbl.gov/) para correr fMRIPrep. Además, utilzando el cluster, que está administrado mediante [SGE](https://es.wikipedia.org/wiki/Sun_Grid_Engine), se pueden correr varios sujetos de manera paralela. Para facilitar la vida, el script `fsl_sub` encapsula los comandos necesarios para la utilización del cluster SGE.


>  :warning:Si vas a correr muchos sujetos de forma simultánea, **existe el riesgo de que satures el cluster.**. Para evitarlo puedes hacer dos cosas:
1. Envía tus sujetos de diez en diez.
2. Solicita mucho RAM para cada uno de los trabajos utilizando el switch `-R` de `fsl_sub`.


Aquí abajo hay un ejemplo de un script para enviar a analizar a un grupo de sujetos. En el ejemplo, la carpeta BIDS (asignada a la variable `bidsDir`) tiene a los sujetos con nomenclatura `sub-????`, donde cada `?` indica un dígito. Es decir, hay desde el sujeto `sub-0001` hasta potencialmente el `sub-9999`. Entonces, para enviar a los sujetos `sub-0001` al `sub-0009`, podemos poner que se procesen los sujetos `${bidsDir}/sub-000?` en la línea donde generamos la lista de sujetos a procesar.

Como vemos en la línea que invoca a `fsl_sub`, estamos solicitando 8 GB de RAM para cada trabajo (`-R 8`), y en las opciones que pasamos a fmriprep, pedimos que el máximo de memoria sean 6000 MB (`--mem_mb 7000`). Como medida adicional, pedimos que cada trabajo no utilice más de un CPU con `--nthreads 1`. Estos detallitos harán que los usuarios de las computadoras no se enojen con nosotros porque estemos acabándonos los recursos de sus máquinas.

```bash
#!/bin/bash

## Indicamos los lugares donde están los datos.
## Ojo, todos deben estar en algún lugar dentro de /misc
# 1. El contenedor de fmriprep
container=/misc/mansfield/lconcha/containers/fmriprep.img
# 2. La ruta de los datos en formato BIDS
bidsDir=/misc/mansfield/lconcha/bids/datos_Circe
# 3. La ruta donde poner los resultados
outDir=/misc/mansfield/lconcha/TMP/out/test
# 4. Una ruta para archivos temporales
workDir=/misc/mansfield/lconcha/TMP/work



# Necesitamos una licencia de freesurfer
export FS_LICENSE=${FREESURFER_HOME}/.license

# Generamos la lista de sujetos a procesar
subjid=`ls -d ${bidsDir}/sub-000?`

# Enviamos los jobs de uno por uno al cluster.
for s in $subjid
do
  this_subject=`basename $s`
  this_subject=${this_subject/sub-/}
  echo "submitting job for subject $this_subject"
  fsl_sub -N pre_${this_subject} -R 8 \
  singularity run \
  --bind /misc $container \
  ${bidsDir} \
  $outDir \
  participant \
  --participant_label $this_subject \
  --fs-no-reconall \
  --ignore fieldmaps \
  --output-space template \
  -w $workDir \
  --resource-monitor \
  --write-graph \
  --fs-license $FS_LICENSE \
  --nthreads 1 \
  --mem_mb 7000
  echo ""
  sleep 1
done
```

Por supuesto, esto es solo un ejemplo, y la miríada de opciones de fMRIPrep pueden consultarse en el [respectivo manual](https://fmriprep.readthedocs.io/en/stable/).


# Revisar el output
`fmriprep` escribe muchos archivos, pero es muy fácil revisar el resultado a través de una página .html que crea por cada sujeto en la carpeta `$outDir`. Es tan sencillo como ir a la carpeta donde están los .html y dar clic en ellos para que se abran en un navegador.

Yo soy muy flojo, por lo que abro de diez en diez como pestañas en el navegador. Por ejemplo, como `outDir=/misc/mansfield/lconcha/TMP/out/test`, entonces puedo escribir en la terminal:
```
chromium-browser ${outDir}/fmriprep/sub-001?.html
```
y voy a ver los reportes del sujeto `sub-0010` al `sub-0019`.

:star:  Esto funciona incluso mediante `sshfs`!
[[images/git.png]]
 
Es un sistema de control de revisiones distribuido que tiene enfásis en velocidad e integridad de datos, así como la confiabilidad del mantenimiento de versiones de aplicaciones cuando éstas tienen un gran número de archivos de código fuente. Se ha convertido en el sistema de control de versiones más utilizado en el desarrollo de software.

Permite a varios usuarios interactuar con el mismo código actualizando las modificaciónes que introduzcan y combinándolas, evitando posibles conflictos. Además facilita la recuperación de diferentes commit's (versiones). Y la generación de ramas alternas a la principal permitiendo un cambio rápido entre la rama original y las ramas alternas.

Contenido en esta wiki:
+ [Comandos Básicos](./git:-Comandos-básicos) En esta sección puedes revisar una recopilación de los comandos básicos de git.
+ [Uso de git](./git:-Uso-de-git) En esta sección puedes revisar una explicación mas detallada sobre el uso de Git.



Descarga los cambios realizados en el repositorio remoto:
```bash
git  fetch
```

Impacta en la rama en la que te encuentras parado, los cambios realizados en la rama “nombre_rama”:
``` bash
git merge '<nombre_rama>'
```
Unifica los comandos ''fetch'' y ''merge'' en un único comando:
 ```bash
git pull
```

Confirma los cambios realizados: El “mensaje” generalmente se usa para asociar al ''commit'' una breve descripción de los cambios realizados:
 ``` bash
git commit -am "<mensaje>"
```

Sube la rama “nombre_rama” al servidor remoto:
 ```bash
git push origin ''<nombre_rama>''
```

Muestra el estado actual de la rama, como los cambios que hay sin commitear:
 ```bash
git status
```

Comienza a trackear el archivo “nombre_archivo”:
 ```bash
git add ''<nombre_archivo>''
```

Crea una rama a partir de la que te encuentres parado con el nombre “nombre_rama_nueva”, y luego salta sobre la rama nueva, por lo que quedas parado en ésta última:
 ``` bash
git checkout -b ''<nombre_rama_nueva>''
```

Si existe una rama remota de nombre “nombre_rama”, al ejecutar este comando se crea una rama local con el nombre “nombre_rama” para hacer un seguimiento de la rama remota con el mismo nombre:
 ```bash
git checkout -t origin/''<nombre_rama>''
```

Lista todas las ramas locales:
```bash
git Branch
```

Lista todas las ramas locales y remotas:
```bash
git branch -a
```

Elimina la rama local con el nombre “nombre_rama”:
 ``` bash
git branch -d ''<nombre_rama>''
```

Elimina la rama remote con el nombre “nombre_rama”:
 ```bash 
git push origin ''<nombre_rama>''
```

Actualiza tu repositorio remoto en caso que algún otro desarrollador haya eliminado alguna rama remota:
```bash git remote prune origin
```

Elimina los cambios realizados que aún no se hayan hecho ''commit'':
 ``` bash 
git reset --hard HEAD
```

Revierte el ''commit'' realizado, identificado por el “hash_commit”:
```bash
git revert ''<hash_commit>''
```

### Instalación y configuración de GIT

Se necesita instalar __git__ y __git-core__ para que funcione como __servidor__, si solo se requiere clonar un repositorio solo instalamos git:

    sudo apt-get  install git-core git  


### Clonar un repositorio

Para obtener una copia de un repositorio se usa la instrucción

    git clone usuario@penfield:/datos/penfield/git/proyecto.git

Con esta opción obtenemos una copia del repositorio maestro de el proyecto. Si el repositorio es nuevo no descargara nada.


### Crear un Repositorio ###

En el servidor se crea una carpeta que funcionara como repositorio, este debe ser configurado sin directorio de trabajo _(opción --bare)_, y con permiso de lectura escritura y ejecución para el grupo tanto en el sistema de archivos como en la configuración de __git__ _(opción --shared)_. Primero creamos la carpeta, determinamos los usuarios, grupos y permisos pertinentes para la carpeta y nos cambiamos a ella:


    mkdir -p /datos/penfield/git/proyecto.git
    chown usuario:fmriuser /datos/penfield/git/proyecto.git
    chmod g+wr /datos/penfield/git/proyecto.git
    cd /datos/penfield/git/proyecto.git

Dentro de la carpeta iniciamos el repositorio __git__:


    git init --bare --shared 


Hay que estar seguros de que el grupo de trabajo contiene a los usuarios que
podrán hacer modificaciones y que el repositorio (proyecto.git) esta a nombre
del grupo de trabajo.


A partir de este momento este repositorio se puede utilizar, aunque de momento no tiene nada dentro. Puede clonarse en el servidor local para comenzar a trabajar.

        git clone usuario@penfield:/datos/penfield/git/proyecto.git


Al clonarse, la instrucción creara una carpeta con el nombre del __proyecto__ en la carpeta donde se ejecuta este comando. 
En esta carpeta podemos agregar algún archivo para realizar el primer commit. Por ejemplo el archivo .gitignore para que git ignore ciertos archivos.

    echo "*.swp" > .gitignore
  
> __Nota:__    
> Esto es solo necesario si no se tienen archivos con los cuales hacer un commit o es la primera vez que se usa. Este comando por segunda vez podría eliminar modificaciónes posteriores sobre __.gitignore__

Ya con los archivos se realiza el commit

    git add .
    git commit -m 'Commit inicial'
    git push origin master

> __Nota:__
> En la primera vez se necesita usar master, para que se agregue la branch, de lo contrario no funcionara.


Ya clonado, los repositorios se agregan automaticamente, Sin embargo si es necesario se puede agrega un repositorio remoto:

    git remote add origin usuario@penfield:/datos/penfield/git/proyecto.git

Esta es la instrucción para agregar un repositorio que se accede por [ssh](?id=ssh), por lo que seguramente nos pedira un password. A menos que hayamos configurado una ssh-key para el servidor. La instrucción para agregar otro tipo de repositorio se encuentra en la [documentación](http://git-scm.com/book/en/Git-Basics-Getting-a-Git-Repository) de git.    



### Branchs ###


Para crear una Branch


    git checkout  mybranch


Para crearla y pasarse a ella 


    git checkout -b mybranch


Regresar a la branch principal 

    git checkout master


Para unir el trabajo de la rama nueva con la rama vieja, primero nos pasamos a
la rama maestra


    git checkout master


Y luego hacemos el merge de nuestra branch


    git merge mybranch


Cuando se hace un merge se suele dar prioridad al merge que primero se hace.
Además si el master de donde parte nuestra branch ha sido cambiado de alguna
forma, por ejemplo un merge de otra rama, git fusiona los diferentes snapshots.
Esto solo  cambia cuando al hacer el merge, la rama y el master cambian el
mismo archivo-línea. En este punto merge pide asistencia para definir a cual
darle prioridad.   

En el caso de querer borrar una branch se usa el comando:


    git branch -d mybranch


Para ver el último commit de cada branch:

    git branch -v

Para subir una rama en la que querramos colaborar, es necesario que exista el
repositorio y se usa el siguiente comando:

    git push origin myotherbranch

Es posible, si queremos que el nombre en el servidor remoto sea distinto,
determinar otro nombre para la branch, usando el comando:


    git push origin myotherbranch:otronombredelabranch


En la siguiente ocasión en la que un colaborador obtenga el repositorio
aparecera la rama que se subio al mismo. Pero esta rama sera solo un apuntador
a la posición origin/mybranch que no esta disponible para edición. Para poder
acceder a esta rama y poder hacer modificaciones se usa el comando:


    git checkout -b myotherbranch origin/myotherbranch


Si se quiere hacer automáticamente el fetch y el push es necesario activar el
tracking para dicha branch. Mediante:


    git checkout --track origin/serverfix


En versiones anteriores se usaba el siguiente comando:


    git checkout -b myotherbranch origin/myotherbranch


Si por ejemplo la rama en la que estamos trabajando deja de ser funcional y
necesitamos  borrar la rama remota se borra con el siguiente comando:


    git push origin :mybranch


Este comando funciona considerando el constructo de la función git push
_remotename_ __localbranch__: *remotebranch* y aquí nos deshacemos de la parte del
localbranch y le decimos que con eso forme el remotebranch. Al estar el local
vacío, sustituye la branch remota por nada.


### Uso cotidiano ###


En el uso cotidiano los pasos a seguir para registrar los cambios son:


    git add .
 
ó


    git add *


ó


    git add nombredearchivo


Esto agrega los archivos para que se anexen al siguiente commit. Después de
esto se hace el commit para consolidar los archivos y los cambios en la
historia de la carpeta:


    git commit


Esto abre un editor de texto (que se puede cambiar) que pide un mensaje que
pueda describir el commit. Si no se proporciona el mensaje no se realiza el
commit. Estos pasos se pueden resumir en el siguiente comando:


    git commit -a -m ‘My commit’




Donde: 

-a
: agrega todos los archivos con cambios al commit, pero no agrega
archivos nuevos  

-m
: permite escribir el mensaje para el commit entre comillas.  


Otro punto importante es observar el estado de los archivos en la carpeta, esto
se realiza mediante:


    git status


Incluso si se tienen los colores activados, este comando muestra en rojo los
archivos que no han sido incluidos en el commit y en verde los que sí se han
incluido. 


Para borrar archivos, se pueden borrar normalmente con rm nombre de archivo,
sin embargo cuando se haga el commit tendremos que borrar también con:


    git rm nombredearchivo


Siendo buena práctica desde el principio usar este comando en la carpeta con
git, ya que borra el archivo e informa de esto a git. O usar durante el commit
la opción -a, sin embargo en ocasiones si necesitamos más control es mejor
hacerlo paso a paso.


### Buenas prácticas
Cada desarrollador o equipo de desarrollo puede hacer uso de Git de la forma que le parezca conveniente: Sin embargo una buena práctica es la siguiente

Se deben utilizar 4 tipos de ramas Master, Development, Features, y Hotfix:

**Master**
Es la rama principal: Contiene el repositorio que se encuentra publicado en producción, por lo que debe estar siempre estable:

**Development**
Es una rama sacada de master: Es la rama de integración, todas las nuevas funcionalidades se deben integrar en esta rama: Luego que se realice la integración y se corrijan los errores (en caso de haber alguno), es decir que la rama se encuentre estable, se puede hacer un merge de development sobre la rama master.

**Features**
Cada nueva funcionalidad se debe realizar en una rama nueva, específica para esa funcionalidad: Estas se deben sacar de development: Una vez que la funcionalidad esté pronta, se hace un merge de la rama sobre development, donde se integrará con las demás funcionalidades. 

**Hotfix**
Son bugs que surgen en producción, por lo que se deben arreglar y publicar de forma urgente: Es por ello, que son ramas sacadas de master: Una vez corregido el error, se debe hacer un merge de la rama sobre master. 
Al final, para que no quede desactualizada, se debe realizar el merge de master sobre development.

Markdown es una manera rápida de escribir texto estructurado y con atajos fáciles para dar formato. Es muuucho más fácil de aprender que LaTeX, y casssi tan poderoso. No parece ser recomendable para escribir una tesis o un artículo, pero sí para escribir un tutorial. De hecho, toda esta wiki está escrita en markdown.

# Aprender markdown
No tiene caso escribir un tutorial aquí. Googlea "markdown tutorial" y algo encontrarás. Por ejemplo [éste](https://www.markdowntutorial.com/).


# Conversiones desde markdown
Algo interesante de markdown es que puede usarse el mismo archivo para generar una página web, un pdf, un ebook, y hasta [presentaciones](./markdown_presentations) (web y power point!).
Una herramienta sumamente útil para convertir de/desde markdown es [pandoc](https://pandoc.org/).
# Pandoc
- Es posible generar presentaciones con markdown usando [pandoc](https://pandoc.org/).
- Se convierte el archivo `.md` a una presentación html.
- Soporta `s5`, `slidy`, `slideous`, `dzslides` y el sexy `revealjs`.
- También soporta `pdf` mediante `beamer`!.
![pandoc](https://i.loli.net/2018/02/21/5a8d775f73d87.png)


# Reglas del `.md`
- Básicamente, seguir las reglas de markdown, usando bullet points.
- Los bullet points se indican con `-`
- Los niveles `#` indican nueva diapositiva.
- También se puede indicar nueva diapositiva con `---------`
- Instrucciones completas [aquí](https://pandoc.org/MANUAL.html#producing-slide-shows-with-pandoc).

# Ejemplo
```
---
title: Presentaciones geek
author: Luis Concha
---

# Pandoc
- Es posible generar presentaciones con markdown usando [pandoc](https://pandoc.org/).
- Se convierte el archivo `.md` a una presentación html.
- Soporta `s5`, `slidy`, `slideous`, `dzslides` y el sexy `revealjs`.
- También soporta `pdf` mediante `beamer`!.
![pandoc](https://i.loli.net/2018/02/21/5a8d775f73d87.png)

# Reglas del `.md`
- Básicamente, seguir las reglas de markdown, usando bullet points.
- Los bullet points se indican con `-`
- Los niveles `#` indican nueva diapositiva.
- También se puede indicar nueva diapositiva con `---------`
- Instrucciones completas [aquí](https://pandoc.org/MANUAL.html#producing-slide-shows-with-pandoc).
```

# Conversión de `.md` a `html`
```
pandoc -t FORMAT -s miarchivo.md -o mipresentacion.html
```

- Donde `FORMAT` debe ser uno de `s5`, `slidy`, `slideous`, `dzslides` o `revealjs`.

-------
Quieres ver un resultado?
Por [aquí!.](https://github.com/c13inb/c13inb.github.io/blob/master/presentaciones_geek.html)

-------

- `FORMAT` también puede ser `beamer`, pero en ese caso el output debe tener la extensión `pdf`
- Se puede indicar un _theme_ de `beamer`:
```
pandoc -t beamer -s miarchivo.md -V theme=Madrid mipresentacion.pdf
```
- [Aquí](https://hartwork.org/beamer-theme-matrix/) hay una galería de temas para beamer.


# Conversión a `.pptx`
- Se puede convertir a power point!
```
pandoc miarchivo.md -o mipresentacion.pptx
```


# Cosas que aún no comprendo
- Controlar el tamaño de las imágenes.
- Los diferentes formatos de salida html tienen opciones distintas y manejan el encabezado (título, autor) de manera diferente.
- Cómo hacer que un bullet-point largo quepa en una sola diapo.

# Opinión personal:
- Útil para presentaciones que contienen código y **tutoriales**.
- Difícil hacer que se vea _exactamente como quiero_ .
- Menos utilidad para presentaciones científicas (no geek).
Matlab corre sin problemas en el cluster usando su interfaz gráfica. La mayoría de los usuarios trabajan en matlab en solo una PC, pero hay ocasiones en que uno quisiera paralelizar código de matlab a través del cluster. Bueno, pues la manera oficial de hacerlo es con matlab pools, pero eso no está configurado (aún) en Don Clusterio. Sin embargo, si el tipo de problema se presta, podemos hacer un truco simpático para encapsular código de matlab en funciones de bash que se manden como trabajos en el cluster con SGE. Veamos un ejemplo:

## Encapsular matlab en bash

Haré un script de bash llamado `corre_matlab.sh`, que usará matlab para calcular el promedio de dos números. Lo sé, un ejemplo muy simplón, pero ya imaginarás que este ejemplo se puede modificar para códigos tan complicados como una película de Christopher Nolan.

```bash
#!/bin/bash
A=$1
B=$2

matlab_job=/tmp/m2d_$$_matlab_job.m
echo "addpath('/misc/mansfield/lconcha/scripts');" >> $matlab_job
echo "av = mean([${A} ${B}])" >> $matlab_job
echo "exit" >> $matlab_job

cat $matlab_job

matlab -nojvm -nodesktop < $matlab_job

rm -f $matlab_job
```


Veamos qué está pasando:

El script de bash recibirá dos argumentos, que asignará a variables `$A` y `$B`. 

Se generará un archivo de texto que contendrá los comandos de matlab. Las líneas con `echo` agregan los comandos de matlab. Si es necesario, agregamos cosas al `path` de matlab ahí. En el tercer `echo` se ve cómo se sustituyen las variables `$A` y `$B` (de bash) dentro de una función simple de matlab. 

La penúltima línea corre matlab sin GUI. Si el script de matlab hubiera escrito archivos, matlab se habría encargado de hacerlo, no bash.

Finalmente se borra el script temporal de matlab.

## Corriendo el script en el cluster.

Ahora, para correr esto en el cluster, sería sencillo:

1. Nos aseguramos de estar corriendo la última versión de fsl (fsl 6.0.2 o 6.0.5), pues aprovecharemos su gestor de SGE (`fsl_sub`). 
2. Dado que el script de prueba  se llama `corre_matlab.sh`, entonces enviamos al cluster así

```bash
PRIMERO=10
SEGUNDO=20
fsl_sub -N nombreDelJob -l /ruta/para/logs ./corre_matlab.sh $PRIMERO $SEGUNDO
```# Mover `home` del servidor a una computadora cliente


Ahora que estamos teniendo problemas con el servidor, `tesla`, se ha hecho muy lenta la lectura/escritura de datos al `home` de los usuarios. Esto sobre todo se nota al abrir programas como libreoffice, gedit, etc, que tienen que leer preferencias grabadas en `home`. 

Mientras encontramos una solución definitiva, hice un script que mueve todas las carpetas de configuración desde `tesla:/home/inb/USER` a alguna de las computadoras cliente. Lo lógico es moverlo a la máquina donde nos sentamos. Por ejemplo, Ale lo pondría en `hahn`, y Luis lo podría en `mansfield`. 

En el siguiente ejemplo, `USER2` ha movido su home desde `tesla` hacia `hahn`. 
![](https://i.imgur.com/jdskemd.jpg)

Ojo, que solo se copian las carpetas de configuración (las que están ocultas en `home`, y que inician con un punto `.`); los archivos *reales* que uno tenga en su home se quedan en el servidor. Después de copiadas las carpetas de configuración, se hacen links simbólicos para apuntar a su nueva localización en la computadora cliente (línea punteada).

## Mover carpetas (de ida)
Estando físicamente en la máquina que queremos usar, o conectado mediante ssh, usamos el comando `inb_create_home_links.sh`
```
lconcha@mansfield:~$ inb_create_home_links.sh 

inb_create_home_links.sh <machine> [-options]

 Copia los archivos de /home/inb/lconcha a una carpeta en /misc:
    /misc/[machine]/lconcha/nobackup/home_links


 Options:

 -h, -help : Imprime esta ayuda.
 -reverse  : Revierte los efectos de este script
             (regresa los archivos a /home/inb/lconcha)
             PRECAUCION: Importante especificar la misma [machine] que cuando se corrio de ida este script.

 
LU15 (0n(H4
INB, UNAM
Septiembre 2020
lconcha@unam.mx

```
Por favor revisa que la máquina donde vas a copiar tenga suficiente espacio en `/misc/machine`, donde `machine` es algo como `hahn`, `carr`, etc.


## Revertir cambios (de vuelta)
Usamos el mismo script, pero con el switch `-reverse`.


Como todas las cosas de andar copiando y moviendo archivos, vale la pena hacer un respaldo previamente.

# PPMI, BIDS
Para bajar datos de PPMI y convertirlos a [BIDS](./BIDS).

:information_source: Requiere [docker](https://www.docker.com/) y python 3.x, así como una cuenta en PPMI.

:star: Basado en [PyPMI](https://pypi.org/project/pypmi/).

## Bajar datos
1.Ir a [PPMI](https://ida.loni.usc.edu/pages/access/search.jsp?tab=collection&loginKey=1607884889662832790&userEmail=lconcha%40unam.mx&project=PPMI&page=DOWNLOADS&subPage=IMAGE_COLLECTIONS).
2. Ir a `Advanced Search` y buscar lo que queremos usando los criterios de inclusión/exclusión. Una vez encontrados, seleccionar los que queremos (o todos) y dar clic en `add to collection`. Generar una nueva colección, o usar una previa.
3. Ir a la pestaña `Data Collections`, buscar nuestra colección, y seleccionar los que queremos bajar ( o todos ). Usar `Advanced Download` para facilitar el que bajen todos en un único zip. 
![](https://i.imgur.com/vuKNzIb.png)
4. Bajar el archivo `.zip`. Copiarlo a una carpeta, y descomprimirlo (podemos usar `unzip` en la terminal)
5. El zip explotará en una carpeta llamda `PPMI`, que tiene una organización NO-BIDS (ver [aquí](https://github.com/rmarkello/pypmi/blob/master/pypmi/bids.py))
```
   └── PPMI/
        ├── SUB-1/
        |   ├── SCAN-TYPE-1/                      (e.g., MPRAGE_GRAPPA)
        |   |   ├── SCAN-DATETIME-1/
        |   |   |   └── SCAN-SERIES-1/
        |   |   |       └── *dcm
        |   |   └── SCAN-DATETIME-2/
        |   ├── SCAN-TYPE-2/                      (e.g., AX_FLAIR)
        |   |   ├── SCAN-DATETIME-1/
        |   |   |   └── SCAN-SERIES-2/
        |   |   |       └── *dcm
        |   |   └── SCAN-DATETIME-2/
        |   ├── .../
        |   └── SCAN-TYPE-N/
        ├── SUB-2/
        ├── .../
        └── SUB-N/
```
Queremos convertir esta jerarquía en BIDS. Usaremos las herramientas de `pypmi`.

## Convertir a BIDS
Para fines de este documento, la carpeta PPMI quedó en `/mnt/newssd/rene/PPMI`, y la carpeta BIDS quedará en `/mnt/newssd/rene/bids`
1. Asegurarnos que tenemos python. Yo estoy probando con Anaconda con python versión 3.8.3.
2. Instalamos las dependencias
```bash=
pip install pypmi pydicom nibabel docker
```
3. Abrimos `ipython` para trabajar.
```bash=
ipython
```
4. Dentro de ipython:
```python
from pypmi import bids
bids.convert_ppmi('/mnt/newssd/rene/PPMI','/mnt/newssd/rene/bids') 
```
La primera vez que lo corremos se tarda un poco, pues tiene que bajar un docker container de [heudiconv](https://github.com/nipy/heudiconv), y no hay mucha información en la terminal (me dí cuenta porque ví que estaba bajando muchos MB/s).
Al terminar, tendremos nuestra carpeta bids
```bash
(base) lconcha@syphon:/mnt/newssd/rene$ tree bids/
bids/
├── CHANGES
├── dataset_description.json
├── participants.tsv
├── README
├── sub-3108
│   ├── ses-1
│   │   ├── anat
│   │   │   ├── sub-3108_ses-1_run-01_T1w.json
│   │   │   └── sub-3108_ses-1_run-01_T1w.nii.gz
│   │   ├── dwi
│   │   │   ├── sub-3108_ses-1_run-01_dwi.bval
│   │   │   ├── sub-3108_ses-1_run-01_dwi.bvec
│   │   │   ├── sub-3108_ses-1_run-01_dwi.json
│   │   │   ├── sub-3108_ses-1_run-01_dwi.nii.gz
│   │   │   ├── sub-3108_ses-1_run-02_dwi.bval
│   │   │   ├── sub-3108_ses-1_run-02_dwi.bvec
│   │   │   ├── sub-3108_ses-1_run-02_dwi.json
│   │   │   └── sub-3108_ses-1_run-02_dwi.nii.gz
│   │   └── sub-3108_ses-1_scans.tsv
│   └── ses-2
│       ├── anat
│       │   ├── sub-3108_ses-2_run-01_T1w.json
│       │   └── sub-3108_ses-2_run-01_T1w.nii.gz
│       ├── dwi
│       │   ├── sub-3108_ses-2_run-01_dwi.bval
│       │   ├── sub-3108_ses-2_run-01_dwi.bvec
│       │   ├── sub-3108_ses-2_run-01_dwi.json
│       │   ├── sub-3108_ses-2_run-01_dwi.nii.gz
│       │   ├── sub-3108_ses-2_run-02_dwi.bval
│       │   ├── sub-3108_ses-2_run-02_dwi.bvec
│       │   ├── sub-3108_ses-2_run-02_dwi.json
│       │   └── sub-3108_ses-2_run-02_dwi.nii.gz
│       └── sub-3108_ses-2_scans.tsv
├── sub-3352
│   └── ses-1
│       ├── anat
│       │   ├── sub-3352_ses-1_run-01_T1w.json
│       │   └── sub-3352_ses-1_run-01_T1w.nii.gz
│       └── sub-3352_ses-1_scans.tsv

```[rclone](https://rclone.org/) te permite montar tu dropbox, google drive, amazon S3 y servicios similares como una carpeta local en linux!

Todas las máquinas del cluster ya tienen instalado rclone. Para verificarlo, escribe `rclone` en la terminal y debería mostrar las instrucciones y opciones. Si no lo hace, entonces avisa.

En la [página de rclone](https://rclone.org/overview/) encontrarás instrucciones sobre cómo montar una gran variedad de servicios. Todos son similares, así que aquí pondremos el ejemplo de cómo configurar Dropbox y cómo montarlo. Asumimos, por supuesto, que ya tienes cuenta en dropbox.


# Configuración de rclone
1. Configuramos rclone
`rclone config`
2. Seleccionamos `New remote`. Lo bautizaremos como `dropbox` (ojo, sensible a mayúsculas/minúsculas, yo decidí en minúsculas).
3. Aparecerá la lista de servicios que rclone conoce. Selecciono el número que corresponde a dropbox.
4. Nos pregunta por `client_id`, y lo dejamos en blanco (presionamos Enter), y lo mismo para `client_secret`. Cuando nos pregunte si queremos entrar a advanced config le decimos que `n` (o sea _nel_, en español). 
5. Cuando pregunta si queremos `auto config` le decimos que `y`. 

6. Se abrirá nuestro navegador de internet de manera mágica, con una pantalla como:
![snapshot](https://github.com/c13inb/c13inb.github.io/blob/master/images/rclone_dropbox_config.png)

7. Finalmente le decimos que `y` a cuando nos pregunte si todo está bien.
8. Salimos de la configuración con `q`.


# Montar Dropbox mediante rclone
1. Designamos un lugar dónde montarlo y creamos el directorio, en caso necesario. En mi caso, montaré en `/misc/mansfield/lconcha/nobackup/mnt_dropbox`. Para facilitarme la vida, corro estos comandos:
```
dropbox_mount=/misc/mansfield/lconcha/nobackup/mnt_dropbox
mkdir $dropbox_mount
```
>  :warning: La carpeta está adentro de una carpeta llamada **`nobackup`**. Ya sabes por qué, verdad? Si no sabes, consulta la entrada de [[Clúster]]
>  :warning: Si alguna vez lconcha se encuentra una carpeta de éstas montada en algún lugar _respaldable_ habrá [consecuencias graves](https://media.giphy.com/media/ToMjGpIYtgvMP38WTFC/source.gif).


2. Monto Dropbox en `dropbox_mount`:
```
rclone mount dropbox: $dropbox_mount
```
 
Se tarda unos segundos, pero ahora ya podemos ver los archivos adentro de esa carpeta, utilizando la terminal o cualquier gestor de archivos. Nota que el comando se queda _colgado_, eso quiere decir que está montado dropbox. Si cancelas ese comando, se desmonta dropbox.

3. Desmontar es fácil. Simplemente tecleamos `Ctrl+c` en la terminal. Si alguna vez te da algún problema, la manera manual de desmontar es:
```
fusermount -u $dropbox_mount
```
# Rocket.chat

El rocket.chat de Red-Lanirem está en la siguiente dirección:
https://chat-lanirem.lavis.unam.mx

:rotating_light: **Ya tienes cuenta y no puedes entrar desde la app de tu teéfono?** :arrow_right: [Sigue este link.](https://hackmd.io/EUm9hfDcRYecYU_Uov5lNA?view)

## Crear nueva cuenta
Si es la primera vez que nos visitas, crea una nueva cuenta (*Register a new account*):
![](https://i.imgur.com/uZSTKML.png)


Lo más recomendable es instalar las aplicaciones oficiales de rocket.chat, disponibles para Windows, Mac, y Linux, así como para teléfonos iOS y Android, disponibles en el siguiente link:
https://rocket.chat/install/

Si no quieres instalar las aplicaciones, puedes usar rocket.chat directamente en tu navegador web con la URL arriba mencionada.


## Conceptos básicos
La comunicación en rocket.chat se da en *canales*. Los canales pueden ser privados o públicos; en el caso de los privados, deberás ser invitado por la persona que administra el canal. Todos los usuarios están inscritos en los canales #general y #journalclub. El resto de los canales pueden variar entre usuarios. Aquí un ejemplo:

![](https://i.imgur.com/REBLT7a.png)

:information_source: Para ver la lista de canales disponibles para tí, utiliza el ícono del mundo que está hasta arriba.

Para escribir, utiliza la caja hasta abajo de la página. En esa página puedes usar texto simple, o utilizar negritas, cursivas, emojis, y hasta código y fórmulas matemáticas. 

![](https://i.imgur.com/EFkbsem.png)

El botón de micrófono te permite enviar mensajes de voz. El botón `+` te permite anexar archivos. Puedes también escribir con [markdown](https://markdown.es/sintaxis-markdown/).



Los usuarios pueden ser *mencionados*, antecediendo su nombre con `@`. Esto permite que la persona mencionada reciba una notificación. El sistema es inteligente, y al escribir la @ y comenzar a escribir el nombre, aparecerán las opciones más cercanas. Los canales son ligados si se les menciona utilizando `#`. 

## Preferencias
Para personalizar tu experiencia en rocket.chat, da clic en tu avatar, en la esquina superior izquierda. Si no lo has cambiado, tu avatar es una letra de tu nombre, con un fondo colorido. Se abrirá un menú, y ve a `Mi Cuenta`. Esta comunidad es segura, así que en la pestaña `Perfil` dinos tu nombre completo, una biografía, tu apodo (si quieres), etc. En la pestaña `Preferencias` podrás cambiar el idioma del programa, y muchas otras cosas.

### Notificaciones
En la pestaña `Preferencias` encontrarás la sección de `Notificaciones`. Si instalaste la aplicación en tu teléfono, puedes controlar las notificaciones *push*. La opción *Todos los mensajes* es el default, pero puedes cambiar a *menciones*, y solo recibirás notificaciones si fuiste mencionada/o. Sería triste que lo hicieras, pero puedes elegir *Nada*. 

Si no usas la aplicación móvil pero no quieres estar fuera de la jugada, puedes usar el correo electrónico como sistema de notificaciones, en las opciones *Notificaciones por correo electrónico fuera de línea*. Igual, puedes elegir todo, menciones, o nada (:cry:).

### Destacados
Si tienes un especial interés en palabras clave, puedes ponerlas aquí. Si esas palabras son usadas en cualquier canal en el que estés, recibirás una notificación. Ejemplos de palabras clave son *cancelado, descompuesto, publicado, fiesta*, etc.


Disfruta de chat-lanirem con rocket.chat!---
title: Singularity
author: Luis Concha
title-slide-attributes:
    data-background-image: logo.png
    data-background-size: contain

---

# Qué es Singularity
- Comprime software en un solo archivo
- El archivo (contenedor) tiene TODO el sistema operativo que soporta al software.
- Incluye todas las librerías.
- Aumenta la reproducibilidad

------------------

## Ventajas
- Permite correr software no instalado en máquina huésped.
- No se requiere ser super usuario en máquina huésped
- Fácil: No se requiere ser super-usuario para correr un contenedor.
- Seguro: Es imposible escalar privilegios del contenedor al huésped).


# Instalación
- No usar `apt`, pues instalará versión vieja.
- Seguir pasos de [instalación](https://sylabs.io/guides/3.6/user-guide/quick_start.html#quick-installation-steps).
- No es difícil.



# Contenedores pre-fabricados
- búsqueda de contenedores:

```
(base) lconcha@syphon:~/singularity$ singularity search dmri
No users found for 'dmri'

No collections found for 'dmri'

Found 1 containers for 'dmri'
	library://guillaumeth/default/dmriqc
		Tags: latest
```
- También se pueden buscar contenedores en [singularity-hub](https://singularity-hub.org/search)
- Y otra manera más es convertir contenedores de `docker` a `singularity`.

------------------

## Generar un contenedor que encontramos

```
singularity build mycontainer_dmriqc.sif library://guillaumeth/default/dmriqc
```
- Los archivos de los contenedores pueden ser de varios GB.

:warning: `build` y `pull` hacen aproximadamente lo mismo, pero `pull` pone el contenedor en el _cache_ (habitualmente en `$HOME/.singularity/cache`), mientras que `build` nos deja generar un archivo `.sif`.
- Esto es relevante en el clúster, donde nuestro `$HOME` no tiene mucho espacio.
- Hacer archivos `.sif` aumenta la reproducibilidad.
- Podemos convertir a `.sif` un container que estaba en el _cache_ usando `build`.

------------------

## Generando un container desde cero
- Hay que tener un archivo de definición `.def`, que contiene la _receta_ a seguir para generar un contenedor. Ahí se pone lo que vamos a instalar y toda la configuración.
- Un archivo ejemplo muy simple, llamado `my_ubuntu.def`:

```
Bootstrap: library
From: ubuntu:20.04
```

- Lo llamaríamos armar así:

```
sudo singularity build my_ubuntu.sif my_ubuntu.def
```

------------------

- Al archivo `.def` se le pueden poner muchas cosas y configuraciones, que vienen explicadas [aquí](https://sylabs.io/guides/3.5/user-guide/definition_files.html).
- Podemos usar `build` con `--sandbox` para ir instalando poco a poco los componentes. Una vez generado el `.sif`, podemos entrar a él con `sudo singularity shell --writable my_ubuntu.def`, y podemos ir poniéndole cosas.
- Esto es útil cuando vamos generando nuestro archivo de definición `.def`


# Corriendo el contenedor
- La mayoría de los contenedores tienen un `%runscript`, que se ejecuta automáticamente al correr el contenedor.
- El `%runscript` puede ser complejo y recibir muchos argumentos y switches, como pasa con el contenedor de `fmriprep`

------------------

- ... pero también puede ser algo tan sencillo como _corre el comando que te pidan_. Esto se logra con un `%runscript` muy simple: `exec "$@"`
- Algo muy padre con un runscript sencillo es que podemos usar comandos de dentro del contenedor, para hacerle cosas a nuestros datos de _fuera_  del contenedor. Para ello, sin embargo es *crucial* hacer un `bind` de la carpeta de _fuera_ del contenedor, para que se vea _adentro_ . Es fácil. Por ejemplo, en un contenedor que incluye a mrtrix, usaremos el comando `mrstats` del contenedor para trabajar en un archivo de _fuera_ del contenedor:

```
singularity run -B /mnt test.sif mrstats /mnt/part1/data/datos_Circe/sub-36/anat/sub-36_T1w.nii.gz
```
En este ejemplo tenemos un archivo en una subcarpeta dentro de `/mnt` en la máquina host, pero lo hacemos visible dentro del contenedor `test.sif` mediante el switch `-B /mnt`.
# Usar `ssh-keygen` para no tener que escribir passwords


Cuando te conectas a una PC mediante ssh, te pide un password. Lógico. Pero cuando te conectas a la misma PC a cada rato, escribir passwords se vuelve tedioso. No habrá una manera de que la máquina destino ya te conozca y no te ande preguntando quién eres a cada rato? 

Claro que hay manera! y se llama `ssh-keygen`. Puedes consultar la documentación completa en la [página oficial](https://www.ssh.com/academy/ssh/keygen). Pero por lo pronto, veamos lo más básico.


Para este tutorial, usaremos una computadora `origen` que es donde estamos trabajando, y una `destino` que es a la que queremos conectarnos. La PC `destino` puede estar dentro del cluster, o ser cualquier computadora del mundo a la que tenemos accesso mediante ssh. Si trabajas en la NASA y tienes acceso, bien por tí.

## Generar la llave
Esta llave se guardará en tu home, y será usada para "abrir la puerta" de la computadora destino. En la computadora `origen` usamos:

    ssh-keygen

Te preguntará dónde quieres grabarla, siendo el default to home. Sugiero que no le muevas. Te pedirá también un _passphrase_ opcional. Puedes escribirlo si quieres, pero no vayas a olvidarlo!


## Copiar la llave al destino
Ahora que ya tenemos cómo identificarnos, enviaremos nuestra llave personal a la PC `destino`, y nos pedirá nuestra contraseña por última vez para verificar que somos quienes decimos ser. La próxima vez que queremos entrar a `destino`, esa PC revisará primero las llaves que ya tiene, y si coincide con el usuario y PC `origen`, dejará entrar sin más preguntas. Yeah!  Copiemos nuestra llave con el comando:

    ssh-copy-id usuario@destino

Donde `usuario` es el nombre de usuario que tengamos en la PC `destino`. (más info sobre este comando [aquí](https://www.ssh.com/academy/ssh/copy-id#:~:text=ssh%2Dcopy%2Did%20installs%20an,tool%20is%20part%20of%20OpenSSH.))

Y listo! La próxima vez que hagamos `ssh usuario@destino` entraremos sin más ni más!

:warning: OBVIO: NO COMPARTAS TU LLAVE.


# Trabajando remotamente


A veces, estando en tu casa, en el café, o en cualquier parte del mundo, necesitarás tus datos que están en las computadoras del cluster. Otras ocasiones querrás dejar corriendo trabajos en el cluster desde tu sofá. Otras, querrás revisar el resultado de tus scripts en tu laptop. O quizás los de la entrada del Campus no te dejaron entrar en vacaciones porque estaban de mal humor. En cualquier caso, tienes varias opciones para acceder al cluster desde cualquier parte del mundo.

>  :warning: Solo UNA computadora de todo el cluster es accesible desde fuera del INB, y es `penfield.inb.unam.mx`. Una vez que llegues a `penfield` podrás brincarte a cualquier otra computadora del cluster, y ver el contendido de tu `home` y de `/misc`.

# Quiero un artículo que no puedo acceder en casa
Lo mejor es hacer un túnel ssh al laboratorio, y usar tu navegador local para ir al artículo
Primero hacemos el túnel:
```
ssh -ND 8080 USER@penfield.inb.unam.mx
```
Te pedirá tu password de las computadoras del laboratorio. Luego vamos a otra terminal y abrimos un navegador web:
```
chromium-browser --proxy-server="socks5://localhost:8080"
```
Esto se puede hacer igualito usando `google-chrome`. ~Y sé que se puede hacer con firefox, usando la extensión `foxyproxy`. Búscala y si aprendes a hacerlo, edita esta página.~

Para firefox, podemos utilizar la extensión [multi-account-containers](https://addons.mozilla.org/es/firefox/addon/multi-account-containers/), con la ventaja de que podemos crear diferentes entornos para cada pestaña. 
Abrimos la extensión y hacemos click en administrar contenedores; creamos uno nuevo _ex-profeso_ para todas nuestras necesidades remotas, personalizamos nuestro contenedor al gusto y en "configuración avanzada del proxy" escribimos "socks://localhost:8080". Le damos aplicar y ¡listo!
[Más info](https://mzl.la/3Vdm23t)


# Quiero acceder gráficamente, con un entorno de escritorio
Excelente, es una experiencia muy agradable tener una "computadora dentro de una computadora". Por favor sigue el tutorial de [x2go](./X2Go).


# Quiero una terminal nada más
Minimalista, eh? Bien, utiliza [ssh](./SSh).


# Yo solo quiero copiar mis archivos desde el cluster a mi laptop
Para ésto puedes usar dos opciones:

## scp
`scp` significa *secure copy*, y su funcionamiento es análogo al clásico `cp` (copy, [ver manual](https://linux.die.net/man/1/cp)). El manual completo de `scp` está [acá](https://linux.die.net/man/1/scp), pero es muy fácil: su sintaxis es `scp ORIGEN DESTINO`, pero en este caso, tanto `ORIGEN` como `DESTINO` son una ruta completa ya sea local, o remota. En el caso de carpetas remotas, se especifica el `usuario` que accede a una `máquina`, y la `ruta` del o los archivos a copiar. Por ejemplo, desde una laptop fuera del INB:

```bash
scp lconcha@penfield.inb.unam.mx:/misc/mansfield/lconcha/misResultados/final.txt /home/lconcha/Desktop/
```

En este ejemplo, estoy copiando (usuario `lconcha`) el archivo `final.txt`, que está en una ruta dentro de `/misc`, que es visible por la computadora `penfield.inb.unam.mx`, y lo voy a poner en mi laptop, en el `Desktop`. Si hubiera querido copiar toda la carpeta, igual que con `cp`, debería utilizar el switch `-r` (recursive).

## rsync
La principal desventaja de `scp` es que le gusta copiar todo, y si algo falla, tienes que volver a empezar. Esto es muy frustrante con carpetas grandes. Pero la herramienta `rsync` te permite continuar una descarga en donde te quedaste. Su uso básico es igual a scp, mediante `rsync ORIGEN DESTINO`. Es habitual utilizar los switches `-avzh` (archivo, verbose, comprimido y modo humano, respectivamente). Tomando el ejemplo anterior:

```bash
rsync -avzh lconcha@penfield.inb.unam.mx:/misc/mansfield/lconcha/misResultados/final.txt /home/lconcha/Desktop/
```
Hay un tutorial muy bueno de `rsync` [aquí](https://www.tecmint.com/rsync-local-remote-file-synchronization-commands/).

Un truco muy bonito es generar un [alias](https://blog.desdelinux.net/creando-alias-en-gnulinux/) con todas las mejores opciones de `rsync` en un comando facilito de usar. Por ejemplo podemos hacer el alias del comando `scpresume`, para llamar a `rsync` con mil opciones, y usarlo cómodamente como si fuera un `scp`:

```bash
alias scpresume='rsync -avz --partial --progress --rsh=ssh'
scpresume lconcha@penfield.inb.unam.mx:/misc/mansfield/lconcha/misResultados /home/lconcha/Desktop/
```
Este último ejemplo copiaría toda la carpeta misResultados dentro de Desktop en la laptop, y si algo fallara, lo puedo volver a correr, y continuará donde se quedó.


# Me gustaría ver la carpeta remota como si fuera local
Elegante! Es una manera muy cómoda para, por ejemplo, utilizar `mrview` en tu laptop para ver un archivo que está en el cluster, sin tener que copiarlo! (Considera que cada vez que lo vas a visualizar, el archivo viajará por internet, por lo que archivos demasiado grandes sí tardarán en abrir).

Primero, en tu laptop debes instalar `sshfs` (ssh file system). En ubuntu es muy fácil:
```bash
sudo apt install sshfs
```

Si no estás en ubuntu, chécate este [tutorial](https://www.digitalocean.com/community/tutorials/how-to-use-sshfs-to-mount-remote-file-systems-over-ssh) para otras instalaciones.

Ahora vamos a *montar*  la ruta remota en una carpeta local. La carpeta local debe existir y debemos tener permisos de escritura. Por ejemplo, voy a crear la carpeta local dentro de mi `home` de mi laptop, y voy a montar `/misc` ahí:

```bash
mkdir /home/lconcha/misc
sshfs lconcha@penfield.inb.unam.mx:/misc /home/lconcha/misc
```
Se ve en la sintaxis que funciona como los ejemplos anteriores, donde mencionamos el usuario, la computadora y la ruta (remotos) que queremos montar (local). Como `sshfs` depende de `ssh`, me pedirá mi password del cluster. Ahora, si yo hago `ls /home/lconcha/misc`, veré las mismas carpetas que si yo hiciera `ls /misc` en una computadora del cluster. Incluso podría ver una imagen, tipo `mrview /home/lconcha/misc/mansfield/imagen.mif`.
