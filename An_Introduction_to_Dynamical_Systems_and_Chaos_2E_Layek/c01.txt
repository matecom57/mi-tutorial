I am motivated to bring out the second edition of the book because of positive feedback received from students, research scholars, and teachers. 
With the advancement of current knowledge and interest of the subject, I focus on reﬁnements and ﬁnetuning of the whole material keeping intact 
the basic structure of the book. In response to researchers’ demand, I have included some new topics with physical problems in this edition. The 
codimension two bifurcations, viz. Bogdanov–Takens, NeimarkSacker with physical examples and center manifold reduction, are discussed in Chaps. 6 
and 10. Symmetry is an intrinsic property in many physical phenomena. The Lie symmetry transformations are discussed relating to differential 
equations thoroughly. The ﬂuid dynamical ﬂow problems, viz. laminar ﬂow of power-law ﬂuid over a plate and logarithmic velocity near a wall in 
turbulence zone, are analyzed through Lie symmetry approach in Chap. 8. The circle homeomorphism and rotation numbers are included in Chap. 11. The 
quasiperiodic motions, mode-locking phenomenon, period-bubbling process, Shil’nikov chaos are explained at length in Chap. 12. The organized 
structures in bi-parameter plane for transitional and chaotic regimes are new active research interest and explored thoroughly. The predatorprey 
interacting models with hunting cooperation among predators are interesting and discussed dynamical behaviors in bi-parameter plane. The multiple 
routes to chaos are explained. The coexisting multiple attractors and hyperchaos in nonlinear systems are included in Chap. 12. The scalings of 
chaotic orbits are connected with fractals cascades and are shown in many physical systems in Chap. 13. The idea of multifractals and the global 
spectrum for quantifying inhomogeneous chaotic attractors are discussed extensively in this chapter.

The second edition is systematically designed from order to chaos and fractal connections with chaotic attractors in dissipative nonlinear systems. 
I am sure that students, research scholars, and young teachers would be inspired to explore the chaos theory, chaotic attractors, and their 
fractals connections.

I express my sincere thanks to my two research scholars Purbasha Deb and Abir Baidya for their cooperation for bringing out this second edition. I 
give special thanks to Dr. N. C. Pati for drawing some ﬁgures in bi-parameter plane. I express my sincere thanks to Prof. Sergey Kryzhevich, an 
active researcher in nonlinear dynamics and chaos theory of Gda´nsk University of Technology, Poland, for his interest and encouragement. I must 
give my thanks to Mr. Shamim Ahmad, Executive Editor, Science Books, Springer Nature India, Mr. Prasanth Anandan, Umamagesh Perumal and other staff 
members for their patience when I requested them again and again for the extension date of ﬁnal submission of the manuscript.

Last but not least, I thank my daughter and son Soumita, Soumyadeep, and wife Atasi Layek for their interest in bringing out the second edition of 
the book.

Chapter 1

Continuous Dynamical Systems

Dynamics is a time-evolutionary process. It may be deterministic or stochastic. Longterm predictions of some systems often become impossible. Even 
their trajectories cannot be represented by usual geometry. In many natural and social phenomena there is unpredictability. Unpredictability is an 
intrinsic property which is present in the phenomenon itself. It has a great impact on human civilization as well as scientiﬁc thoughts. There are 
numerous questions in human mind; e.g., how can a deterministic trajectory be unpredictable? What are the causes in the formation of symmetric 
crystals and snowﬂakes in nature? How can one ﬁnd chaotic trajectories? Can a deterministic trajectory be random? How can one deﬁne and explain 
turbulence in ﬂuid motion? Is there any local symmetry in chaos? How can one relate chaotic dynamics with fractal object? For answering these 
questions, we have no way but to study nonlinear dynamics.

Dynamical systems are generally described by differential or difference equations. Studies of differential equations in mathematics were devoted 
mainly of ﬁnding analytical solutions of equations for more than two centuries. But the dynamical behaviors of a system may not always be 
determined by analytical or closed-form solutions. Moreover, analytical solutions of nonlinear equations are difﬁcult to obtain except in a few 
special cases. The subject dynamical systems had evolved at the end of nineteenth century and made signiﬁcant contributions to understanding some 
nonlinear phenomena. The dynamics of a system may be expressed either as a continuous-time or as a discrete-time-evolutionary process. The simplest 
mathematical models of continuous systems are those consisting of ﬁrst-order differential equations. In ﬁrst-order autonomous system (explicit in 
time), the dynamics is a very restrictive class of system since its motion is in the real line. In simple nonautonomous cases, on the other hand, 
the dynamics is very rich.

Nonlinear science and its dynamics have been a matter of great importance in the ﬁeld of natural and social sciences. Examples include physical 
science (e.g., earth’s atmosphere, laser, electronic circuit, superconductivity, ﬂuid turbulence, etc.), chemistry (Belousov–Zhabotinsky reaction, 
Brusselator model, etc.), biology (neural

and cardiac systems, biochemical processes), ecology and social sciences (spreading of fading, spreading diseases, price ﬂuctuations of markets 
and stock markets, etc.), to mention a few. Nonlinear systems are harder (if not sometimes impossible) to solve than linear systems, because the 
latter follow the superposition principle and can be divided into parts. Each part can be solved individually and adding them all provides the 
ﬁnal result. However, solutions of linear systems are helpful for the analysis of nonlinear systems.

In this chapter we discuss some important deﬁnitions, concept of ﬂows, their properties, examples, and analysis of one-dimensional ﬂows for an 
easy way to understand the nonlinear dynamical systems.

1.1 Dynamics: A Brief History

The explicit time behaviors of a system and its dependency on initial conditions of solutions began after the 1880s. It is well known that 
analytical or closed-form solutions of nonlinear equations cannot be obtained except for very few special forms. Moreover, the solutions behaviors 
at different initial conditions or their asymptotic characters are sometimes cumbersome to determine from closed-form solutions. In this situation 
scientists felt the necessity for developing a method that determines the qualitative features of a system rather than the quantitative analysis. 
The French mathematician Henri Poincaré (1854–1912) pioneered the qualitative approach, a combination of analysis and geometry which was proved to 
be a powerful approach for analyzing behaviors of a system and brought Poincaré recognition as the ‘father of nonlinear dynamics’. The 
time-evolutionary process governed either by linear or nonlinear equations gives the dynamical system. Dynamics and its representations are 
inextricably tied with mathematics. The subject was initiated informally from the different views of mathematicians and physicists. Studies began 
in the mid1600s when Newton (1643–1727) invented calculus, differential equations, the laws of motion, and universal gravitation. With the help of 
Newton’s discoveries, the laws of planetary motions, already postulated by Jonaesh Kepler, a German astrologist (1609, 1619) were established 
mathematically and the study of dynamical systems commenced. In the qualitative approach, the local, long-term, and asymptotic behaviors of an 
equation could be explained. Unfortunately, the qualitative study was restricted to mathematicians only. However, the power and necessity of the 
qualitative approach for analyzing the dynamical evolution of a system were subsequently enriched by A. M. Lyapunov (1857–1918), G. D. Birkhoff 
(1908–1944) and a group of mathematicians from the Russian schools, viz. A. A. Andronov, V. I. Arnold, and coworkers (1937, 1966, 1971, 1973).

In fact, Poincaré studied continuous systems in connection with an international competition held in honor of the 60th birthday of King Oscar II 
(1829–1907) of Sweden and Norway. Of the four questions announced in the competition, he opted for the stability of the solar system. He won the 
prize concluding that at least motions of the sun, earth, and moon were stable. But the published memoir differed signiﬁcantly

from the original due to an error. In the study of dynamics, he found it convenient to replace a continuous ﬂow of time with a discrete analogue. 
In Poincaré section orbits may be analyzed through the set of points at which they pierce a two-dimensional transverse surface. In celestial 
mechanics, Newton solved two-body problems: the motion of the earth around the sun. This is the famous inverse-square law: F (gravitational force) 
∝ (distance between two bodies) − 2 . Many great mathematicians and physicists tried to extend Newton’s analytical method to the three-body 
problem (sun, earth, and moon), but three or more than three-body problems were found to be remarkably difﬁcult for ﬁnding solutions. At this 
juncture the situation seemed completely hopeless. This means that instead of asking about the exact positions of the planets always, one may ask 
‘Is the solar system stable forever?’ Answering this question for qualitative behavior of the system Poincaré devised a new way of analysis which 
emphasized the qualitative approach. This eventually gave birth to the subject of ‘Dynamical Systems’. The Russian Schools, viz. 
Mandelstam-Andronov School, contributed immensely to the mathematical theories for dynamical systems in the second half of the 1920s and in the 
1930s. In the dynamic evolution stability of a system is an important property. The Russian academician A. M. Lyapunov made a signiﬁcant 
contribution to the stability/instability of a system. The mathematical deﬁnition of stability, construction of Lyapunov function, and Lyapunov 
theorem are extensively used for analyzing the stability of a particular class of systems. The Lyapunov exponent assuming the exponential 
growth/decay with time of nearby orbits in statistical sense is applied for quantifying in chaotic motions. Also, Poincaré conceived the idea that 
certain family of orbits lying on curves intersect inﬁnitely many times in the neighborhood of a point which instigates sensitivity with respect 
to small changes in initial conditions of the system.

One of the most remarkable breakthroughs in the early nineteenth century was the discovery of solitary waves in a shallow water. Solitary waves are 
disturbances occurring on the surface of a ﬂuid. They are dispersive in nature and form a single hump above the surface by displacing an equal 
amount of ﬂuid, creating a bore at the place. Furthermore, these waves spread while propagating without changing their shape and velocity. The 
speed of these waves is proportional to depth of the ﬂuid that causes large amplitude of the wave. Consequently, the speed of the wave increases 
with increase in the height of the wave. When a high amplitude solitary wave is formed behind a low amplitude wave, the former overtakes the latter 
keeping its shape unchanged with only a shift in position. This preservation of shape and velocity after collision suggests a particle-like 
character of these waves and therefore called as solitary wave or soliton, coined by Zabusky and Kruskal relevant with photon, proton, etc. John 
Scott Russel, the Scottish naval engineer ﬁrst observed solitary wave on the Edinburgh–Glasgow canal in 1834 and he called it the ‘great wave of 
translation’. Russel reported his observations to the British Association in 1844 as ‘Report on waves’. The mathematical form of these waves was 
given by Boussinesq in 1871 and subsequently by Lord Rayleigh in 1876. The equation for solitary wave was later derived by Korteweg and de Vries in 
1895 and was popularly

known as the KdV equation. This is a nonlinear equation with a balance between the nonlinear advection term and dispersion resulting in the 
propagation of solitary waves in an inviscid ﬂuid. However, the ﬂuid viscosity dampens the nonlinear KdV wave propagation in a viscous ﬂuid.

In the ﬁrst half of the twentieth century nonlinear dynamics was mainly concerned with nonlinear oscillations and their applications in physics, 
electrical circuits, mechanical engineering, and biological science. Oscillations occur widely in nature and are exploited in many manmade devices. 
Many great scientists, viz. van der Pol (1889–1959), Alfred-Marie Liénard (1869–1958), Georg Dufﬁng (1861–1944), John Edensor Littlewood 
(1885–1977), A. A. Andronov (1901–1952), M. L. Cartwright (1900–1998), N. Levinson (1912–1975), and others, made mathematical formulations and 
analyzed different aspects of nonlinear oscillations. Balthasar van der Pol had made signiﬁcant contributions to areas such as limit cycles 
(isolated closed trajectory but neighboring trajectories are not closed either as they spiral toward the closed trajectory or away from it, that 
is, cycles in limiting sense), relaxation oscillations (limiting cycles exhibit an extremely slow buildup followed by a sudden discharge, and then 
followed by another slow buildup and sudden discharge, and so on) of nonlinear electrical circuits, forced oscillators, hysteresis (sudden jump 
behavior which is completely different from original behavior) and bifurcation phenomena. The well-known van der Pol equation ﬁrst appeared in his 
paper entitled ‘On relaxation oscillations’ published in the Philosophical Magazine in the year 1926. The van der Pol oscillator in a triode 
circuit is a simple example of a system with a limit cycle. He and var der Mark used van der Pol nonlinear equation to describe the heartbeat and 
an electrical model of the heart. Limit cycles were found later in mechanical and biological systems. The existence of limit cycle, its uniqueness, 
and multiple limit cycles of a system are important scientiﬁcally and stable limit cycle exhibits self-sustained oscillations.

Species live in harmony in nature. The existence of one species depends on the other; otherwise, one of the species would become extinct. 
Coexistence and sometimes mutual exclusion occur in reality in which one of the species becomes extinct. Species may ﬁnd themselves in competition 
for limited resources, whether food or space. Mutualism is a mechanism where several species interact in a way that beneﬁts each others. A real 
ecosystem may have hundreds or thousands of interacting populations, with all sorts of direct and indirect interactions among them. Can such a 
system of interacting populations show stability, periodic cycles and chaos, and if so, under what circumstances? Alfred James Lotka (1880–1949), 
Vito Volterra (18601940), Ronald Fisher (1890–1962), Nicols Rashevsky (1899–1972), and many others had explored the area of mathematical biology. 
The interaction dynamics of species, its mathematical model, and their asymptotic behaviors are useful tools in population dynamics of interacting 
species. Interaction dynamics among species have a great impact on the ecology and environment. The two-species predator–prey model in which one 
species prey on another had been formulated by Lotka in 1910 and later by Volterra in 1926. This is known as the Lotka–Volterra model taking linear 
predator response function. In reality, the predator–prey populations rise and fall periodically and the maximum and minimum values (amplitudes) 
are relatively constant.

However, this is not true for the Lotka–Volterra model. Different initial conditions can have solutions with different amplitudes. So, this model 
is structurally unstable but it has profound historical importance. On the other hand, Holling and Tanner (1975) constructed a mathematical model 
for predator–prey populations whose solutions have the same amplitudes in the long time irrespective of the initial populations. Different types 
linear and nonlinear predator response functions, viz. Holling types I, II, III, and IV, are designed for satisfying various behaviors of predator 
and prey populations. The mathematical ecologist Robert May (1972) and many other scientists formulated several realistic population models that 
are useful in analyzing the population dynamics.

The perception of unpredictability in natural and social phenomena has a great impact on human thoughts and also in scientiﬁc evolutions. The 
conﬂict between determinism and freewill has been a long-standing continuing debate in philosophy. Nature is our great teacher. In the nineteenth 
century, the French engineer Joseph Fourier (1770–1830) wrote: ‘The study of Nature is the most productive source of mathematical discoveries. By 
offering a speciﬁc objective, it provides the advantage of excluding vague problems and unwieldy calculations. It is also a means to formulate 
mathematical analysis, and to isolate the most important aspects to know and to conserve. These fundamental elements are those which appear in all 
natural effects’. Models for physical phenomena are pitfalls and limitations. The true testament can be made through observations and so is the 
mother of invention.

Newtonian mechanics gives us a deterministic view of an object in which the future is determined by the laws of force and the initial conditions. 
There is no question of unpredictability or freewill in the Newtonian setup. In the beginning of the twentieth century experimental evidence, 
logical description, and also philosophical perception of physical phenomena, both microscopic and macroscopic, made a breakthrough in science as a 
whole. The perception of inﬁnity, how we approach the stage of inﬁnitum, was a matter of great concern in the scientiﬁc community of the 
twentieth century. In the macroscopic world, studies particularly in oscillations of electrical, mechanical, and biological systems and the 
emergence of statistical mechanics either in ﬂuid system or material body established the role and consequence of nonlinearity on their dynamics.

The existence of a chaotic orbit for a forced nonlinear van der Pol equation was proved mathematically by M. L. Cartwright, J. E. Littlewood about 
the 1950s. During this period, mathematician N. Levinson showed that a physical model had a family of solutions that are unpredictable in nature. 
On the other hand, the turbulence in ﬂuid ﬂows is an unsolved and challenging problem in classical mechanics even today. Turbulence problem is an 
interface between mathematics and physics. The Soviet academician A. N. Kolmogorov (1903–1987), the greatest probabilist of the twentieth century 
and his coworkers made seminal contributions to isotropic turbulence in ﬂuids, the famous Kolmogorov-5/3 law (K41 theory) in the statistical 
equilibrium range. Kolmogorov’s idea was based on the existence of statistical equilibrium in homogeneous isotropic ﬂuid turbulence, and turbulent 
ﬂow quantities maintained complete self-similarities. In turbulent motion large unstable eddies

form and decay spontaneously into smaller unstable eddies, so that the energyeddies cascade continues until the eddies reach a size so small that 
the cascade is damped effectively by ﬂuid viscosity. Further, the energy-eddies cascade known as the Richardson-Kolmogorov cascade proceed in a 
self-similar manner. Osborne Reynolds (1842–1912), Geoffrey Ingram Taylor (1886–1975), von Karman (18811963), and coworkers had made signiﬁcant 
contributions to the statistical description of turbulent motion. Yet, till today the nature of turbulent ﬂow and universal law remain elusive. 
The statistical formulation suffers from the ‘closure problem’ for ﬂuctuation components. Recent experimental and theoretical works on turbulence 
revealed the existence of different nonequilibrium dissipation laws in some turbulent ﬂows, contrary to Kolmogorov equilibrium dissipation law. 
Also, theoretical studies showed that there is some generality in turbulent dissipation relations and scaling laws stemming from dilation symmetry 
groups of turbulent model equations.

In nonlinear dynamics the well-known Kolmogorov–Arnold–Moser (KAM) theorem proves the existence of a positive measure set of quasiperiodic motions 
lying on invariant tori for Hamiltonian ﬂows that are sufﬁciently close to completely integrable systems. This is the condition of weak chaotic 
motion in conservative systems. In chemistry, oscillation in chemical reaction such as the Belousov–Zhabotinsky reaction provided a wonderful 
example of relaxation oscillation. The experiment was conducted by the Russian biochemist Boris Belousov around the 1950s. However, he could not 
publish his discovery as in those days it was believed that chemical reagents must go monotonically to equilibrium solution, with no oscillatory 
motion. Later, Zhabotinsky conﬁrmed Belousov’s results and brought this discovery to the notice of the scientiﬁc community at an international 
conference in Prague in the year 1968. For the progress of nonlinear science in the twentieth century both in theories and experiments such as 
hydrodynamic (water, helium, liquid mercury), electronic, biological (heart muscles), chemical, etc., scientists believed that simple looking 
systems can display highly complex seemingly random behavior. It was Henri Poincaré who ﬁrst reported the notion of sensitivity to initial 
conditions in his work. The quotation from his essay on Science and Method is relevant here: ‘It may happen that small differences in the initial 
produce very great ones in the ﬁnal phenomena. A small error in the former will produce an enormous error in the later prediction becomes 
impossible’. Perhaps the most intriguing characteristic of a chaotic system is the extreme sensitivity to initial conditions. Naturally, there is a 
need to develop the science of the unpredictable. The real breakthrough came from the computational result of a simple nonlinear system. In the 
year 1963, Edward Lorenz (1917–2008) published a paper entitled ‘Deterministic Non-periodic Flow’. In this paper he derived equations for thermal 
convection in a simpliﬁed model of atmospheric ﬂow and noticed a very strange thing that the solutions of the equations would be unpredictable 
and irregular despite being a deterministic system. The sensitive dependence of the evolution of a system for an inﬁnitesimal change of initial 
conditions is called the butterﬂy effects. Deterministic systems may exhibit a regular behavior for some values of their control parameters and 
irregular behavior for other values. Deterministic systems can give rise to motions that are essentially random and the long-term prediction is 
impossible. Another paper from the discrete system

‘Differential Dynamical Systems’ published by Stephen Smale proved mathematically the existence of chaotic solutions and gave a geometric 
description of the chaotic set, the cascading of Smale horseshoe map. Mathematicians/physicists such as Lev.D. Laudau (transition scenario: laminar 
ﬂow to turbulence), James Yorke (‘Period three implies chaos’), Robert May (mathematical biology), Enrico Fermi (ergodicity), Stanislaw Ulam (the 
growth of patterns in cellular automata, lattice dynamics), J. G. Senai (ergodic theory), Sharkovskii (ordering of inﬁnitely many periodic points 
of a map of a line into itself), Ruelle and Takens scenario (laminar to turbulence through quasiperiodic motions and ‘strange attractor’), A. 
Libchaber and J. Maurer (intermittency as a route to ﬂuid turbulence) and many others are the great contributors to the development of nonlinear 
science and chaos theory. In the mid-1970s, a remarkable discovery was made by Mitchell Feigenbaum: the universality feature in transitional route 
to chaos for quadratic unimodal maps undergoing period-doubling bifurcation cascading. It maintained the monotonic sequence of period-doubling 
bifurcations as Period-1 → Period-2 → Period-2 2 → · · · → Period-2 n → · · · → Period-inﬁnitum. The successive bifurcations occur faster 
and faster with increasing growth parameter. This monotonic sequence has an accumulation point 3.57 approximately, above which the formation of 
period-doubling cycles attain at critical boundary and chaos through inﬁnite number of period-doubling cascade comes into existence. Feigenbaum 
discovered the universal number 4.669201. On the other hand, there exists two parameters dependent and anti-monotonicity process where the creation 
and annihilation of periodic orbits occur attaining the same period in a reverse way. This results in creating of closed bubbles, known as periodic 
bubbles. The smaller and smaller bubbles are generated and sandwiched in the original ones. The cascade continued until chaos comes into existence. 
However, the convergence rate is slower than the period-doubling process.

The power of ﬂuctuations has got now recognition. The 2021 Nobel Prize in physics has been awarded to Syukuro Manabe, Klaus Hasselmann, and 
Giorgio Parisi for their contributions to our understanding of complex physical systems. The Nobel Committee gave one-half of the prize money to 
Syukuro Manabe and Klaus Hasselmann ‘for the physical modeling of earth’s climate, quantifying variability and reliably predicting global warming’ 
and the other half to Giorgio Parisi ‘for the discovering of the interplay of disorder and ﬂuctuations in physical systems from atomic to 
planetary scales’. The multiparameters dependent dynamics of nonlinear systems showed some novel dynamical features that cannot occur in 
single-parameter models. Several well-organized structures in chaotic regime, viz. the periodic Arnold tongue, devil’s staircase, shrimp structure, 
periodic structures with period-adding sequences, coexistence of multiple attractors, etc., have been observed in many systems. Specifically, the 
organized structures in bi-parameter plane for transitional and chaotic regimes are active research interest for exploring novel features in 
dynamics. The structures in chaotic motions have some special features like the scale invariance property and universality character which are 
essential properties for understanding the dynamics at all length scales. Further, in turbulent ﬂow the organized structure is developed. In the 
Kolmogorov equilibrium at inertial range the organized structure

‘the energy-eddies cascade’, known as Richardson-Kolmogorov cascade is developed at a sufﬁciently high Reynolds number for homogeneous isotropic 
turbulence. In this range the turbulent kinetic energy is cascaded down from the larger to the smaller scales.

The concept of fractal geometry or fractal objects is about 50 years old and was ﬁrst introduced by the Polish–French–American mathematician 
Benoit Mandelbrot (1924–2010) in 1975. Fractals are structures that are irregular, erratic, and self-similarity is intrinsic in most of these 
objects. Fractal objects consist of self-similarity between scales, that is, the patterns observed in larger scales repeat in ever decreasing 
smaller and smaller scales. In short, a fractal object is made up of parts similar to the whole in some way but lacks a characteristic smallest 
scale to measure. Fractal geometry is different from Euclidean geometry and ﬁnds order in chaotic shapes and processes. Chaotic orbit can be 
expressed in terms of fractal object. Scaling and self-similarity are important features in most natural and manmade fractal objects through 
scalings. The self-similarity and contractivity are two fundamental attributes in fractal geometry. There exist numerous examples of fractals in 
natural and physical sciences. One can also ﬁnd a number of examples of fractals in the human anatomy. For instance, lungs, heart, and many other 
anatomical structures are either fractal or fractal-like. Moreover, in recent years the idea of fractals is being exploited to ﬁnd applications in 
medical science to curb fatal diseases. Mandelbrot and other researchers have shown how fractals could be explored in different areas including 
chaos and turbulence. There is an underlying structure to chaotic orbits, and the connection between fractal and chaotic orbit is well-established 
now that help to measure the loss of information in random motion. The phenomenon of chaos is a realistic phenomenon and therefore one has to 
understand and realize chaos in usual incidents happening in our everyday life. The study of chaotic phenomena has begun in full length nowadays 
and is widely applied in different areas. The theory of chaos is now applied in computer security, digital watermarking, secure data aggregation, 
and video surveillance successfully. Thus, chaotic phenomena are not only destructive as in tsunami, tornado, etc., but can also be effectively 
utilized for the welfare of human beings. Chaos has been considered as the third greatest discovery, after relativity and quantum mechanics in the 
twentieth century science and philosophy. In the past 20 years scientists and technologists have been realizing the potential use of chaos in 
natural and technological sciences.

1.2 Dynamical Systems

Dynamics is primarily the study of the time-evolutionary process, and the corresponding system of equations is known as dynamical system. 
Generally, a system of n ﬁrst-order differential equations in the space R n is called a dynamical system of dimension n which determines the time 
behavior of evolutionary process. Evolutionary processes may possess the properties of determinacy/non-determinacy, ﬁnite/ inﬁnite 
dimensionality, and differentiability. A process is called deterministic if

its entire future course and its entire past are uniquely determined by its state at the present time. Otherwise, the process is called 
nondeterministic. However, the process may be semi-deterministic (determined, but not uniquely). In classical mechanics the motion of a system 
whose future and past are uniquely determined by the initial positions and the initial velocities is an example of a deterministic dynamical 
system. The evolutionary process may describe, viz. (i) a continuous-time process and (ii) a discrete-time process. The continuous-time process is 
represented by differential equations, whereas the discrete-time process is by difference equations (or maps). The continuous-time dynamical 
systems may be described mathematically as follows:

Let x = x (t) ∈ R n , t ∈ I ⊆ R be the vector representing the dynamics of a

∼ ∼ continuous system (continuous-time system). The mathematical representation of the system may be written as

d x ∼ = x = f (x , t), dt ∼ ∼ ∼

(1.1)

where f (x , t) is a sufﬁciently smooth function deﬁned on some subset U

⊂

R n × R.

∼

∼

Schematically, this can be shown as

Rn 

(state space)

× R

=

Rn + 1 

(space of motions)

.

(time)

The variable t is usually interpreted as time and the function f (x , t) is generally

∼

∼

nonlinear. The time interval may be ﬁnite, semi-ﬁnite, or inﬁnite. The function f (x , t)

∼

∼

may involve with parameters and the system is∼ x˙ = f (x , c , t),

c

∼

∈ R m . On the other

∼

∼ ∼

hand, the discrete system is related to a discrete map (given only at equally spaced points of time) such that from a point x 0 , one can obtain a 
point x 1 which in turn maps into x 2 , and so on. In other words, x n + 1 = g(x n ) = g(g(x n−1 )), etc. This is also written in the form x n + 1 
= g(x n ) = g 2 (x n−1 ) = · · · . The discrete system will be discussed in the later chapters.

If the right-hand side of Eq. (1.1) is explicitly time independent, then the system is called autonomous. The trajectories of such a system do not 
change in time. On the other hand, if the right-hand side of Eq. (1.1) has explicit dependence on time then the system is called nonautonomous. An 
n-dimensional nonautonomous system can be converted into autonomous form by introducing a new dependent variable xn + 1  such that x n + 1 = t. In 
general, the solution of Eq. (1.1) is difﬁcult or sometimes impossible to obtain when the function f (x , t) is nonlinear, except in some special

∼

∼

cases. Examples of autonomous and nonautonomous systems are given below.

(i) Autonomous systems

(a) ¨x + α x˙ + βx = 0, α, β > 0. This is a damped linear harmonic oscillator.

The parameters α and β are respectively, the strength of damping and the

strength of linear restoring force. For α = / 0 the system has a point attractor. It exhibits periodic motion for α = 0, the no damping case.

(b) ¨x + ω 2 sin x = 0, ω = √ g/L . g is the gravitational acceleration, and L is the string length. This is a simple undamped nonlinear 
oscillator (pendulum). It has interesting dynamics to be explored.

(c) . This is the well-known Lotka–Volterra simple y˙ = −γ y + δxy ) predator–prey model, where α, β, γ , δ are all positive constants. The terms 
βxy and δxy are interactions among preys and predators. This nonlinear system shows periodic cycle for speciﬁc ranges of parameter values.

x˙ = αx − βxy

(d) ¨x − μ(1 − x 2 )x˙ + β x = 0, μ > 0. This is the well-known van der Pol nonlinear oscillator, which gives unique stable limit cycle (regular 
attractor) surrounding the origin for small value of μ. This limiting periodic motion has a special physical signiﬁcance in diode electrical 
circuits. Physically, there is a balance among the source of energy, that is, a DC voltage, the source of dissipation, and the restraining forces 
for the existence of limit cycle. However, it exhibits the relaxation oscillator for large values of μ.

(ii) Nonautonomous systems

(a) ¨x + α x˙ + βx = f cos ωt, α, β > 0. This is an example of linear oscillator with external time-dependent force. The parameters f and ω are the 
amplitude and frequency of driving force, respectively.

(b) ¨x + α x˙ + ω 0 2 x + βx 3 = f cos ωt . This is a G. Dufﬁng nonlinear oscillator who studied it in 1930s. It has a cubic restoring force and 
harmonic forcing. The parameter α is the strength of damping, ω 0 the natural frequency and β is the strength of the nonlinear restoring force.

(c) ¨x − μ(1 − x 2 )x˙ + βx = f cos ωt, μ > 0. This is a van der Pol nonlinear forced oscillator exhibiting nonlinear oscillations. A linear 
oscillator shows multiples of base frequency representing multiplicative dynamics while this nonlinear oscillator with forced periodic driving 
exhibits submultiples of the base frequency ω 0 , that is, ω , ω , . . . , ω . In addition to 2 0 3 0 n0  mω0  subharmonics, higher harmonics of n 
(m, n = 1, 2, 3, ...) appear with increasing of periodic driving voltage. Subharmonics play a vital role in creating prechaotic vibrations. The 
subharmonic frequencies develop an irregular noise with frequency demultiplications. The noise occurs when the frequency jumps to the next lower 
frequency. This phenomenon is one of the ﬁrst evidence of chaos and implies that chaotic motion occurs in a system intrinsically. There are many 
stories and myths on nonlinear oscillations before 1960s when people did not believe the existence of chaotic motions and its several implications. 
Researchers ﬁnd how chaos theory could explore a new answer to Einstein’s famous question: ‘Does God play dice in nature?’ in case of macroscopic 
dynamics. Note that the famous ‘Japanese Attractor’ corresponding to Dufﬁng equation applicable to an electrical circuit with nonlinear inductor 
had not been recognized until

1978. It was discovered by Professor Yoshisake Ueda of Kyoto University. Instead of a closed Poincare‘ section, he obtained a ragged picture and 
called it a ‘shattered egg’. With the advancement of nonlinear dynamics and its mathematical theory the intermittent oscillations and chaotic noise 
are now recognized in engineering devices and physical processes. (d) ¨x − μ(1 − x 2 )x˙ + ω0 2 x + βx 3 = f cos ωt. This is a Dufﬁng-van der 
Pol nonlinear equation with a cubic nonlinearity and harmonic forcing. The system exhibits many interesting phenomena.

Some distinct properties of linear and nonlinear systems as follows:

(a) Superposition principle: This holds good for linear systems and solutions constitute a linear space. Consider a linear equation ¨x + x = 0, x 
≡ x(t). It has two linearly independent solutions, viz.sin(t) and cos(t). The general solution is expressed by x(t) = A cos(t) + B sin(t) which is 
a linear combination of two solutions and A, B are arbitrary constants. So, the linear differential operator L : C(R) → C(R), the collection of 
all real-valued continuous functions such d2  that Lx = 0, L = 1 holds the relation L(Ax 1 Bx 2 ) = AL x 1 BL x 2 for dt + + + two solutions. This 
is the linearity principle. Now, consider a nonlinear equation ¨x + x + εx 3 = 0. We examine now the principle of superposition as given by L(Ax 1 
+ Bx 2 ) = AL x 1 + BL x 2 + ε [ L(Ax 1 + Bx 2 ) 3 − (Ax 1 3 + Bx 2 3 ) ] implying that L(Ax 1 + Bx 2 ) = / AL x 1 + BL x 2 . The principle of 
superposition does not hold for nonlinear equations. The conclusion is that the notion of linearly independent solutions for nonlinear systems 
loses its meaning.

(b) Dependence on integration constants and /or initial conditions of nonlinear systems: The dependences of solution on the initial/integration 
constants are related generally in the form of their linear combinations for linear equation. This is not true for nonlinear systems in general. 
Consider a nonlinear equation, d x ¨x + x˙ 2 = 0 ⇒ dt (x ˙x) = 0 ⇒ x x˙ = A say. So, x dx = Adt ⇒ x 2 = 2At + 2B ⇒ x = ± √ 2At + 2B . The 
conclusion is that the dependence on the two integration constants A and B is connected nonlinearly. Again, we consider x˙ = f (x) = 1 + x 2 with 
x(0) = 0. f (x) is continuous in the real line, and so solution exists. The solution is given by x(t) = tan(t). However, the solutions are blown up 
inﬁnity at t = ± π/2. It indicates the fact that solutions are not always valid for all time even though the solution exists.

(c) Frequency multiplication-higher harmonics, subharmonics, sustained and relaxation oscillations, chaotic noise, etc.: Oscillation is an 
important phenomenon that exhibits in many physical processes. It revolutionized in 1920–1940 for discoveries of different electrical and 
electronic devices in particular the diode, triode, and transistors. The second- and higher-order systems exhibit oscillations. Linear oscillators 
are not structurally stable depending upon initial conditions and amplitude, and so engineers were tried to design nonlinear oscillators which are 
structurally stable, robust and the amplitude of oscillation at steady state is independent of initial conditions. The nonlinear equations have an 
intrinsic tendency to multiply frequencies resulting multiplicative dynamics and they may have a family of solutions. The multiples frequencies 
appear


depending on the nature of nonlinearity. Apart from these properties nonlinear systems exhibit bi-stability (two states), sustained oscillation, 
relaxation oscillation, hysteresis (a sudden jump phenomenon observed in many mechanical and electrical systems), coexistence of quasiperiodic 
motions and phase-locking, existence of unique or multiple limit cycles, coexistence of multiple attractors, creating noise, random and 
unpredictable dynamics. These are appeared intrinsically in nonlinear systems.

Some Examples of Dynamical Systems

(a) The most common example of a deterministic dynamical system is Newtonian systems governed by Newton’s law of motion. This law states that the 
acceleration of a particle is determined by the force per unit mass. The force can be a function of the velocity ( ˙x) and the position (x), and so 
the Newtonian systems take the form

m ¨x = F(x, ˙x), (m = mass, F = force).

(1.2)

Equation (1.2) may be written as a system of two ﬁrst-order differential equations

as

x˙ = y, and y˙ = F(x, y).

(1.3)

System (1.3) may be viewed as a dynamical system of dimension two in the xy-plane and the dynamics is a set of trajectories giving time evolution 
of motion.

(b) The simple exponential growth model for a single population is expressed mathematically as

dx = rx with x = x 0 at t = 0, dt

(1.4)

where r > 0 is the population growth parameter. The solution of (1.4) is x(t) = x 0 e rt . This solution expresses the simplest model for 
population growth with time in unrestricted resources and the population x(t) → ∞ as t → ∞ . Obviously, this model does not obey realistic 
population growth of any species.

The simple population growth model, considering effects like intraspecies competitions, depletion of resources with population growth, and sudden 
emergence of infectious disease is given as

dx = (r − bx)x dt

(1.5)

with the condition x = x 0 at t = 0. The solution of (1.5) is given as


x(t) = ( b ) . x 0 + ( b r − x 0 ) e−rt 

(1.6)

Clearly x → b r as t → ∞ for both the cases x 0 > b r and x 0 < b r . In this model a linear decrease growth with the population is considered.

This growth model is known as the logistic growth model of population. The graphical representation of the above solution is shown in Fig. 1.1.

This simple model shows that population x(t) is of constant growth rate after some time t.

(c) Populations of two competing species (predator and prey populations) could be modeled mathematically. The predator–prey populations model was 
ﬁrst formulated by Alfred J. Lotka (1880–1949) in the year 1910 and later by Vito Volterra (1860–1940) in the year 1926. This is known as 
Lotka–Volterra predator–prey model. The idea of constructing this model came from observing ﬁsh populations when ﬁshing was mostly suspended 
during the First World War. An Italian marine biologist Umberto D’Ancona noticed in the mid-1920s that the relative frequency of some ﬁsh species 
were increased and decreased in the relative frequency of other species by performing a statistical analysis. He posed the distinct patterns in 
ﬁsh populations to Luisa Volterra, an ecologist and then to Vito Volterra, a mathematician. As a result, the Lotka-Volterra model for predators 
and preys in ﬁsh populations was emerged. Here we demonstrate another two interacting populations viz., Fox and Rabbit populations. In the model 
the foxes prey on rabbits. The population density of rabbit affects the population density of fox, since the latter relies on the former for food. 
If the density of rabbit is high, the fox population decreases, while when the fox population increases, the rabbit population decreases. When the 
rabbit population falls, the fox population also falls. When the fox population drops, the rabbits can multiply again and so on. The growth or 
decrease of two populations could be analyzed using dynamical system principles. The dynamical equations for predator–prey model

are given as

x˙ = αx − β xy , y˙ = −γ y + δxy )

(1.7)

where x denotes the population density of the prey and y, the population density of the predator. The parameter α represents the growth rate of the 
prey in the absence of intersection with the predators whereas the parameter γ represents the death rate of the predators in the absence of 
interaction with the prey and β , δ are the interaction parameters and are all constants (for simple model). Using the dynamical principle one can 
obtain a necessary condition for coexistence of the two species. In this model the survival of the predators depends entirely on the population of 
the prey. If initially x = 0, then y˙ = −γ y, that is, y(t) = y(0)e −γ t and y(t) → 0 as t → ∞ , Arrowsmith and Place [1]. However, the 
Lotka-Volterra model is structurally unstable but it has historical interest.

In the development of mathematical biology, people begin to pay more attention for studying discrete predator–prey model. Sometimes it shows richer 
and more complex dynamics than the corresponding continuous model. The general discrete predator–prey interacting model is of the form in the (n + 
1)th generation, Ren et al. [2]

x(n + 1) = x(n) + rx(n)(1 − x(n)) − p 1 (x(n), y(n))y(n), y(n 1) = y(n) sy(n) p 2 (x(n), y(n))y(n). ( + + +

The term rx(n)(1 − x(n)) represents the logistic growth of prey population in the absence of predator and the parameter r is the intrinsic growth 
rate of prey. s represents the death rate or intrinsic growth rate of predator. Due to interdependency of two interacting populations, the model 
can be classiﬁed into the following types:

(i) General predator–prey model: In this model, the parameter s is considered the death rate of predator (s < 0), p 1 = p 2 > 0 is the predator 
response functions. The response functions are referred to the change in the density of prey population per unit time.

(ii) Leslie–Gower predator–prey model: Here s denotes the intrinsic growth rate of predator (s > 0), p 1 is predator response function, p 2 = 
−y/(γ x), y/(γ x) is called Leslie–Gower term in the model. So, for x = / 0, and y(n + 1) = y(n) + sy(n) [ 1 − sy(n)/((γ s)x(n)) ] .

Where (γ s) is a measure of food quantity of prey for conversion into predator growth depending on the density of the prey population. Notably, 
predator grows logistically with intrinsic growth rate s with carrying capacity proportional to the population size of prey.

Different types response functions are designed depending upon predator and prey populations and their interacting strategies. The Holling type-I 
response function is represented by p 1 (x, y) = m x . The linear function p 1 (x, y) is replaced by

(mx/(q + x)), which is Holling type-II functional response, that is, concave upward curve with saturation level, and the Holling type-III is p 1 
(x, y) = mx 2 /(x 2 + b 2 ), which is a sigmoid-shaped curve. The type-IV is represented by p 1 (x, y) = mx/(qx + ry + s), which is nonmonotonic 
curve with ﬁrst part increasing and the last part decreasing. Among these the Holling type-II is used widely. However, all response functions are 
involved various parameters and are required suitable values. These response functions are designed for representing different types of predator’s 
behavior and interacting capacity for preying. The complexity of interactions among populations shows that the functional responses depend not only 
on prey but also on predator. In the study of dragonﬂy, Crowley and Martin [3] showed that the feeding rates of the second-year class larvae are 
connected with their own density and also the density of their ﬁrst-year class conspeciﬁc prey, and the functional response is represented by

p 1 (x, y) = mx/ [ (1 + ax)(1 + bx) ] ,

where m, a, b > 0 represent the effects of capture rate, handling time, and the magnitude of interference among predators. In this model, the study 
shows that predator feeding rate decreases with higher predator density even when prey density is high. The intra-speciﬁc interference should 
generally increase in intensity with increasing population density. In spite of these effects there creates psychological stress on prey population 
due to the mere presence of predators. The predator has a twofold impact on prey population, viz. (i) the predators physically attack and kill 
their preys and thereby reduce their number, and (ii) they hold the power of putting the prey individuals in a state of psychological state. Also, 
there are various kinds cooperation hunting strategies among predators for capturing preys efﬁciently, different types of harvesting, viz. 
constant rate, linear, or proportional harvesting and nonlinear harvesting. The impacts on prey–predator models under direct and indirect effects 
will discuss in later chapters.

(d) Suppose we have an LCR circuit consisting of a resistor of resistance R, a capacitor of capacitance C, and an inductor of inductance L. In a 
simple electrical circuit, the values of R, C, and L are always nonnegative and are independent of time t. Kirchhoff’s current law (the sum of the 
currents ﬂowing into a node is equal to the sum of the currents ﬂowing out of it) is satisﬁed if we pass a current I to the closed loop as shown 
in Fig. 1.2.

According to Kirchhoff’s voltage law of the circuit (the sum of the potential differences around any closed loop in a circuit is zero), we have the 
equation

V 12 + V 23 + V 31 = 0.

(1.8)

Here V i j denotes the voltage difference between node i and node j.

From Ohm’s law, we get the relation

V 31 = IR.

(1.9)

Also, from the deﬁnition of capacitance C, we have

dV12  C = I. dt

(1.10)

Again, Faraday’s law of inductance gives

dI L =V23 . dt

(1.11)

Substituting (1.8) and (1.10) into (1.11) and writing V 12 = V , we get

dI R V =− I− . dt L L

(1.12)

From (1.10) and (1.12) we ﬁnally obtain

dV I dI R V = and = − I − . dt C dt L L

(1.13)

These equations represent a dynamical system of dimension two in the V −I plane. This is a simple linear model in LCR circuit. The linear models 
have undoubtedly had good success, but they also have limitations. Linear models can only produce persistent oscillations of a harmonic 
(trigonometric) type.

A circuit is called nonlinear when it contains at least one nonlinear circuit element like a nonlinear resistor, a nonlinear capacitor or a 
nonlinear inductor. Chua’s diode model system is a simple example of nonlinear electric circuit represented by x˙ = c 1 (y − x − f (x)), y˙ = c 2 
(x − y + z), z˙ = −c 3 y where f (x) = m 1 x + ((m 0 m 1 )/2)( | x + 1 | − | x − 1 | ) satisfying two parameters m 0 < −1 < m 1 . It 
represents three different voltage-current regimes in the diode circuit and is only nonlinear term in the equation. The function f (x) is piecewise 
linear and gives nonlinear effects in the circuit, see Lakshmanan and Rajasekar [4] for different nonlinear electrical

circuits. However, the function is not differentiable at x=-1 and x=1. The above Chua’s model equations exhibit double scroll chaos through 
period-doubling cascade.

1.3 Flows

The time-evolutionary process may be described as a ﬂow of a vector ﬁeld in R n . Solutions are curves in an open set U subset of R n which are 
tangent to this vector ﬁeld at each point. Generally, ﬂow is frequently used for discussing the dynamics as a whole rather than the evolution of 
a system at a particular point. The solution x (t) of a system x˙ = f (x ) which satisﬁes ∼ x (t 0 ) = x 0 gives the past (t < t 0 ) and

∼

∼

∼

∼

∼

future (t > t 0 ) evolutions of the system. Mathematically, the ﬂow is deﬁned by φ t (x ) : U → R n where φ t (x ) = φ(t, x ) is a smooth vector 
function of x ∈ U ⊆ Rn 

∼ ∼ ∼ ∼ and t ∈ I ⊆ R satisfying the equation

d φ t (x ) = f (φ t (x )) dt ∼ ∼ ∼

for all t such that the solution through x exists and φ(0, x ) = x . The ﬂow φ t (x )

∼

∼

∼

∼

satisﬁes the following properties:

(a) φ o = I d , (b) φ t + s = φ t ◦ φ s .

Some ﬂows may also satisfy the property

φ(t + s, x ) = φ(t, φ(s, x )) = φ(s, φ(t, x )) = φ(s + t, x ). ∼ ∼ ∼ ∼

Flows in R : Consider a one-dimensional autonomous system represented by x˙ = f (x), x ∈ R. We can imagine that a ﬂuid is ﬂowing along the real 
line with local velocity f (x). This imaginary ﬂuid is called the phase ﬂuid, and the real line is called the phase line. It speciﬁes the state 
of the system as time goes on. For solution of the system x˙ = f (x) starting from an arbitrary initial position x 0 , we place an imaginary 
particle, called a phase point, at x 0 and watch how it moves along with the ﬂow in phase line in varying time t. As time goes on, the phase point 
(x, t) in the one-dimensional system x˙ = f (x) with x(0) = x 0 moves along the x-axis according to some function φ(t, x 0 ). The function φ(t, x 0 
) is called the trajectory for a given initial state x 0 , and the set { φ(t, x 0 ) | t ∈ I ⊆ R } is the orbit of x 0 ∈ R. The set of all 
qualitative trajectories of the system is called phase portrait.

2 Flows in R : Consider a two-dimensional system represented by the following equations x˙ = f (x, y), y˙ = g(x, y), (x, y) ∈ R 2 . An imaginary 
ﬂuid particle ﬂows in the plane R 2 , known as phase plane of the system. The succession of states given parametrically by x = x(t), y = y(t) 
trace out a curve through some initial

point P(x(t 0 ), y(t 0 )) is called a phase path. The set { φ(t, x

orbit of

x

∼

0

∈ I ⊆ R } is the in R 2 There are an inﬁnite number of trajectories that would ﬁll the

0

) | t

∼

.

phase plane when they are plotted. But the qualitative behavior can be determined by plotting a few trajectories with different initial conditions. 
The phase portrait displays how the qualitative behavior of a system is changing as x and y vary with time t. An orbit is called periodic if x(t + 
p) = x(t) for some p > 0, for all t. The smallest integer p for which the relation is satisﬁed is called the prime period of the orbit. Flows in R 
cannot have oscillatory or closed path.

Flows in R n : Let us now deﬁne an autonomous system representing n ordinary differential equations as

x˙ 1 = f 1 (x 1 , x 2 , . . . , x n ) ⎪ ⎪ ⎫ ⎪ x˙ 2 = f 2 (x 1 , x 2 , . . . , x n ) . . ⎪ ⎬ . ⎪ ⎪ x˙ n = f n (x 1 , x 2 , . . . , x n ) ⎭

which can also be written in symbolic notation as x˙

= f (x ), where x = ∼ ∼ ∼ (x 1 x 2 . . . , x n and f = ( f 1 f 2 , . . . , f n ). The solution of this system with the

∼

,

,

)

,

∼

initial condition

x

∼

(0) =

x

∼

0

can be thought as a continuous curve in the phase space

R n parameterized by time t ∈ I ⊆ R. So the set of all states of the evolutionary process is represented by an n-valued vector ﬁeld in R n . The 
solutions of the system with different initial conditions describe a family of phase curves in the phase space, called the phase portrait of the 
system. The vector ﬁeld f (x ) is everywhere tangent

∼

∼

to these curves, and their orientation is directed by the direction of the tangent vector of f (x ).

∼

∼

A family of maps φ t : X → X for t ≥ 0 such that φ 0 = I d and φ t + s = φ t ◦ φ s for every t, s ≥ 0 is called a semi-ﬂow. On the other hand, 
a family of maps φ t : X → X for t ∈ R such that φ 0 = I d and φ t + s = φ t ◦ φ s for every t, s ∈ R is called a ﬂow.

Also, we say that a family of maps φ t represents a dynamical system if it is a ﬂow or semi-ﬂow. Note that if a family of maps generates a ﬂow, 
then

φ t ◦ φ −t = φ −t ◦ φ t and φ 0 = I d so that each map φ t is invertible and its inverse is given by φ t −1 = φ −t .

For example, any movement by translation is a ﬂow with constant velocity. It is expressed as φ t : R n → R n such that φ t (x) = x + ty, t ∈ 
R,x, y ∈ R n , that is, a ﬂow generated by translation with constant velocity. Now, φ 0 = I d and φ t + s (x) = x + (t + s)y = (x + sy) + ty = φ 
t ◦ φ s (x) . Hence, the family of maps φ t generates a ﬂow.

1.4 Evolution

Consider a system x˙ = f (x ), x ∈ R n with initial conditions x (t 0 ) = x

∼

∼

∼

∼

∼

∼

0

. Let

E ⊂ R n be an open set and f ∈ C 1 (E). For x 0 ∈ E, let φ(t, x 0 ∼ ∼ ∼ the above system on the maximum interval of existence I (x 0 ) ⊂

) be a solution of

R. The mapping φ t : R n → R n deﬁned by φ t (x 0 ) = φ(t, x 0 ) is known as evolution operator of

∼

∼

∼

the system. The linear ﬂow for the system x˙ = A x with ∼ x (t 0 ) = x

∼

∼

∼

0

, is deﬁned by

φ t : R n → R n and φ t = e At , the exponential matrix. The mappings φ t for both linear and nonlinear systems satisfy the following properties:

(i) φ 0 (x ) = x . ∼ ∼ (ii) φ s (φ t (x )) = φ s + t (x ), ∀s, t ∈ R. ∼ ∼ (iii) φ t (φ −t (x )) = φ −t (φ t (x )) = x , ∀t ∈ R. ∼ ∼ ∼

In general, a dynamical system may be viewed as group of nonlinear / linear operators evolving as { φ t (x ), t ∈ R, x ∈ R n } . The following 
dynamical group properties ∼ ∼ hold good:

(i) φ t φ s ∈ { φ t (x ), t ∈ R, x ∈ R n } (closure property). ∼ ∼

(ii) φ t (φ s φ r ) = (φ t φ s )φ r (associative property).

(iii) φ 0 (x ) = x , φ 0 being the identity operator. ∼ ∼

(iv) φ t φ −t = φ −t φ t = φ 0 , where φ −t is the inverse of φ t .

For some cases the ﬂow satisﬁes the commutative property φ t φ s = φ s φ t .

1.5 Fixed Points of a System

The notion of a ﬁxed point is important in analyzing the local and global behaviors of a system. The ﬁxed point is nothing but a constant or 
equilibrium or invariant solution of a system. A point is a ﬁxed point of the ﬂow generated by an autonomous system∼ x˙ = f (x ), x ∈ R n if 
and only if the ﬂow satisﬁes φ(t, x ) = x for all t ∈ R.

∼ d

∼

∼

∼

∼

φ(t, x) = x = 0 ⇒ f (x ) = 0 for ﬁxed points. For nonautonomous ∼ ∼ ∼ ∼ systems ﬁxed point can be deﬁned for a ﬁxed time interval. A ﬁxed 
point is also known as a critical point or an equilibrium point or a stationary point. This point is also called stagnation point with respect to 
the ﬂow φ t in R n . Flows on line may have no ﬁxed points, only one ﬁxed point, ﬁnite number of ﬁxed points, and inﬁnite number of ﬁxed 
points. For example, the ﬂow x˙ = 5 (no ﬁxed points), x˙ = x (only one ﬁxed point), x˙ = x 2 − 1 (two ﬁxed points), and x˙ = sin x (inﬁnite 
number of ﬁxed points on the real line).

1.6 Linear Stability Analysis

A ﬁxed point, say x is said to be stable if for a given ε > 0, there exists a δ > 0

∼ 0

x ≥ t 0 , || ∼ x (t) − ∼ x 0 (t) || < ε, whenever || ∼ (t 0 ) R denotes the norm of a vector in R n . Otherwise, the

depending upon ε such that for all t

, where (t) || < δ || . || : R n → ﬁxed point is called unstable. In linear stability analysis the quadratic and higherorder terms in the Taylor 
series expansion about a ﬁxed point x ∗ of a system x˙ = f (x), x ∈ R are neglected due to the smallness of the terms. Consider a small 
perturbation quantity ξ(t), away from the ﬁxed point x ∗ , such that x(t) = x ∗ + ξ(t). We see whether the perturbation grows or decays as time 
goes on. So, we get the perturbation equation as

x

∼ 0

ξ ˙ = x˙ = f (x) = f (x ∗ + ξ).

Taylor series expansion of f (x∗ 

+

ξ) gives

ξ2  ξ ˙ = f (x ∗ ) + ξ f ' (x ∗ ) + f '' (x ∗ ) + · · · . 2

According to linear stability analysis, we get

ξ ˙ = ξ f ' (x ∗ ) [ ∵ f (x ∗ ) = 0 ] .

Assuming f ' (x ∗ ) = / 0, the perturbation ξ(t) grows exponentially if f ' (x ∗ ) > 0 and decays exponentially if f ' (x ∗ ) < 0. Linear theory 
fails if f ' (x ∗ ) = 0 and then higher-order derivatives must be considered in the neighborhood of ﬁxed point for stability analysis of the 
system.

Example 1.1 Find the evolution operator φ t for the one-dimensional ﬂow x˙ = −x 2 . Show that φ t forms a dynamical group. Is it a commutative 
group?

Solution The solutions of the given system are obtained as below:

dx 1 1 x˙ = = −x 2 ⇒ = t + A ⇒ x(t) = dt x t + A

in any interval of R that does not contain the point x = 0, where A is a constant.

If we take starting point x(0) = x 0 , then A = 1/x 0 and so we get

x0  x(t) = , t = / −1/x 0 . 1 + x0 t

The point x = 0 is not included in this solution. But it is the ﬁxed point of the given system, because x˙ = 0 ⇔ x = 0. Therefore, φ t (0) = 0 
for all t ∈ R. So the evolution operator of the system is given as φ t (x) = x 1 + xt for allx ∈ R.

The evolution operator φ t is not deﬁned for all t ∈ R. For example, if t = −1/x, x = / 0, then φ t is undeﬁned. Thus, we see that the interval 
in which φ t is deﬁned is completely dependent on x.

We shall now examine the group properties of the evolution operator φ t below:

(i) φ r φ s ∈ { φ t (x), t ∈ R, x ∈ R } ∀r, s ∈ R (closure property) Now,

y x φ r (y) = . Take y = 1 + yr 1 + xs

x/1 + sx x x = xr = = 1 + 1 + xs 1 + xs + xr 1 + x(s + r )

= φ s + r ∈ { φ t (x), t ∈ R, x ∈ R } .

(ii) φ t (φ s φ r ) = (φ t φ s )φ r (associative property)

y z L.H.S. = φ t ((φ s φ r )(x)) = φ t (y) = = 1 + yt 1 + zs

x = , y = φ s (φ r (x)) 1 + x(r + s)

x (where y = φ s (z), z = φ r (x) = 1 + rx )

x L.H.S. = = φ t + r + s (x) ∴ 1 + x(t + r + s)

x RH.S. = ((φ t φ s )φ r (x)) = φ t + s + r (x) = 1 + x(t + s + r )

Hence, φ t (φ s φ r )(x) = (φ s φ r )φ t (x), ∀x ∈ R.

(iii) φ 0 (x) = 1 + x x·0 = x, φ 0 is the identity operator.

y x φ t φ −t (x) = φ t (y) = , y = φ −t (x) =

1 + ty 1 − tx (iv) x = = x = φ 0 (x) (φ −t is the inverse ofφ t ). 1 − tx + tx Hence the ﬂow evolution operator forms a dynamical group.

(v) φ t φ s = φ s φ t ,

y x (φ t φ s )(x) = φ t (y) = , y = φ s (x) = 1 + ty 1 + xs x = = φ t + s (x) 1 + x(t + s)

x φ s φ t (x) = φ s + t (x) = . 1 + (s + t)x

So, φ t φ s = φ s φ t (Commutative property). Thus, the evolution operator φ t forms a commutative group.

Example 1.2 Find the evolution operator φ t for the system x˙ = x 2 − 1 and also verify that φ t (φ s (x)) = φ t + s (x) for all s, t ∈ R. Show 
that the evolution operator forms a dynamical group. Examine whether it is commutative dynamical group.

Solution Same as Example 1.1.

Example 1.3 Find the maximal interval of existence for unique solution of the following systems

(i) ˙x(t) = x 2 + cos 2 t, t > 0, x(0) = 0

(ii) x˙ = x 2 , x(0) = 1.

Solution (i) By maximal interval of existence of solution we mean the largest interval for which the solution of the equation exists. The given 
system is nonautonomous and f (t, x) = x 2 + cos 2 t. Consider the rectangle R = { (t, x) : 0 ≤ t ≤ a, | x | ≤ b, a > 0, b > 0 } containing the 
point (0, 0). Clearly, f (t, x) is continuous and ∂ ∂ x f = 2x is bounded on R. The Lipschitz condition | f (t, x 1 ) − f (t, x 2 ) | ≤ K | x 1 
− x 2 | , ∀(t, x 1 ), (t, x 2 ) ∈ R, K being the Lipschitz constant, is satisﬁed on R. Since | f (t, x) | = | | x 2 + cos 2 t | | ≤ | | x 2 | 
| + | t | ≤ | x 2 | + 1, and M = max | f (t, x) | = 1 + b 2 in R. Therefore, | cos 2 | | | from Picard’s theorem (if f (t, x) is a continuous 
function in a rectangle R = { (t, x) : | t − t 0 | ≤ a, | x − x 0 | ≤ b, a > 0, b > 0 } and satisﬁes Lipschitz condition therein, then the 
initial value problem x˙ = f (t, x), x(t 0 ) = x 0 has a unique solution in the rectangle R ' = { (t, x) : | t − t 0 | ≤ h, | x − x 0 | ≤ b } , 
where h = min { a, b/M } , M = max | f (t, x) | for all (t, x) ∈ R, see the books Coddington and Levinson [5], Arnold [6]). Now h = min { a, M b } 
= min { a, 1 + b b 2 } . We now determine the

maximum/minimum value(s) of b/(1 + b 2 ). Let g(b) = 1 + b b 2 . Then g ' (b) = (1 1−b 2 b 2 )2  + 2 and g '' (b) = 2b(b (1 + b −3) . For max or 
min value(s) of g(b), g ' (b) = 0. This gives b = 1. 2 )3  Since g '' (1) = −1/2 < 0, g(b) is maximum at b = 1 and the maximum value is given by 
g(1) = 2 1 . Now, if a ≥ 1/2, then h = 1 + b b 2 ≤ 1/2 and if a < 1/2, then h < 1/2. Thus we must have h ≤ 1/2. Hence the maximum interval of 
existence of the solution of the given system is 0 ≤ t ≤ 1/2.

(ii) Here f (t, x) = x 2 . Consider the rectangle R = { (t, x) : | t | ≤ a, | x − 1 | ≤ b, a > 0, b > 0 } containing the point (0, 1). Clearly, 
f (t, x) is continuous and ∂ ∂x f = 2x is bounded on R. Hence the Lipschitz condition is satisﬁed on R. Also in R, M = max | f (t, x) | = (1 + 
b) 2 . Therefore, h = min { a, M b } = min (1 + b b) 2 It can be shown, as earlier, that g(b) = (1 + b b) 2 is a, . { }

maximum at b = 1 and the maximum value is g(1) = 1/4. Now if a ≥ 1/4, then h = (1 + b b) 2 ≤ 1/4 and if a < 1/4, then h < 1/4. Thus we must have 
h ≤ 1/4. Hence the maximum interval of existence of solution of the given system is | t | ≤ 1/4, that

is, −1/4 ≤ t ≤ 1/4. Note that Picard’s theorem gives the local region of existence of unique solution for a system.

Example 1.4 Using linear stability analysis determine the stability of the critical points for the following systems:

(i) x˙ = sin x, (ii) x˙ = x 2 .

Solution (i) The given system has inﬁnite numbers of critical points. The critical points are x n ∗ = nπ, n = 0, ±1, ±2, . . . . When n is even, 
f ' (x n ∗ ) = cos(x n ∗ ) = cos(nπ) = (−1) n = 1 > 0. So, these critical points are unstable. When n is odd, f ' (x n ∗ ) = −1 < 0, and so 
these critical points are stable.

(ii) The critical point of the system is at x ∗ = 0. Now, f ' (x ∗ ) = 0 and f '' (x ∗ ) = 2 > 0. Hence, x ∗ is attracting when x < 0 and 
repelling when x > 0. Actually, the critical point is semi-stable in nature.

1.7 Analysis of One-Dimensional Flows

As we know qualitative approach pioneered by Henri Poincaré is the combination of analysis and geometry and is a powerful tool for analyzing 
solution behaviors of a system qualitatively. Basically, the topological dynamical behaviors can be explored using this mathematical tool. By 
drawing trajectories in phase line/plane/space, the behaviors of phase points may be found easily. In qualitative analysis we mainly look for the 
following solution behaviors:

(i) Local stabilities of ﬁxed points for a system.

(ii) Analyzing the existence of periodic/quasiperiodic, torus solutions, limit cycles, relaxation oscillation, hysteresis, the notions of local and 
global conjugations, etc.

(iii) Local and asymptotic solutions behaviors of a system.

(iv) Topological features of ﬂows such as bifurcations, catastrophe, topological equivalence, transitiveness, denseness, etc.

(v) How far can the evolution of a system be predicted in the long-term?

We shall now analyze a simple one-dimensional system as follows.

Consider a one-dimensional system represented as ˙x(t) = sin x with the initial condition x(t = 0) = x(0) = x 0 . The characteristic features of 
the system are (i) it is a one-dimensional system, (ii) nonlinear system, (iii) autonomous system, and (iv) its closed-form solution (analytical 
solution) exists. This is a one-dimensional ﬂow and we analyze the system on the basis of ﬂow. The analytical solution of the system is obtained 
easily

dx = sin x ⇒ dt = cosec(x)dx. dt

Integrating, we get

t=

∫

cosec(x)dx

= − log | cosec(x) + cot(x) | + c,

where c is an integrating constant. Using the initial condition x(0) = x 0 , we get the integrating constant c as

c = log | cosec(x 0 ) + cot(x 0 ) | .

Thus, the solution of the system is given as

| cosec(x 0 ) + cot(x 0 ) | t = log | | | | . | cosec(x) + cot(x) |

From this closed-form solution, the behaviors of solutions for any initial conditions are difﬁcult to analyze. Moreover, the asymptotic values of 
the system are also difﬁcult to obtain. The qualitative approach can give better dynamical behavior about this simple system.

We consider t as time, x as the position of an imaginary particle moving along the ﬂow in real line and x˙ as the velocity of that particle. The 
differential equation x˙ = sin x represents a vector ﬁeld on the line. It gives the velocity vector x˙ at each position x. The arrows point to the 
right when x˙ > 0 and to the left when x˙ < 0. We shall draw the graph of sin x versus x in x x˙ -plane which gives the ﬂow in the x-axis (see 
Fig. 1.3).

We may imagine that ﬂuid is ﬂowing steadily along the x-axis with a velocity x˙ which varies from place to place, according to equation x˙ = sin 
x. At points x˙ = 0, there is no ﬂow and such points are called equilibrium points (ﬁxed points). According to the deﬁnition of ﬁxed point, the 
equilibrium points of this system are obtained as sin x = 0 ⇒ x = nπ(n = 0, ±1, ±2, . . .). This simple looking autonomous system

has inﬁnite numbers of equilibrium points in R. We can see that there are two kinds of equilibrium points. The equilibrium points where the ﬂow 
is toward the point is called sink or point attractor (neighboring trajectories approach asymptotically to the point as t → ∞ ). On the other 
hand, when the ﬂow is away from the point, the point is called source or repeller (neighboring trajectories move away from the point as t → ∞ ). 
From the above ﬁgure the solid circles represent the sinks that are stable equilibrium points and the open circles are the sources, which are 
unstable equilibrium points. The names are given because the sinks and sources are common in ﬂuid ﬂow problems. From the geometric approach one 
can get local stability behavior of the equilibrium points of the system easily and is valid for all time. We shall now re-look the analytical 
solution of the system. The analytical solution can be expressed as

t = log | tan(x/2) | + c ⇒ x(t) = 2 tan −1 (Ae t ),

where A is an integrating constant.

Let the initial condition be x 0 = x(0) = π/4. Then from the above solution we obtain

A = tan(π/8) = −1 + √ 2 = 1/ + √ 2 1 . ( )

So the solution is expressed as

et  −1 x(t) = 2 tan . ( 1 + √ 2 )

We see that the solution x(t) → π and t → ∞ .

Without using analytical solution for this particular initial condition, the same result can be found by drawing the graph of x versus t. So, the 
solution’s behavior at any initial condition can be obtained easily by geometric approach. This simple one-dimensional system also has an 
interesting application. For a slow motion of a spring immersed in a highly viscous ﬂuid such as grease or viscoelastic ﬂuid (the combined 
effects of ﬂuid viscosity and elasticity for example, synovial ﬂuid in the joints of human bones), the viscous damping force is very strong 
compared to the inertia resulting in slow (creeping) motion. So one can neglect acceleration term (i.e., inertia) and the spring-mass system may be 
governed by the equation α x˙ = sin x, where α > 0 (string constant) is a real number and the dynamics can be obtained using this approach for 
different values of α (see the book Strogatz [7] for more physical examples).

We shall discuss a few worked-out examples presented below.

Example 1.5 With the help of ﬂow concept discuss the local stability of the ﬁxed

points of x˙ = f (x) = (x 2 − 1).

Solution The ﬁxed points of the given autonomous system are given by setting f (x) = 0. This gives x = ±1. So the ﬁxed points of the system are 1 
and −1. For the local stability of the system about these ﬁxed points we plot the graph of the function f (x) and then sketch the vector ﬁeld. 
The ﬂow is to the right direction, indicated by the symbol ‘ → ’, where the velocity x˙ > 0, that is, where (x 2 − 1) > 0 and to the left 
direction, indicated by the symbol ‘ ← ’, where x˙ < 0, that is, (x 2 − 1) < 0. We also use solid circles to represent stable ﬁxed points and 
open circles for unstable ﬁxed points.

In Fig. 1.4 the arrows indicate the ﬂow of the system. From the ﬁgure, we see that the ﬁxed point x = 1 is unstable, since it acts as a source 
point and the ﬁxed point x = −1 is stable, since it acts as a sink point.

Example 1.6 Discuss the stability character of the ﬁxed points for the system x˙ = x(1 − x) using the concept of ﬂow.

Solution Here f (x) = x(1 − x). Then for the ﬁxed points, we have

f (x) = 0 ⇒ x(1 − x) = 0 ⇒ x = 0, 1.

Thus, the ﬁxed points are 0 and 1. To discuss the stability of these ﬁxed points we plot the system (x versus ˙x) and then sketch the vector 
ﬁeld. The ﬂow is to the right direction, indicated by the symbol ‘ → ’, when the velocity x˙ > 0, and to the left direction, indicated by the 
symbol ‘ ← ’, when x˙ < 0. We also use solid circle to represent stable ﬁxed point and open circle to represent unstable ﬁxed point.

From Fig. 1.5 we see that the ﬁxed point x = 1 is stable, whereas the ﬁxed point x = 0 is unstable.

Example 1.7 Find the ﬁxed points and analyze the local stability of the following

Fig. 1.5 Pictorial representation of

f (x) = x(1 − x)

systems (i) x˙ = x + x 3 (ii) x˙ = x − x 3 (iii) x˙ = −x − x 3 .

Solution (i) Here f (x) = x + x 3 . Then for ﬁxed points f (x) = 0 ⇒ x + x 3 = 0 ⇒ x = 0, as x ∈ R. So, 0 is the only ﬁxed point of the 
system. We now see that when x > 0, x˙ > 0 and when x < 0, x˙ < 0. Hence the ﬁxed point x = 0 is unstable. The graphical representation of the 
ﬂow generated by the system is displayed in Fig. 1.6.

(ii) Here f (x) = x − x 3 . Then f (x) = 0 ⇒ x − x 3 = 0 ⇒ x = 0, 1, −1. Therefore, the ﬁxed points of the system are 0, 1, −1. We now see 
that

(a) when x < −1, then x˙ > 0

(b) when −1 < x < 0, x˙ < 0

(c) when 0 < x < 1, x˙ > 0

(d) when x > 1, then x˙ < 0.

This shows that the ﬁxed points 1 and − 1 are stable, whereas the ﬁxed point 0 is unstable (Fig. 1.7).

(iii) Here f (x) = −x − x 3 . Then f (x) = 0 ⇒ −x − x 3 = 0 ⇒ x = 0, as x ∈ R. So x = 0 is the only ﬁxed point of the system. We now see 
that x˙ > 0 when

x < 0 and x˙ < 0 when x > 0. This shows that the ﬁxed point x = 0 is stable. The graphical representation of the ﬂow generated by the system is 
displayed in Fig. 1.8.

Example 1.8 Determine the equilibrium points and sketch the phase diagram in the neighborhood of the equilibrium points for the system represented 
as x˙ + xsgn(x) = 0.

Solution Given system is x˙ function sgn(x) is deﬁned as

+

xsgn(x) = 0, that is, x˙ = − xsgn(x), where the

⎪ ⎧ 1, x > 0 sgn(x) = 0, x = 0 ⎪ ⎨ ⎩ −1, x < 0

For equilibrium points, we have

x˙ = 0 ⇒ xsgnx = 0 ⇒ x = 0.

This shows that the system has only one equilibrium point at x = 0. In ﬂow analysis we see that the velocity x˙ < 0 for all x = / 0. The ﬂow is 
to the right

direction, when x˙ > 0, in the negative x-axis and to the left direction, when x˙ < 0, in the positive x-axis. This is shown in the phase diagram 
depicted in Fig. 1.9, which shows that the ﬁxed-point origin is semi-stable.

1.8 Conservative and Dissipative Dynamical Systems

The dichotomy of dynamical systems in conservative versus dissipative is very important. They have some fundamental properties. Particularly, 
conservative systems are the integral part of Hamiltonian mechanics. We give here only the formal deﬁnitions of conservative and dissipative 
systems. Consider an autonomous system represented as

x = f (x ), x ∈ R n . ∼ ∼ ∼ ∼

(1.15)

The conservative and dissipative systems are deﬁned with respect to the divergence of the corresponding vector ﬁeld, which in turn refers to the 
conservation of volume or area in their state space or phase plane, respectively, as follows:

A system is said to be conservative if the divergence of its vector ﬁeld is zero. On the other hand, it is said to be dissipative if its vector 
ﬁeld has negative divergence. The phase volume in a conservative system is constant under the ﬂow while for a dissipative system the phase volume 
occupied by the system is gradually decreased as the time t increases and shrinks to zero as t → ∞ . When divergence of vector ﬁeld is positive, 
the phase volume is gradually expanding. We shall discuss it in a later chapter. We state a lemma below which gives the change of volume in a phase 
space for an autonomous system.

Sometimes, it is useful to ﬁnd the evolution of volume in the phase space of a system∼ x˙ = f (x ), x ∈ R n . The system generates a ﬂow φ(t, x 
). We give Liouville’s

∼

∼

∼

theorem which describes the time evolution of volume under the ﬂow φ(t, x ). Before

∼

this we now give the following lemma.

.

Lemma 1.1 Consider an autonomous vector ﬁeld x = f (x ), x ∈ R n , f ≡ f and ∼ ∼ ∼ ∼ generates a ﬂow φ t (x ). Let D 0 be a domain in R n 
and φ t (D 0 ) be its evolution under ∼ the ﬂow. If V (t) is the volume of D t , then the time rate of change of volume is given

as dV dt | | t=0 = ∫ D 0 ∇ · f d x . ∼

Proof The volume V(t) can be expressed in the following form using the deﬁnition of the Jacobian of a transformation as.

| ∂φ(t, x ) | | ∼ | V (t) = | | d x . ∫ | | ∂x | | ∼ D0 

Expanding Taylor series of φ(t, x ) in the neighborhood of t = 0, we get

∼

φ(t, x ) = x + f (x )t + O(t 2 ) ∼ ∼ ∼

∂φ ∂ f ⇒ = I + t + O(t 2 ). ∂ x ∂ x ∼ ∼

Here I is the n × n identity matrix and

|

|

|

|

| ∂φ | | ∂ f | | | = | I + t | + O(t 2 ) | ∂ x | | ∂ x | | ∼ | | ∼ | | | | |

∂f = 1 + trace ⎛ ⎞ t + O(t 2 ) [ Using expansion of the determinant ] . ∂ x ⎝ ∼ ⎠

Now, trace ∂ ∂ f x = ∇ · f, so we have ( ∼ )

V (t) = V (0) + t∇ · f d x + O(t 2 ). ∫ ∼ D0 

This gives dV dt | | t=0 = ∫ D 0 ∇ · f d x . ∼

Theorem 1.1 (Liouville’s theorem) Suppose ∇ · f = 0 for a vector ﬁeld f . Then for any region D 0 ⊆ R n , the volume V(t) generated by the ﬂow 
φ(t, x ) is V (t) = V (0), ∼ V (0) being the volume of D 0 .

Proof Suppose the divergence of the vector ﬁeld f is everywhere constant, that is, ∇ · f = c. For arbitrary time t 0 the evolution equation for 
the volume is given as V ˙ = cV . This gives V (t) = V (0)e ct . When the vector ﬁeld is divergence free, that is, c = 0, we get the result V ˙ = 
0 ⇒ V (t) = V (0) = constant. Thus, we can say that the ﬂow generated by a time independent system is volume preserving.

Examples of conservative and dissipative systems are presented below.

(a) Consider a linear and undamped pendulum represented as ¨x + x = 0. This is an example of a conservative system. Setting x˙ = y, we can write it 
as a system

of equations x˙ = y, y˙ = −x .

The system may also be written in the compact form x˙ =

f

(x ), where

∼

∼

∼

y → . The divergence of the vector ﬁeld f is given by ∇ · f = ∼ ∼ ( −x ) ∼ ∼ ∂ ∂ = 0. According to the deﬁnition, the system is 
conservative ∂x (y) + ∂ y (−x) and the area occupied in the xy-phase plane is constant. ..

f (x ) =

(b) The damped pendulum governed by x + α x˙ + βx = 0, α, β > 0 is an example of a dissipative system. Setting x˙ = y, we can write the system as

x˙ = y, y˙ = − αy − βx.

y The vector ﬁeld is then expressed as f (x ) = . ∼ ∼ ( − αy − β x )

Now,

∇ → ·

f

=

∂

∂x

(y) +

∂

∂y

(−αy − βx) = −α < 0, since α > 0.

∼

This shows that the divergence of the vector ﬁeld is negative. So, the system is dissipative in nature and the area in the phase plane is 
decreasing as time goes on. This is the simplest linear oscillator with linear damping. It describes a spring-mass system with a damper in 
parallel. The spring force is proportional to the extension x of the spring and the damping or frictional force is proportional to the velocity x.˙ 
The two constants α and β are related to the stiffness of the spring and the degrees of friction in the damper, respectively. According to the 
above lemma, the change in phase area is given by

A(t) = cA(0)e −αt , α > 0, c being a constant as t → ∞, A(t) → 0.

Example 1.9 Find the phase volume element for the systems (i) x˙ = −x, (ii) x˙ = ax − bxy, y˙ = bxy − cy where x, y ≥ 0 and a, b, c are 
positive constants.

Solution (i) The ﬂow of the system x˙ = −x is attracted toward the point x = 0. The time rate of change of volume element V (t) under the ﬂow is 
given as

dV | | = − dx = −V (0) dt | | t=0 ∫ D(0)

or, V (t) = V (0)e −t → 0 as t → ∞.

Hence the phase volume element V (t) shrinks exponentially.

(ii) The given system is a classical Lotka–Volterra predator–prey population model. The rate of change in phase area A(t) is given as

dV → = − ∇ · f dxdy dt ∫ ∼

= − (a − c − by + bx)dxdy. ∫

This shows that a phase area periodically shrinks and expands resulting in variable amplitudes.

1.9 Some Deﬁnitions

In this section we give some important preliminary deﬁnitions relating to ﬂow of a system. The deﬁnitions given here are elaborately discussed 
in the later chapters for higher-dimensional systems.

Invariant set A set D ⊂ R n is said to be an invariant set under the ﬂow φ t if for any point p ∈ D, φ t (p) ∈ D for all t ∈ R. The set D is 
said to be positively invariant if φ t (p) ∈ D for t ≥ 0. Trajectories starting in an invariant set remain in the set for all times. An interval 
is called trapping if it is mapped into itself and is said to be invariant if it is mapped exactly onto itself. Moreover, if a bounded interval is 
trapping, then all of its trajectories are trapped inside and must converge to a closed, invariant and bounded limit set. Clearly, every orbit is 
invariant. On the other way, the basin of attraction of the ﬂow trajectories is the set of all initial states for which its long-time behavior 
approaches to certain limit set. Due to the continuity of ﬂow and properties of ﬁxed points, it can be easily veriﬁed that the basin of 
attraction is an invariant set. Moreover, its deﬁnition is self-sufﬁcient to prove that for any point of the basin set and for any arbitrary open 
set containing that point, the subsequent ﬂow always remains sufﬁciently close to every point of the open set. So, that basin set of an 
attracting ﬁxed point be open. It can prove easily. There exists an open set U around an attracting ﬁxed point x 0 such that for any x∈U, ϕ t 
(x)→ x 0 as t→∞. If x1  be in its basin, then ϕ t (x 1 )→ x 0 as t→∞. Since, ϕ t is continuous so, the preimage of U under it say V is also 
open and contains that x 1 . Now, as for any point in V ends up in U after large time and attracts the point x 0 . So it is obvious that, any x 1 
in the basin has an open neighborhood V around it which is entirely within the basin. The limit sets are called attractors of a system. Attractors 
are classiﬁed into

different types. The regular attractors specify the equilibrium point or point attractor, periodic orbits, limit cycles, torus, and quasiperiodic 
motions. There are another class of fractal-like attractors, known as strange attractors in deterministic nonlinear dissipative systems. They are 
erratic, aperiodic, and unpredictable, which are main attributes of chaos. However, there exist nonchaotic strange attractors also.

Theorem 1.2 The ternary Cantor set is uncountable but invariant.

Proof The ternary Cantor set C can be constructed by using the two contraction transformations T 1 : x → x 3 , T 2 : x → x 3 + 2 3 . Moreover, if 
a point a = 0 · a 1 a 2 a 3 . . . = ∑ i=1 ∞ ( a ) ∈ C has triadic expansion with only 0 or 2, 3i i  and so a i = / 1. Again, each point in [0,1] 
has binary representation of the form b = 0 · b 1 b 2 b 3 ..., where b i = 0 or 1. Let us deﬁne a map f : C → [0, 1] by

b i = 0 if a i = 0 f (0 · a 1 a 2 a 3 . . .) = 0 · b 1 b 2 b 3 . . . where b i = 1 if a i = 2 )

Then clearly f is a bijection. Thus, C has a one-to-one correspondence with the uncountable set [0,1]. So, C is also uncountable.

If we start with the closed and bounded interval A 0 = [0, 1], then under the above 1 2 transformations we have A 1 = T 1 [ 0, 1 ] ∪ T 2 [ 0, 1 ] 
= [ 0, 3 ] ∪ [ 3 , 1 ] . Applying these transformations once again to each of the above intervals will give A 2 = 1 1 1 7 1 2 2 2 2 8 T 1 [ 0, 3 ] 
∪ T 2 [ 0, 3 ] ∪ T 1 [ 3 , 1 ] ∪ T 2 [ 3 , 1 ] = [ 0, 9 ] ∪ [ 3 , 9 ] ∪ [ 9 , 3 ] ∪ [ 9 , 1 ] .

Thus, A 2 is obtained from A 1 by the transformations T 1 and T 2 , similarly A 3 will be obtained from A 2 and so on. So, we can write the Cantor 
set as, C = ∩ n=1 ∞ A n = ∞ ∞ 1 2 ∩ n=1 T (A n−1 ) = ∩ n=1 (T 1 (A n−1 ) ∪ T 2 ( A n−1 )) = 3 ∩ n=1 ∞ ( A n−1 ∪ ( 3 + A n−1 )) . 
Thus C ⊂ TC . Moreover, if a point say a = 0.a 1 a 2 . . . ∈ C has the triadic expansion with only 0 or 2 then the points obtained after applying 
the transformations T 1 and T2  a3  have also the triadic expansion with 0 or 2. As, T 1 (0.a 2 a 3 ...) T 1 a = ( 3 2 + 3 2 + · · · ) = a 1 a 3 a 
2 a 3 0 a 2 a3  · · · = · · · = · · · = 0.0a 2 a 3 . . . and 3 ( 3 2 + 3 2 + ) 3 2 + 3 3 + 3 + 3 2 + 3 3 + a 3 2 1 a 3 2 a 2 a3  T 2 (0 a 2 a 3 . . 
.) T 2 a a · = ( 3 2 + 3 2 + · · · ) = 3 + 3 ( 3 2 + 3 2 + · · · ) = 3 + 3 2 + 3 3 + · · · = 0.2a 2 a 3 . . ..This shows that a = 0.a 1 a 2 . . . 
is the image of T 1 if a 1 = 0 and is the image of T 2 if a 1 = 2. Hence, TC ⊂ C . So, we can write TC = C . Hence the Cantor set is invariant 
under the contraction transformations T which is the combination of T 1 and T 2 .

Limit points: ω- and α -limit points A continuous map f : X → X is said to be a topological system with discrete time or simply a topological 
dynamical system wheref is a homeomorphism that is a bijective continuous map with continuous inverse. Any ﬂow or semi-ﬂow is a topological 
dynamical system with continuous time. We now deﬁne two limiting topological concepts which are relevant to the orbits of dynamical systems 
asymptotically. The asymptotic behavior of a trajectory may be related with limit points/sets or cycles and are termed as ω- and α -limit 
points/sets or cycles. The ω-limit set of a point p is contained by the points that are arbitrarily approximated by the images of f n (p)

while the α -limit set of p is contained by the points that are arbitrarily approximated by the preimages of f −n ( p). We now give the 
mathematical deﬁnitions.

A point p ∈ R n is called an ω-(resp. a α -) limit point if there exists a sequence { t i } with t i → ∞ (resp. t i → −∞) such that the ﬂow 
φ(t i , x) → p as i → ∞ . The ω-limit set(cycle) is denoted by ∧(x ) and is deﬁned as

∼

∧(x ) = ∈ R n | ∃ { t i } with t i → ∞ and φ(t i , x ) → p as i → ∞ x . ∼ { ∼ ∼ }

Speciﬁcally, in a discrete-time system the ω- limit set of a point p is deﬁned (overbar indicates the closure of a set) as

∧(p) = ∩ f m (p) : m ≥ n . n∈N { }

Similarly, the α -limit set (cycle) for the ﬂow φ(t i , x), μ(x ) is deﬁned as

∼

x μ(x ) = ∈ R n | ∃ { t i } with t i → −∞ and φ(t i , x ) → p as i → ∞ . ∼ { ∼ ∼ }

The α - limit set in discrete-time system is deﬁned by

μ(p) = ∩ f −m (p) : m ≥ n . n∈N { }

For example, consider a ﬂow φ(t, x) on R 2 generated by the system r˙ = cr (1 r ), θ ˙ = 1, c being a positive constant. For x = / 0, let p be any 
point of the closed ∼ orbit C and take { t i } i=1 ∞ to be the sequence of t > 0. The trajectory through x crosses the radial line through p. So, 
t i → ∞ as i → ∞ and φ(t i , x) → p as i → ∞ . If x ∼ lies in the closed orbit C, then φ(t i , x) = p for each i. Hence every point of C is 
a ω-limit point of x and so Ʌ(x) = C for every x = / 0. When | x | ≤ 1, the sequence ∼

{ 0 } for | x | < 1 ( closed orbit for | x | = 1. When | x | > 1, there is no sequence { t i } i=1 ∞ , with t i → ∞ as i → ∞ , such that φ(t i 
, x) exists as i → ∞ . So, μ(x) is empty when | x | > 1. The closed orbit C is called a limit cycle of the system, C : x 2 + y 2 = 1, so the 
limit cycle is a circle. In a similar way one can ﬁnd the limiting sets for the ﬂow represented by r˙ = r (r − 1)(r − 2),θ ˙ = 1 as follows: 
(i) α(p) = ω(p) = { 0, 0 } for r = 0, (ii) α(p) = { (0, 0) } , ω( p) = c 1 : x 2 + y 2 = 1 for r ∈ (0, 1), (iii )α(p) = ω(p) = c1  for r = 1, (iv) 
α(p) = c 1 , ω(p) = c 2 for r ∈ (1, 2), (v) α( p) = ω(p) = c 2 for r = 2, (vi) α(p) = c 2 , ω(p) = φ for r > 2. Since θ increases as t increases 
the trajectories move in anticlockwise direction. So, there exists two limit cycle c 1 and c 2 . It reveals that there exist ﬂows with multiple 
limit cycles.

{ t i }i=1 ∞ 

with t < 0 gives the α -limit set μ(x) =

The trajectory of a system through a point x is the set γ (x ) = U t∈R φ(t, ∼ x )

∼

∼

and the corresponding positive semi-trajectory γ + (x ) and negative semi-trajectory

∼

γ − (x ) are deﬁned as follows:

∼

γ + (x ) = ∐ φ(t, ∼ x ) and γ − (x ) = ∐ φ(t, ∼ x ). ∼ ∼ t ≥ 0 t ≤ 0

We now state two lemmas below. Interested readers can try for proofs (see Glendinning [8]).

Theorem 1.3 Prove that the ω-limit set is invariant, nonempty, and compact if the positive orbit is bounded.

Proof If Ʌ(x) is ﬁnite, then it is closed. Let Ʌ(x) = ω be inﬁnite. Taking α ∈ ω ' (the derived set of ω). So, for all open neighborhood N δ (α) 
of α , N δ (α) ∩ ω = / ∅ . Let p δ ∈ N δ (α) ∩ ω. Since N δ (α) is open, so for all δ 1 > 0, N δ 1 (p δ ) ⊂ N δ (α) and N δ 1 (p δ ) ∩ γ + 
(x) = / ∅ . This implies, N δ (α) ∩ γ + (x) = / ∅ . Hence, α ∈ ω. That is,Ʌ(x) = ω is closed.

Moreover if γ + (x) is bounded, then its set of limit point Ʌ(x) is also bounded. So, Ʌ(x) is compact.

Let p ∈ ω. Then there exists a sequence { t k } → ∞ such that { ϕ(t k , x) } → p . By using the continuity and ﬂow properties of ϕ , we get

ϕ(t, p) = ϕ t, lim ϕ(t k , x) = lim ϕ(t, ϕ(t k , x)) = lim ϕ(t + t k , x). ( k→∞ ) k→∞ k→∞

This implies there exists a sequence, { t + tk  that ϕ(t + t k , x) → ϕ(t, p). Therefore, ϕ(t, p) under the ﬂow ϕ .

Lemma 1.2

} ∈

which converges to inﬁnity such ω. Hence, Ʌ(x) = ω is invariant

(a) The set D is invariant if and only if γ (x ) ⊂ D for all

x

∼

∈ D.

∼

(b) D is invariant if and only if R n \ D is invariant.

(c) Let (D i ) be a countable collection of invariant subsets of R n . Then ∩ i D i are also invariant subsets of R n .

Ui 

D i and

Lemma 1.3 The set Ʌ(x ) = ∩ ∼ x

∼

∈γ (x )

∼

cl

γ+  (

(x ) , where cl denotes the closure of ∼ )

the set, is the ω-limit set.

Non-wandering point A point p is called a nonwandering point if for any neighborhood U of p and for any T > 0, there exists some | t | > T such 
that φ(t, U )∩U = / ϕ .

The nonwandering set, denoted by Ω, contains all such points p ∈ U and it is closed. Nonwandering points give asymptotic behavior of the orbit. In 
the above deﬁnition, if φ(t, U ) ∩ U = ϕ , then the point p is called a wandering point.

The examples of nonwandering points are ﬁxed points and periodic orbits of a ..

system. For the undamped oscillator ( x + x = 0), all points are nonwandering in ..

x x˙ phase plane while for the damped oscillator ( x + α x˙ + x = 0), origin is the only nonwandering point. We now give some speciﬁc deﬁnitions 
of invariant sets.

Absorbing set A positive invariant compact subset B ⊆ R n is said to be an absorbing set if there exists a bounded subset C of R n with C ⊃ B 
such that t C > 0 ⇒ φ(t, C) ⊂ B∀t ≥ t C (see Wiggins [9] for details).

Trapping zone An open set U in an invariant set D ⊂ R n in an attracting set for a ﬂow generated by a system is called a trapping zone. Let a set 
A be closed and invariant. The set A is said to be stable if and only if every neighborhood of A contains a neighborhood U of A which is trapping.

Basin of attraction The domain (called as basin of attraction) of an attracting set D is deﬁned as U t ≤ 0 φ(t, U ) where U is any open set in D 
⊂ R n . It is also an invariant set. The basin of attraction for the ﬂow as in Fig. 1.3 for a particular ﬁxed point say π is (0,2π). The basin 
of attractions of other attracting ﬁxed points can be found.

Attracting set A closed invariant set D ⊂ R n for a ﬂow φ t is said to be an attracting set if there exists some neighborhood U in D such that 
∀t ≥ 0, φ(t, U) ⊂ U and

∩ t>0 φ(t, U ) = D .

We now give an example of attracting set which is invariant and closed from Ruelle [10] and discussed in Guckenheimer and Holmes [11] also. 
Consider the one-dimensional system x˙ = −x 4 sin(π/x). It has countably inﬁnite set of ﬁxed points at x ∗ = 0, ± n 1 , n = 1, 2, 3, . . .. All 
ﬁxed points are in [-1,1]. The ﬂow generated on the real line. Now,

f (x) = −x 4 sin(π/x) ⇒ f ' (x) = −4x 3 sin(π/x) + πx 2 cos(π/x)

π π ⇒ f ' (x ∗ ) | x ∗ =± n 1 = cos(nπ) = (−1) n . n 2 n2 

The ﬁxed point x ∗ = 0 is neither attracting nor repelling. The ﬁxed points x ∗ = ± 2n 1 , n = 1, 2, . . . are repelling while the ﬁxed points 
x ∗ = ± (2n−1) 1 , n = 1, 2, . . . are attracting. Hence using the above deﬁnition of attracting set, the closed interval [-1,1] is an 
attracting set of the given system.

1.10 Exercises

1. (a) What is a dynamical system? Write its importance.

(b) Discuss continuous and discrete dynamical systems with examples.

(c) Explain deterministic, semi-deterministic, and nondeterministic dynamical processes with examples.

(d) What do you mean by ‘qualitative study’ of a nonlinear system? Write it importance in nonlinear dynamics. Compare the basic properties of 
qualitative and quantitative approaches for the study of dynamical systems.

2. (a) Give the mathematical deﬁnition of ﬂow. Discuss the concept related to ‘a ﬂow and its orbit’. Also indicate its implication on uniqueness 
theorem of differential equation.

(b) Show that the initial value problem x˙ = x 1/3 , x(0) = 0 has an inﬁnite number of solutions. How would you explain it in the context of ﬂow?

(c) Consider a system x˙ = | x | p/q with x(0) = 0 where p and q are prime to each other. Show that the system has an inﬁnite number of solutions 
if p < q, and it has a unique solution if p > q. 3. Find the maximum interval of existence for the solutions of the following equations

(a) x˙ = x 2 , x(0) = x 0 , (b) x˙ = tx 2 , x(0) = x 0 , (c) x˙ = x 2 + t 2 , x(0) = x 0 , (d) x˙ = x(x − 2), x(0) = 3

4. For what values of t 0 and x 0 does the initial value problem x˙ = √ x, x(t 0 ) = x0  have a unique solution?

5. Show that the initial value problem x˙ = 3x 2/3 with x(0) = 0 has two solutions passing through the point (0, 0). How do you explain the context 
of ﬂow in this?

6. Show that the initial value problem x˙ = | x | 1/2 , x(0) = 0 has four different solutions through the point (0, 0). Sketch these solutions in 
the t − x plane. Explain this from Picard’s theorem.

7. Prove that the system x˙ = x 3 with the initial condition x(0) = 2 has a solution on an interval (−∞, c), c ∈ R. Sketch the solution x(t) in 
the t – x plane and ﬁnd the limiting behavior of solution x(t) as t → c-.

0 whenx 0 8. Prove that the Solutions of the Initial Value Problem x˙ = ≤ ( x 1/n whenx > 0

With x(0) = 0 Are not Unique for n = 2, 3, 4, . . . .

9. What do you mean by ﬁxed point of a system? Explain its important in dynamical system. Determine the ﬁxed points of the system x˙ = x 2 − x, 
x ∈ R. Show that solutions exist for all time and become unbounded in ﬁnite time.

10. Give mathematical deﬁnitions of ‘ﬂow evolution operator’ of a system. Write the basic properties of an evolution operator of a ﬂow.

11. Show that the dynamical system (or evolution) forms a dynamical group. What can you say about commutative/non-commutative group of a system? 
Give reasons in support of your answer.

12. (a) Find the evolution operators for the following systems: (i) x˙ = x − x 2 ,

(ii) x˙ = x 2 , (iii) x˙ = x ln x, x > 0, (iv) x˙ = tanh(x), (v) x˙ = x − x 3 , (vi) x˙ = f cos ωt , (vii) x˙ = f sin ωt.

Verify that φ t (φ s (x)) = φ t + s (x) ∀x, t, s ∈ R for all cases. Also, show that the evolution operator φ t for the system x˙ = x 2 forms a 
dynamical group.

(b) Let f : R n → R n be a continuous function such that, given x 0 ∈ R n , the initial value problem x˙ = f (x) with x(0) = x 0 has unique 
solution x(t, x 0 ) for t ∈ R. Then prove that the family of maps φ(t) ∈ R n → R n such that

φ t (x 0 ) = x(t, x 0 ) for each t ∈ R is a ﬂow.

13. Deﬁne ﬁxed point of a system in the context of ﬂow. Give its geometrical interpretation. How do you relate this concept with the usual 
notion of ﬁxed point in a continuous dynamical system?

14. (a) Deﬁne source and sink for a one-dimensional ﬂow. Illustrate them with examples.

(b) Locate the source and sink for the system x˙ = (x 2 − 1), x ∈ R.

15. Consider the one-dimensional system represented as x˙ = ax + b, where b is a constant and a is a nonzero parameter. Find all ﬁxed points of 
the system and discuss their stability for different values of a.

16. (a) Sketch the region of the ﬂow generated by the one-dimensional system x˙ = 1/x, x > 0 with the starting condition x(0) = x 0 . Find the 
ﬁxed points of the one-dimensional system x˙ = x 4 cos(π/x) and also determine their nature of stability.

(b) What do you mean by oscillating solution of a system? Explain with examples. Show that one-dimensional ﬂow cannot oscillate. 17. (a) Find the 
critical points of the following systems: (i) x˙ = e x − 1, (ii) x˙ = x 2 −x−1, (iii) x˙ = sin(πx), (iv) x˙ = cos x, (v) x˙ = sinh x , (vi) x˙ = 
rx−x 2 for r < 0, r = 0, r > 0, (vii) x˙ = x − ln(1 + x) + r, r > 0, (viii) x˙ = x − x 3 /6.

(b) Using linear stability analysis determine the stabilities/instabilities of the following systems about their critical points:

(i) x˙ = x(x − 1)(x − 2), (ii) x˙ = (x − 2)(x − 3), (iii) x˙ = log x , (iv) x˙ = cos x , (v) x˙ = tan x , (vi) x˙ = 2 + sin x , (vii) x˙ = x − 
x 3 /6, (viii) x˙ = 1 − x 2 /2 + x 4 /24.

18. Sketch the family of solutions of the differential equation x˙ = ax −bx 2 , x > 0, and a, b > 0. How does the velocity vector x˙ behave when 
(a/b) < x < ∞?

19. Find the critical points and analyze the local stability about the critical points of each of the following systems: (i)x˙ = x 4 − x 3 − 2x 2 
, (ii) x˙ = sinh(x 2 ) (iii) x˙ = cos x − 1, (iv) x˙ = (x − a) 2 , (v) x˙ = (x + 1)(x + 2), (vi) x˙ = tan x, (vii) x˙ = log x,(viii) x˙ = e x − 
x − 1.

20. Classify all possible ﬂows in R of the system x˙ = a 0 + a 1 x + a 2 x 2 + x 3 , where

a 0 , a 1 , a 2 ∈ R..

21. Consider the one-dimensional system x˙ = μx + x 3 , μ ≥ 0. Using geometric approach ﬁnd the solution behavior for any initial condition x 0 
(= / 0).

22. When is a ﬂow called conservative? Give an example of conservative ﬂow.

23. Prove that the phase volume of a conservative system is constant. Is the converse true? Give reasons in support of your answer.

24. What can you say about time rate of change of phase volume element in a dissipative dynamical system? Explain it geometrically. Give an example 
of a dissipative system.

25. What signify the limit sets of a dynamical system? Prove that the α - and ω-limit sets of a ﬂow φ t (x) are contained in the nonwandering set 
of the ﬂow φ t (x).

26. Deﬁne absorbing set of a ﬂow. Write the relation between trapping zone and absorbing set. Prove that for an absorbing set A, ∩ t ≥ 0 φ(t, 
A) forms an attracting set.

27. Give the deﬁnition of invariant set of a ﬂow. Write its importance in dynamical evolution of a system. Prove that the ω-limit set, λ(x ), is 
invariant and it is

nonempty and compact if the positive orbit γ + (x ) of

∼

∼ x ∼

is bounded.

28. If two orbits γ (x) and γ (y) of autonomous systems satisfy γ (x) ∩ γ (y) = / ϕ , prove that both the orbits are coinciding.

29. Show that the middle third Cantor set is nowhere dense. Find its measure.

30. Find the limit cycle for r˙ = cr(1 − r ), θ ˙ = 1, c being a constant.

References

1. Arrowsmith, D.K., Place, C.M.: An Introduction to Dynamical Systems. Cambridge University Press, Cambridge (1990)

2. Ren, J., Yu, L., Siegmund, S.: Bifurcations and chaos in a discrete predator-prey model with Crowley-Martin functional response. Nonlinear Dyn. 
90, 19–41 (2017)

3. Crowley, P.H., Martin, E.K.: Functional responses and interference within and between year classes of a dragonﬂy population. J. North Am. 
Benthol. Soc. 8(3) (1989)

4. Lakshmanan, M., Rajasekar, S.: Nonlinear Dynamics: Integrability, Chaos and Patterns.

Springer, Berlin (2003)

5. Coddington, E.A., Levinson, N.: Theory of Ordinary Differential Equations. McGraw Hill, New York (1955)

6. Arnold, V.I.: Ordinary Differential Equations. MIT Press, Cambridge (1973)

7. Strogatz S.H.: Nonlinear Dynamics and Chaos with application to physics, biology, chemistry and engineering. Perseus books, L.L.C, Massachusetts 
(1994)

8. Glendinning P.: Stability, Instability and Chaos: An Introduction to the Theory of Nonlinear Differential Equations. Cambridge University Press, 
Cambridge (1994)

9. Wiggins S.: Introduction to Applied Nonlinear Dynamical Systems and Chaos, 2nd edn.

Springer, Berlin (2003)

10. Ruelle, D.: Elements of Differentiable Dynamics and Bifurcation Theory. Academic Press, New York (1989)

11. Guckenheimer J., Holmes, P.: Nonlinear Oscillations, Dynamical Systems, and Bifurcations of Vector Fields. Springer, Berlin (1983)


